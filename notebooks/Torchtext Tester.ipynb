{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from argparse import ArgumentParser\n",
    "import mlearn.modeling.multitask as mtl\n",
    "from mlearn.utils.metrics import Metrics\n",
    "from mlearn.data.batching import TorchtextExtractor\n",
    "from mlearn.data.clean import Cleaner, Preprocessors\n",
    "from mlearn.utils.train import run_mtl_model, train_mtl_model\n",
    "from torchtext.data import TabularDataset, Field, LabelField, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data inputs and outputs\n",
    "main = 'davidson'\n",
    "auxi = ['waseem']\n",
    "datadir = '../data/json/'\n",
    "results = '../results/'\n",
    "save_model = '../results/'\n",
    "\n",
    "# Cleaning and metrics\n",
    "cleaners = ['lower', 'username', 'url']\n",
    "metrics = ['f1-score', 'precision', 'recall', 'accuracy']\n",
    "display_metric = stop_metric = 'f1-score'\n",
    "dev_metrics = Metrics(metrics, display_metric, stop_metric)\n",
    "metrics = Metrics(metrics, display_metric, stop_metric)\n",
    "\n",
    "# Experiment\n",
    "experiment = 'word'\n",
    "tokenizer = 'bpe'\n",
    "seed = 42\n",
    "\n",
    "# Modelling\n",
    "# All models\n",
    "model = 'lstm'\n",
    "patience = 1\n",
    "encoding = 'embedding'\n",
    "loss = 'nlll'\n",
    "optimizer = 'adam'\n",
    "shuffle = True\n",
    "gpu = False\n",
    "batch_first = True\n",
    "clip = 1.0\n",
    "\n",
    "# LSTM\n",
    "layers = 1\n",
    "\n",
    "# CNN\n",
    "window_sizes = \"2,3,4\"\n",
    "filters = 128\n",
    "\n",
    "# Hyper Parameters\n",
    "embedding = 64\n",
    "hidden = [\"64,64\"]\n",
    "shared = 64\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.02\n",
    "dropout = 0.2\n",
    "nonlinearity = 'tanh'\n",
    "\n",
    "# MTL specific\n",
    "batches_epoch = 50\n",
    "loss_weights = [1.0, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise random seeds\n",
    "torch.random.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set up experiment and cleaner\n",
    "c = Cleaner(processes = cleaners)\n",
    "exp = Preprocessors('data/').select_experiment(experiment)\n",
    "onehot = True if encoding == 'onehot' else False\n",
    "\n",
    "# Load tokenizers\n",
    "if tokenizer == 'spacy':\n",
    "    selected_tok  = c.tokenize\n",
    "elif tokenizer == 'bpe':\n",
    "    selected_tok = c.bpe_tokenize\n",
    "elif tokenizer == 'ekphrasis' and args.experiment == 'word':\n",
    "    selected_tok = c.ekphrasis_tokenize\n",
    "    annotate = {'elongated', 'emphasis'}\n",
    "    flters = [f\"<{filtr}>\" for filtr in annotate]\n",
    "    c._load_ekphrasis(annotate, flters)\n",
    "elif tokenizer == 'ekphrasis' and args.experiment == 'liwc':\n",
    "    ekphr = c.ekphrasis_tokenize\n",
    "    annotate = {'elongated', 'emphasis'}\n",
    "    flters = [f\"<{filtr}>\" for filtr in annotate]\n",
    "    c._load_ekphrasis(annotate, flters)\n",
    "\n",
    "    def liwc_toks(doc):\n",
    "        tokens = ekphr(doc)\n",
    "        tokens = exp(tokens)\n",
    "        return tokens\n",
    "    selected_tok = liwc_toks\n",
    "tokenizer = selected_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up fields\n",
    "text = Field(tokenize = tokenizer, lower = True, batch_first = True)\n",
    "label = LabelField()\n",
    "fields = {'text': ('text', text), 'label': ('label', label)}  # Because we load from json we just need this.\n",
    "\n",
    "# Load main task training data\n",
    "if main == 'davidson':\n",
    "    train, dev, test = TabularDataset.splits(datadir, train = 'davidson_binary_train.json',\n",
    "                                             validation = 'davidson_binary_dev.json',\n",
    "                                             test = 'davidson_binary_test.json',\n",
    "                                             format = 'json', skip_header = True, fields = fields)\n",
    "text.build_vocab(train)\n",
    "label.build_vocab(train)\n",
    "main = {'train': train, 'dev': dev, 'test': test, 'text': text, 'labels': label, 'name': main}\n",
    "\n",
    "# Load aux tasks\n",
    "auxillary = []\n",
    "for aux in auxi:\n",
    "    # Set up fields\n",
    "    text = Field(tokenize = tokenizer, lower = True, batch_first = True)\n",
    "    label = LabelField()\n",
    "    fields = {'text': ('text', text), 'label': ('label', label)}  # Because we load from json we just need this.\n",
    "\n",
    "    if aux == 'davidson':\n",
    "        train, dev, test = TabularDataset.splits(datadir, train = 'davidson_binary_train.json',\n",
    "                                                 validation = 'davidson_binary_dev.json',\n",
    "                                                 test = 'davidson_binary_test.json',\n",
    "                                                 format = 'json', skip_header = True, fields = fields)\n",
    "    elif aux == 'hoover':\n",
    "        train, dev, test = TabularDataset.splits(datadir, train = 'hoover_train.json',\n",
    "                                                 validation = 'hoover_dev.json',\n",
    "                                                 test = 'hoover_test.json',\n",
    "                                                 format = 'json', skip_header = True, fields = fields)\n",
    "    elif aux == 'oraby_factfeel':\n",
    "        train, dev, test = TabularDataset.splits(datadir, train = 'oraby_fact_feel_train.json',\n",
    "                                                 validation = 'oraby_fact_feel_dev.json',\n",
    "                                                 test = 'oraby_fact_feel_test.json',\n",
    "                                                 format = 'json', skip_header = True, fields = fields)\n",
    "    elif aux == 'oraby_sarcasm':\n",
    "        train, dev, test = TabularDataset.splits(datadir, train = 'oraby_sarcasm_train.json',\n",
    "                                                 validation = 'oraby_sarcasm_dev.json',\n",
    "                                                 test = 'oraby_sarcasm_test.json',\n",
    "                                                 format = 'json', skip_header = True, fields = fields)\n",
    "    elif aux == 'waseem':\n",
    "        train, dev, test = TabularDataset.splits(datadir, train = 'waseem_train.json',\n",
    "                                                 validation = 'waseem_dev.json',\n",
    "                                                 test = 'waseem_test.json',\n",
    "                                                 format = 'json', skip_header = True, fields = fields)\n",
    "    elif aux == 'waseem_hovy':\n",
    "        train, dev, test = TabularDataset.splits(datadir, train = 'waseem_hovy_train.json',\n",
    "                                                 validation = 'waseem_hovy_dev.json',\n",
    "                                                 test = 'waseem_hovy_test.json',\n",
    "                                                 format = 'json', skip_header = True, fields = fields)\n",
    "    text.build_vocab(train)\n",
    "    label.build_vocab(train)\n",
    "    auxillary.append({'train': train, 'dev': dev, 'test': test, 'text': text, 'labels': label, 'name': aux})\n",
    "    if len(auxillary) == len(auxi): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'shared_dim': 64, 'batch_first': True, 'hidden_dims': [64, 64], 'input_dims': [18176, 9826], 'output_dims': [2, 4]}\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameters\n",
    "dropout = dropout\n",
    "nonlinearity = nonlinearity\n",
    "learning_rate = learning_rate\n",
    "epochs = epochs\n",
    "batch_size = batch_size\n",
    "batch_count = batches_epoch\n",
    "loss_weights = loss_weights\n",
    "\n",
    "params = dict(shared_dim = shared,\n",
    "              batch_first = True,\n",
    "              hidden_dims = [int(hidden) for hidden in hidden[0].split(',')],\n",
    "              input_dims = [len(main['text'].vocab.stoi)] + [len(aux['text'].vocab.stoi) for aux in auxillary],\n",
    "              output_dims = [len(main['labels'].vocab.stoi)] + [len(aux['labels'].vocab.stoi) for aux in auxillary],\n",
    "              )\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EmbeddingLSTMClassifier(\n",
      "  (all_parameters): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 18176x64]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 9826x64]\n",
      "      (2): Parameter containing: [torch.FloatTensor of size 64x64]\n",
      "      (3): Parameter containing: [torch.FloatTensor of size 64]\n",
      "      (4): Parameter containing: [torch.FloatTensor of size 256x64]\n",
      "      (5): Parameter containing: [torch.FloatTensor of size 256x64]\n",
      "      (6): Parameter containing: [torch.FloatTensor of size 256]\n",
      "      (7): Parameter containing: [torch.FloatTensor of size 256]\n",
      "      (8): Parameter containing: [torch.FloatTensor of size 256x64]\n",
      "      (9): Parameter containing: [torch.FloatTensor of size 256x64]\n",
      "      (10): Parameter containing: [torch.FloatTensor of size 256]\n",
      "      (11): Parameter containing: [torch.FloatTensor of size 256]\n",
      "      (12): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "      (13): Parameter containing: [torch.FloatTensor of size 2]\n",
      "      (14): Parameter containing: [torch.FloatTensor of size 4x64]\n",
      "      (15): Parameter containing: [torch.FloatTensor of size 4]\n",
      "  )\n",
      "  (shared): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (softmax): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if not onehot:\n",
    "    params.update({'embedding_dims': embedding})\n",
    "if model == 'lstm':\n",
    "    params.update({'no_layers': layers})\n",
    "    model = mtl.OnehotLSTMClassifier if onehot else mtl.EmbeddingLSTMClassifier\n",
    "else:\n",
    "    params.update({'non-linearity': nonlinearity})\n",
    "\n",
    "    if model == 'cnn':\n",
    "        params.update({'window_sizes': [int(win) for win in window_sizes[0].split(',')],\n",
    "                       'num_filters': filters})\n",
    "        model = mtl.OnehotCNNClassifier if onehot else mtl.EmbeddingCNNClassifier\n",
    "    elif model == 'mlp':\n",
    "        model = mtl.OnehotMLPClassifier if onehot else mtl.EmbeddingMLPClassifier\n",
    "\n",
    "model = model(**params)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info about losses: https://bit.ly/3irxvYK\n",
    "if loss == 'nlll':\n",
    "    loss = torch.nn.NLLLoss()\n",
    "elif loss == 'crossentropy':\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Set optimizer\n",
    "if optimizer == 'adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "elif optimizer == 'sgd':\n",
    "    optimizer = torch.optim.SGD(model.parameters(), learning_rate)\n",
    "elif optimizer == 'asgd':\n",
    "    optimizer = torch.optim.ASGD(model.parameters(), learning_rate)\n",
    "elif optimizer == 'adamw':\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[    2, 12800,    11,  ...,     1,     1,     1],\n",
       "         [   96,   114,     4,  ...,     1,     1,     1],\n",
       "         [  238,   411,     6,  ...,     1,     1,     1],\n",
       "         ...,\n",
       "         [   32,  7108,   127,  ...,     1,     1,     1],\n",
       "         [   63,  1910,  8765,  ...,     1,     1,     1],\n",
       "         [   12,     2,    32,  ...,     1,     1,     1]]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "         0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch data\n",
    "batchers = []\n",
    "test_batchers = []\n",
    "if not onehot:\n",
    "    train_buckets = BucketIterator(dataset = main['train'], batch_size = batch_size, sort_key = lambda x: len(x))\n",
    "    main_train = TorchtextExtractor('text', 'label', main['name'], train_buckets)\n",
    "    batchers.append(main_train)\n",
    "\n",
    "    dev_buckets = BucketIterator(dataset = main['dev'], batch_size = 64, sort_key = lambda x: len(x))\n",
    "    dev = TorchtextExtractor('text', 'label', main['name'], dev_buckets)\n",
    "\n",
    "    test_buckets = BucketIterator(dataset = main['test'], batch_size = 64, sort_key = lambda x: len(x))\n",
    "    test = TorchtextExtractor('text', 'label', main['name'], test_buckets)\n",
    "    test_batchers.append(test)\n",
    "\n",
    "    for aux in auxillary:\n",
    "        train_buckets = BucketIterator(dataset = aux['train'], batch_size = batch_size, sort_key = lambda x: len(x))\n",
    "        train = TorchtextExtractor('text', 'label', aux['name'], train_buckets)\n",
    "        batchers.append(train)\n",
    "\n",
    "        test_buckets = BucketIterator(dataset = aux['test'], batch_size = 64, sort_key = lambda x: len(x))\n",
    "        test = TorchtextExtractor('text', 'label', aux['name'], test_buckets)\n",
    "        test_batchers.append(test)\n",
    "else:\n",
    "    train_buckets = BucketIterator(dataset = main['train'], batch_size = batch_size, sort_key = lambda x: len(x))\n",
    "    train = TorchtextExtractor('text', 'label', main['name'], train_buckets, len(main['text'].vocab.stoi))\n",
    "    batchers.append(train)\n",
    "\n",
    "    dev_buckets = BucketIterator(dataset = main['dev'], batch_size = 64, sort_key = lambda x: len(x))\n",
    "    dev = TorchtextExtractor('text', 'label', main['name'], dev_buckets, len(main['text'].vocab.stoi))\n",
    "\n",
    "    test_buckets = BucketIterator(dataset = main['test'], batch_size = 64, sort_key = lambda x: len(x))\n",
    "    test = TorchtextExtractor('text', 'label', main['name'], test_buckets)\n",
    "    test_batchers.append(test)\n",
    "\n",
    "    for aux in auxillary:\n",
    "        train_buckets = BucketIterator(dataset = aux['train'], batch_size = batch_size, sort_key = lambda x: len(x))\n",
    "        train = TorchtextExtractor('text', 'label', aux['name'], train_buckets, len(aux['text'].vocab.stoi))\n",
    "        batchers.append(train)\n",
    "\n",
    "        test_buckets = BucketIterator(dataset = aux['test'], batch_size = 64, sort_key = lambda x: len(x))\n",
    "        test = TorchtextExtractor('text', 'label', aux['name'], test_buckets)\n",
    "        test_batchers.append(test)\n",
    "next(iter(batchers[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_writing = dict(mdl_hdr = ['model', 'scores'], batch_writer = csv.writer(open('test', 'w')),\n",
    "                     model_hdr = ['name'], main_name = 'davidson', hyper_info = ['embedding_dim'],\n",
    "                     metric_hdr = ['f1-score'], writer = csv.writer(open('test2', 'w')), data_name = 'davidson')\n",
    "modelling_vars = dict(model = model, batchers = batchers, optimizer = optimizer, loss = loss,\n",
    "                      metrics = metrics, batch_size = batch_size, epochs = epochs, clip = clip,\n",
    "                      early_stopping = patience, save_model = results, dev = dev_buckets, dev_metrics = dev_metrics,\n",
    "                      dev_task_id = 0, batches_per_epoch = batches_epoch, low = False, shuffle = False, \n",
    "                      dataset_weights = None, loss_weights = loss_weights, gpu = False, hyperopt = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s, batch_loss=0.0325, epoch_loss=0.0325, task=1, task_score=0.0312]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:10,  4.63it/s, batch_loss=0.0325, epoch_loss=0.0325, task=1, task_score=0.0312]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:10,  4.63it/s, batch_loss=0.0650, epoch_loss=0.0487, task=0, task_score=0.1302]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:11,  4.29it/s, batch_loss=0.0650, epoch_loss=0.0487, task=0, task_score=0.1302]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:11,  4.29it/s, batch_loss=0.0327, epoch_loss=0.0434, task=1, task_score=0.2193]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:09,  4.76it/s, batch_loss=0.0327, epoch_loss=0.0434, task=1, task_score=0.2193]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:09,  4.76it/s, batch_loss=0.0325, epoch_loss=0.0407, task=1, task_score=0.1793]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:00<00:09,  5.09it/s, batch_loss=0.0325, epoch_loss=0.0407, task=1, task_score=0.1793]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:01<00:09,  5.09it/s, batch_loss=0.0650, epoch_loss=0.0455, task=0, task_score=0.1039]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:08,  5.05it/s, batch_loss=0.0650, epoch_loss=0.0455, task=0, task_score=0.1039]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:08,  5.05it/s, batch_loss=0.0650, epoch_loss=0.0488, task=0, task_score=0.1353]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:08,  5.04it/s, batch_loss=0.0650, epoch_loss=0.0488, task=0, task_score=0.1353]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:08,  5.04it/s, batch_loss=0.0325, epoch_loss=0.0465, task=1, task_score=0.1154]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:07,  5.48it/s, batch_loss=0.0325, epoch_loss=0.0465, task=1, task_score=0.1154]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:07,  5.48it/s, batch_loss=0.0650, epoch_loss=0.0488, task=0, task_score=0.1302]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:01<00:07,  5.36it/s, batch_loss=0.0650, epoch_loss=0.0488, task=0, task_score=0.1302]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:01<00:07,  5.36it/s, batch_loss=0.0650, epoch_loss=0.0506, task=0, task_score=0.4622]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:01<00:07,  5.39it/s, batch_loss=0.0650, epoch_loss=0.0506, task=0, task_score=0.4622]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:01<00:07,  5.39it/s, batch_loss=0.0649, epoch_loss=0.0520, task=0, task_score=0.2471]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:01<00:07,  5.58it/s, batch_loss=0.0649, epoch_loss=0.0520, task=0, task_score=0.2471]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:07,  5.58it/s, batch_loss=0.0649, epoch_loss=0.0532, task=0, task_score=0.2312]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:07,  5.47it/s, batch_loss=0.0649, epoch_loss=0.0532, task=0, task_score=0.2312]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:07,  5.47it/s, batch_loss=0.0650, epoch_loss=0.0542, task=0, task_score=0.1935]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:02<00:06,  5.54it/s, batch_loss=0.0650, epoch_loss=0.0542, task=0, task_score=0.1935]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:02<00:06,  5.54it/s, batch_loss=0.0651, epoch_loss=0.0550, task=0, task_score=0.4286]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:02<00:06,  5.37it/s, batch_loss=0.0651, epoch_loss=0.0550, task=0, task_score=0.4286]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:02<00:06,  5.37it/s, batch_loss=0.0647, epoch_loss=0.0557, task=0, task_score=0.3644]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:02<00:06,  5.47it/s, batch_loss=0.0647, epoch_loss=0.0557, task=0, task_score=0.3644]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:02<00:06,  5.47it/s, batch_loss=0.0326, epoch_loss=0.0542, task=1, task_score=0.2168]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:02<00:06,  5.79it/s, batch_loss=0.0326, epoch_loss=0.0542, task=1, task_score=0.2168]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:02<00:06,  5.79it/s, batch_loss=0.0660, epoch_loss=0.0549, task=0, task_score=0.4483]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:02<00:06,  5.56it/s, batch_loss=0.0660, epoch_loss=0.0549, task=0, task_score=0.4483]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:03<00:06,  5.56it/s, batch_loss=0.0650, epoch_loss=0.0555, task=0, task_score=0.1870]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:03<00:05,  5.55it/s, batch_loss=0.0650, epoch_loss=0.0555, task=0, task_score=0.1870]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:03<00:05,  5.55it/s, batch_loss=0.0325, epoch_loss=0.0542, task=1, task_score=0.2716]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:03<00:05,  5.83it/s, batch_loss=0.0325, epoch_loss=0.0542, task=1, task_score=0.2716]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:03<00:05,  5.83it/s, batch_loss=0.0649, epoch_loss=0.0548, task=0, task_score=0.1672]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:03<00:05,  5.83it/s, batch_loss=0.0649, epoch_loss=0.0548, task=0, task_score=0.1672]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:03<00:05,  5.83it/s, batch_loss=0.0650, epoch_loss=0.0553, task=0, task_score=0.2534]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:03<00:05,  5.64it/s, batch_loss=0.0650, epoch_loss=0.0553, task=0, task_score=0.2534]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:03<00:05,  5.64it/s, batch_loss=0.0651, epoch_loss=0.0558, task=0, task_score=0.0725]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:03<00:05,  5.51it/s, batch_loss=0.0651, epoch_loss=0.0558, task=0, task_score=0.0725]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:04<00:05,  5.51it/s, batch_loss=0.0325, epoch_loss=0.0547, task=1, task_score=0.2013]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:04<00:04,  5.70it/s, batch_loss=0.0325, epoch_loss=0.0547, task=1, task_score=0.2013]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:04<00:04,  5.70it/s, batch_loss=0.0650, epoch_loss=0.0551, task=0, task_score=0.1618]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:04<00:04,  5.53it/s, batch_loss=0.0650, epoch_loss=0.0551, task=0, task_score=0.1618]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:04<00:04,  5.53it/s, batch_loss=0.0649, epoch_loss=0.0556, task=0, task_score=0.1789]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:04<00:04,  5.38it/s, batch_loss=0.0649, epoch_loss=0.0556, task=0, task_score=0.1789]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:04<00:04,  5.38it/s, batch_loss=0.0650, epoch_loss=0.0559, task=0, task_score=0.4913]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:04<00:04,  5.20it/s, batch_loss=0.0650, epoch_loss=0.0559, task=0, task_score=0.4913]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:04<00:04,  5.20it/s, batch_loss=0.0325, epoch_loss=0.0550, task=1, task_score=0.1087]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:04<00:04,  5.63it/s, batch_loss=0.0325, epoch_loss=0.0550, task=1, task_score=0.1087]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:04<00:04,  5.63it/s, batch_loss=0.0650, epoch_loss=0.0554, task=0, task_score=0.1429]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:04<00:04,  5.46it/s, batch_loss=0.0650, epoch_loss=0.0554, task=0, task_score=0.1429]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:05<00:04,  5.46it/s, batch_loss=0.0325, epoch_loss=0.0546, task=1, task_score=0.1146]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:05<00:03,  5.74it/s, batch_loss=0.0325, epoch_loss=0.0546, task=1, task_score=0.1146]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:05<00:03,  5.74it/s, batch_loss=0.0325, epoch_loss=0.0538, task=1, task_score=0.1200]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:05<00:03,  6.12it/s, batch_loss=0.0325, epoch_loss=0.0538, task=1, task_score=0.1200]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:05<00:03,  6.12it/s, batch_loss=0.0324, epoch_loss=0.0531, task=1, task_score=0.1677]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:05<00:03,  6.18it/s, batch_loss=0.0324, epoch_loss=0.0531, task=1, task_score=0.1677]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:05<00:03,  6.18it/s, batch_loss=0.0649, epoch_loss=0.0535, task=0, task_score=0.2014]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:05<00:04,  4.48it/s, batch_loss=0.0649, epoch_loss=0.0535, task=0, task_score=0.2014]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:05<00:04,  4.48it/s, batch_loss=0.0649, epoch_loss=0.0538, task=0, task_score=0.1552]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:05<00:03,  4.80it/s, batch_loss=0.0649, epoch_loss=0.0538, task=0, task_score=0.1552]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:06<00:03,  4.80it/s, batch_loss=0.0653, epoch_loss=0.0542, task=0, task_score=0.1111]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  66%|██████▌   | 33/50 [00:06<00:03,  4.95it/s, batch_loss=0.0653, epoch_loss=0.0542, task=0, task_score=0.1111]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:06<00:03,  4.95it/s, batch_loss=0.0324, epoch_loss=0.0536, task=1, task_score=0.1348]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:06<00:03,  5.26it/s, batch_loss=0.0324, epoch_loss=0.0536, task=1, task_score=0.1348]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:06<00:03,  5.26it/s, batch_loss=0.0322, epoch_loss=0.0529, task=1, task_score=0.2500]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:06<00:02,  5.67it/s, batch_loss=0.0322, epoch_loss=0.0529, task=1, task_score=0.2500]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:06<00:02,  5.67it/s, batch_loss=0.0649, epoch_loss=0.0533, task=0, task_score=0.2123]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:06<00:02,  5.88it/s, batch_loss=0.0649, epoch_loss=0.0533, task=0, task_score=0.2123]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:06<00:02,  5.88it/s, batch_loss=0.0323, epoch_loss=0.0527, task=1, task_score=0.2347]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:06<00:02,  6.04it/s, batch_loss=0.0323, epoch_loss=0.0527, task=1, task_score=0.2347]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:06<00:02,  6.04it/s, batch_loss=0.0650, epoch_loss=0.0530, task=0, task_score=0.2123]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:06<00:02,  5.39it/s, batch_loss=0.0650, epoch_loss=0.0530, task=0, task_score=0.2123]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:07<00:02,  5.39it/s, batch_loss=0.0650, epoch_loss=0.0533, task=0, task_score=0.1903]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:07<00:02,  4.45it/s, batch_loss=0.0650, epoch_loss=0.0533, task=0, task_score=0.1903]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:07<00:02,  4.45it/s, batch_loss=0.0650, epoch_loss=0.0536, task=0, task_score=0.1789]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:07<00:02,  4.37it/s, batch_loss=0.0650, epoch_loss=0.0536, task=0, task_score=0.1789]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:07<00:02,  4.37it/s, batch_loss=0.0650, epoch_loss=0.0539, task=0, task_score=0.4286]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:07<00:02,  4.46it/s, batch_loss=0.0650, epoch_loss=0.0539, task=0, task_score=0.4286]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:07<00:02,  4.46it/s, batch_loss=0.0324, epoch_loss=0.0534, task=1, task_score=0.1971]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:07<00:01,  4.99it/s, batch_loss=0.0324, epoch_loss=0.0534, task=1, task_score=0.1971]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:08<00:01,  4.99it/s, batch_loss=0.0649, epoch_loss=0.0537, task=0, task_score=0.2014]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:08<00:01,  4.05it/s, batch_loss=0.0649, epoch_loss=0.0537, task=0, task_score=0.2014]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:08<00:01,  4.05it/s, batch_loss=0.0324, epoch_loss=0.0532, task=1, task_score=0.2989]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:08<00:01,  4.47it/s, batch_loss=0.0324, epoch_loss=0.0532, task=1, task_score=0.2989]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:08<00:01,  4.47it/s, batch_loss=0.0329, epoch_loss=0.0527, task=1, task_score=0.1092]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:08<00:00,  5.01it/s, batch_loss=0.0329, epoch_loss=0.0527, task=1, task_score=0.1092]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:08<00:00,  5.01it/s, batch_loss=0.0650, epoch_loss=0.0530, task=0, task_score=0.1789]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:08<00:00,  4.83it/s, batch_loss=0.0650, epoch_loss=0.0530, task=0, task_score=0.1789]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:08<00:00,  4.83it/s, batch_loss=0.0323, epoch_loss=0.0526, task=1, task_score=0.2014]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:08<00:00,  5.34it/s, batch_loss=0.0323, epoch_loss=0.0526, task=1, task_score=0.2014]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:09<00:00,  5.34it/s, batch_loss=0.0650, epoch_loss=0.0528, task=0, task_score=0.1172]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:09<00:00,  5.31it/s, batch_loss=0.0650, epoch_loss=0.0528, task=0, task_score=0.1172]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:09<00:00,  5.31it/s, batch_loss=0.0323, epoch_loss=0.0524, task=1, task_score=0.2209]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:09<00:00,  5.70it/s, batch_loss=0.0323, epoch_loss=0.0524, task=1, task_score=0.2209]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:09<00:00,  5.70it/s, batch_loss=0.0326, epoch_loss=0.0520, task=1, task_score=0.1159]\u001b[A\n",
      "Batch: 100%|██████████| 50/50 [00:09<00:00,  5.89it/s, batch_loss=0.0326, epoch_loss=0.0520, task=1, task_score=0.1159]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Evaluating model:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating model:  18%|█▊        | 7/39 [00:00<00:00, 64.49it/s]\u001b[A\n",
      "Evaluating model:  31%|███       | 12/39 [00:00<00:00, 58.95it/s]\u001b[A\n",
      "Evaluating model:  54%|█████▍    | 21/39 [00:00<00:00, 64.32it/s]\u001b[A\n",
      "Evaluating model:  67%|██████▋   | 26/39 [00:00<00:00, 57.11it/s]\u001b[A\n",
      "Evaluating model:  82%|████████▏ | 32/39 [00:00<00:00, 57.10it/s]\u001b[A\n",
      "Evaluating model:  97%|█████████▋| 38/39 [00:00<00:00, 57.55it/s]\u001b[A\n",
      "Training model:  10%|█         | 1/10 [00:10<01:32, 10.22s/it, dev_loss=0.0655, dev_score=0.1657, loss=0.0326]\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s, batch_loss=0.0322, epoch_loss=0.0322, task=1, task_score=0.2689]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:08,  5.64it/s, batch_loss=0.0322, epoch_loss=0.0322, task=1, task_score=0.2689]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:08,  5.64it/s, batch_loss=0.0650, epoch_loss=0.0486, task=0, task_score=0.1172]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:10,  4.80it/s, batch_loss=0.0650, epoch_loss=0.0486, task=0, task_score=0.1172]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:10,  4.80it/s, batch_loss=0.0650, epoch_loss=0.0541, task=0, task_score=0.1903]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:09,  4.91it/s, batch_loss=0.0650, epoch_loss=0.0541, task=0, task_score=0.1903]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:09,  4.91it/s, batch_loss=0.0651, epoch_loss=0.0568, task=0, task_score=0.2014]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:00<00:09,  4.81it/s, batch_loss=0.0651, epoch_loss=0.0568, task=0, task_score=0.2014]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:01<00:09,  4.81it/s, batch_loss=0.0650, epoch_loss=0.0584, task=0, task_score=0.1353]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:08,  5.02it/s, batch_loss=0.0650, epoch_loss=0.0584, task=0, task_score=0.1353]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:08,  5.02it/s, batch_loss=0.0322, epoch_loss=0.0541, task=1, task_score=0.3594]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:07,  5.51it/s, batch_loss=0.0322, epoch_loss=0.0541, task=1, task_score=0.3594]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:07,  5.51it/s, batch_loss=0.0324, epoch_loss=0.0510, task=1, task_score=0.2275]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:07,  5.47it/s, batch_loss=0.0324, epoch_loss=0.0510, task=1, task_score=0.2275]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:07,  5.47it/s, batch_loss=0.0321, epoch_loss=0.0486, task=1, task_score=0.2321]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:01<00:07,  5.60it/s, batch_loss=0.0321, epoch_loss=0.0486, task=1, task_score=0.2321]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:01<00:07,  5.60it/s, batch_loss=0.0322, epoch_loss=0.0468, task=1, task_score=0.2624]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:01<00:07,  5.63it/s, batch_loss=0.0322, epoch_loss=0.0468, task=1, task_score=0.2624]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:02<00:07,  5.63it/s, batch_loss=0.0650, epoch_loss=0.0486, task=0, task_score=0.1672]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:09,  4.38it/s, batch_loss=0.0650, epoch_loss=0.0486, task=0, task_score=0.1672]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:09,  4.38it/s, batch_loss=0.0649, epoch_loss=0.0501, task=0, task_score=0.2508]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:08,  4.60it/s, batch_loss=0.0649, epoch_loss=0.0501, task=0, task_score=0.2508]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:08,  4.60it/s, batch_loss=0.0322, epoch_loss=0.0486, task=1, task_score=0.3436]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:02<00:07,  4.86it/s, batch_loss=0.0322, epoch_loss=0.0486, task=1, task_score=0.3436]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:02<00:07,  4.86it/s, batch_loss=0.0650, epoch_loss=0.0499, task=0, task_score=0.1429]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  26%|██▌       | 13/50 [00:02<00:08,  4.55it/s, batch_loss=0.0650, epoch_loss=0.0499, task=0, task_score=0.1429]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:02<00:08,  4.55it/s, batch_loss=0.0320, epoch_loss=0.0486, task=1, task_score=0.2534]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:02<00:07,  4.82it/s, batch_loss=0.0320, epoch_loss=0.0486, task=1, task_score=0.2534]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:03<00:07,  4.82it/s, batch_loss=0.0650, epoch_loss=0.0497, task=0, task_score=0.1789]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:07,  4.68it/s, batch_loss=0.0650, epoch_loss=0.0497, task=0, task_score=0.1789]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:07,  4.68it/s, batch_loss=0.0650, epoch_loss=0.0506, task=0, task_score=0.1039]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:03<00:07,  4.54it/s, batch_loss=0.0650, epoch_loss=0.0506, task=0, task_score=0.1039]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:03<00:07,  4.54it/s, batch_loss=0.0324, epoch_loss=0.0496, task=1, task_score=0.1922]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:03<00:06,  4.77it/s, batch_loss=0.0324, epoch_loss=0.0496, task=1, task_score=0.1922]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:03<00:06,  4.77it/s, batch_loss=0.0650, epoch_loss=0.0504, task=0, task_score=0.1672]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:03<00:08,  3.75it/s, batch_loss=0.0650, epoch_loss=0.0504, task=0, task_score=0.1672]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:04<00:08,  3.75it/s, batch_loss=0.0650, epoch_loss=0.0512, task=0, task_score=0.1172]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:04<00:10,  3.09it/s, batch_loss=0.0650, epoch_loss=0.0512, task=0, task_score=0.1172]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:04<00:10,  3.09it/s, batch_loss=0.0650, epoch_loss=0.0519, task=0, task_score=0.1789]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:04<00:08,  3.45it/s, batch_loss=0.0650, epoch_loss=0.0519, task=0, task_score=0.1789]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:04<00:08,  3.45it/s, batch_loss=0.0649, epoch_loss=0.0525, task=0, task_score=0.1618]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:04<00:07,  3.90it/s, batch_loss=0.0649, epoch_loss=0.0525, task=0, task_score=0.1618]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:04<00:07,  3.90it/s, batch_loss=0.0320, epoch_loss=0.0516, task=1, task_score=0.3010]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:04<00:06,  4.26it/s, batch_loss=0.0320, epoch_loss=0.0516, task=1, task_score=0.3010]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:05<00:06,  4.26it/s, batch_loss=0.0319, epoch_loss=0.0507, task=1, task_score=0.3348]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:05<00:05,  4.59it/s, batch_loss=0.0319, epoch_loss=0.0507, task=1, task_score=0.3348]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:05<00:05,  4.59it/s, batch_loss=0.0316, epoch_loss=0.0499, task=1, task_score=0.3229]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:05<00:05,  4.59it/s, batch_loss=0.0316, epoch_loss=0.0499, task=1, task_score=0.3229]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:05<00:05,  4.59it/s, batch_loss=0.0321, epoch_loss=0.0492, task=1, task_score=0.2360]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:05<00:05,  4.78it/s, batch_loss=0.0321, epoch_loss=0.0492, task=1, task_score=0.2360]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:05<00:05,  4.78it/s, batch_loss=0.0324, epoch_loss=0.0486, task=1, task_score=0.2974]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:05<00:04,  4.96it/s, batch_loss=0.0324, epoch_loss=0.0486, task=1, task_score=0.2974]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:05<00:04,  4.96it/s, batch_loss=0.0649, epoch_loss=0.0492, task=0, task_score=0.2111]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:05<00:05,  4.51it/s, batch_loss=0.0649, epoch_loss=0.0492, task=0, task_score=0.2111]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:06<00:05,  4.51it/s, batch_loss=0.0316, epoch_loss=0.0485, task=1, task_score=0.3356]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:06<00:04,  4.60it/s, batch_loss=0.0316, epoch_loss=0.0485, task=1, task_score=0.3356]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:06<00:04,  4.60it/s, batch_loss=0.0649, epoch_loss=0.0491, task=0, task_score=0.2014]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:06<00:04,  4.88it/s, batch_loss=0.0649, epoch_loss=0.0491, task=0, task_score=0.2014]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:06<00:04,  4.88it/s, batch_loss=0.0316, epoch_loss=0.0485, task=1, task_score=0.2536]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:06<00:03,  5.13it/s, batch_loss=0.0316, epoch_loss=0.0485, task=1, task_score=0.2536]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:06<00:03,  5.13it/s, batch_loss=0.0652, epoch_loss=0.0491, task=0, task_score=0.1111]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:06<00:03,  4.92it/s, batch_loss=0.0652, epoch_loss=0.0491, task=0, task_score=0.1111]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:06<00:03,  4.92it/s, batch_loss=0.0670, epoch_loss=0.0493, task=1, task_score=0.3929]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:06<00:03,  5.59it/s, batch_loss=0.0670, epoch_loss=0.0493, task=1, task_score=0.3929]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:07<00:03,  5.59it/s, batch_loss=0.0649, epoch_loss=0.0497, task=0, task_score=0.1672]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:07<00:03,  5.15it/s, batch_loss=0.0649, epoch_loss=0.0497, task=0, task_score=0.1672]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:07<00:03,  5.15it/s, batch_loss=0.0319, epoch_loss=0.0492, task=1, task_score=0.3441]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:07<00:02,  5.34it/s, batch_loss=0.0319, epoch_loss=0.0492, task=1, task_score=0.3441]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:07<00:02,  5.34it/s, batch_loss=0.0314, epoch_loss=0.0487, task=1, task_score=0.3720]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:07<00:02,  5.41it/s, batch_loss=0.0314, epoch_loss=0.0487, task=1, task_score=0.3720]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:07<00:02,  5.41it/s, batch_loss=0.0323, epoch_loss=0.0482, task=1, task_score=0.3008]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:07<00:02,  5.28it/s, batch_loss=0.0323, epoch_loss=0.0482, task=1, task_score=0.3008]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:07<00:02,  5.28it/s, batch_loss=0.0317, epoch_loss=0.0478, task=1, task_score=0.2641]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:07<00:02,  5.31it/s, batch_loss=0.0317, epoch_loss=0.0478, task=1, task_score=0.2641]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:08<00:02,  5.31it/s, batch_loss=0.0650, epoch_loss=0.0482, task=0, task_score=0.1488]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:08<00:02,  4.87it/s, batch_loss=0.0650, epoch_loss=0.0482, task=0, task_score=0.1488]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:08<00:02,  4.87it/s, batch_loss=0.0322, epoch_loss=0.0478, task=1, task_score=0.2409]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:08<00:02,  5.06it/s, batch_loss=0.0322, epoch_loss=0.0478, task=1, task_score=0.2409]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:08<00:02,  5.06it/s, batch_loss=0.0650, epoch_loss=0.0482, task=0, task_score=0.1353]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:08<00:02,  4.80it/s, batch_loss=0.0650, epoch_loss=0.0482, task=0, task_score=0.1353]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:08<00:02,  4.80it/s, batch_loss=0.0650, epoch_loss=0.0487, task=0, task_score=0.1429]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:08<00:02,  4.42it/s, batch_loss=0.0650, epoch_loss=0.0487, task=0, task_score=0.1429]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:08<00:02,  4.42it/s, batch_loss=0.0651, epoch_loss=0.0491, task=0, task_score=0.1903]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:08<00:01,  4.51it/s, batch_loss=0.0651, epoch_loss=0.0491, task=0, task_score=0.1903]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:09<00:01,  4.51it/s, batch_loss=0.0315, epoch_loss=0.0486, task=1, task_score=0.3191]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:09<00:01,  4.78it/s, batch_loss=0.0315, epoch_loss=0.0486, task=1, task_score=0.3191]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:09<00:01,  4.78it/s, batch_loss=0.0322, epoch_loss=0.0483, task=1, task_score=0.3132]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:09<00:01,  4.91it/s, batch_loss=0.0322, epoch_loss=0.0483, task=1, task_score=0.3132]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:09<00:01,  4.91it/s, batch_loss=0.0650, epoch_loss=0.0486, task=0, task_score=0.1672]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:09<00:01,  4.66it/s, batch_loss=0.0650, epoch_loss=0.0486, task=0, task_score=0.1672]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:09<00:01,  4.66it/s, batch_loss=0.0313, epoch_loss=0.0483, task=1, task_score=0.3217]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  92%|█████████▏| 46/50 [00:09<00:00,  4.71it/s, batch_loss=0.0313, epoch_loss=0.0483, task=1, task_score=0.3217]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:09<00:00,  4.71it/s, batch_loss=0.0316, epoch_loss=0.0479, task=1, task_score=0.4236]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:09<00:00,  4.97it/s, batch_loss=0.0316, epoch_loss=0.0479, task=1, task_score=0.4236]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:10<00:00,  4.97it/s, batch_loss=0.0317, epoch_loss=0.0476, task=1, task_score=0.3692]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:10<00:00,  5.07it/s, batch_loss=0.0317, epoch_loss=0.0476, task=1, task_score=0.3692]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:10<00:00,  5.07it/s, batch_loss=0.0650, epoch_loss=0.0479, task=0, task_score=0.1353]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:10<00:00,  4.44it/s, batch_loss=0.0650, epoch_loss=0.0479, task=0, task_score=0.1353]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:10<00:00,  4.44it/s, batch_loss=0.0650, epoch_loss=0.0483, task=0, task_score=0.1672]\u001b[A\n",
      "Batch: 100%|██████████| 50/50 [00:10<00:00,  4.44it/s, batch_loss=0.0650, epoch_loss=0.0483, task=0, task_score=0.1672]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Evaluating model:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating model:  10%|█         | 4/39 [00:00<00:00, 39.26it/s]\u001b[A\n",
      "Evaluating model:  21%|██        | 8/39 [00:00<00:00, 34.80it/s]\u001b[A\n",
      "Evaluating model:  36%|███▌      | 14/39 [00:00<00:00, 39.24it/s]\u001b[A\n",
      "Evaluating model:  49%|████▊     | 19/39 [00:00<00:00, 41.47it/s]\u001b[A\n",
      "Evaluating model:  64%|██████▍   | 25/39 [00:00<00:00, 45.03it/s]\u001b[A\n",
      "Evaluating model:  82%|████████▏ | 32/39 [00:00<00:00, 49.25it/s]\u001b[A\n",
      "Evaluating model:  95%|█████████▍| 37/39 [00:00<00:00, 48.85it/s]\u001b[A\n",
      "Training model:  20%|██        | 2/10 [00:21<01:25, 10.63s/it, dev_loss=0.0654, dev_score=0.1647, loss=0.0650]\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s, batch_loss=0.0649, epoch_loss=0.0649, task=0, task_score=0.2534]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:09,  4.98it/s, batch_loss=0.0649, epoch_loss=0.0649, task=0, task_score=0.2534]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:09,  4.98it/s, batch_loss=0.0650, epoch_loss=0.0649, task=0, task_score=0.1903]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:09,  4.94it/s, batch_loss=0.0650, epoch_loss=0.0649, task=0, task_score=0.1903]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:09,  4.94it/s, batch_loss=0.0650, epoch_loss=0.0650, task=0, task_score=0.1039]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:09,  4.74it/s, batch_loss=0.0650, epoch_loss=0.0650, task=0, task_score=0.1039]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:09,  4.74it/s, batch_loss=0.0319, epoch_loss=0.0567, task=1, task_score=0.2786]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:00<00:09,  4.98it/s, batch_loss=0.0319, epoch_loss=0.0567, task=1, task_score=0.2786]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:01<00:09,  4.98it/s, batch_loss=0.0319, epoch_loss=0.0517, task=1, task_score=0.2635]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:09,  4.96it/s, batch_loss=0.0319, epoch_loss=0.0517, task=1, task_score=0.2635]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:09,  4.96it/s, batch_loss=0.0322, epoch_loss=0.0485, task=1, task_score=0.2672]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:08,  5.06it/s, batch_loss=0.0322, epoch_loss=0.0485, task=1, task_score=0.2672]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:08,  5.06it/s, batch_loss=0.0649, epoch_loss=0.0508, task=0, task_score=0.1789]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:08,  5.00it/s, batch_loss=0.0649, epoch_loss=0.0508, task=0, task_score=0.1789]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:08,  5.00it/s, batch_loss=0.0649, epoch_loss=0.0526, task=0, task_score=0.1672]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:01<00:08,  5.14it/s, batch_loss=0.0649, epoch_loss=0.0526, task=0, task_score=0.1672]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:01<00:08,  5.14it/s, batch_loss=0.0649, epoch_loss=0.0540, task=0, task_score=0.1903]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:01<00:08,  5.12it/s, batch_loss=0.0649, epoch_loss=0.0540, task=0, task_score=0.1903]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:02<00:08,  5.12it/s, batch_loss=0.0649, epoch_loss=0.0551, task=0, task_score=0.1903]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:08,  4.95it/s, batch_loss=0.0649, epoch_loss=0.0551, task=0, task_score=0.1903]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:08,  4.95it/s, batch_loss=0.0316, epoch_loss=0.0529, task=1, task_score=0.3588]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:07,  5.17it/s, batch_loss=0.0316, epoch_loss=0.0529, task=1, task_score=0.3588]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:07,  5.17it/s, batch_loss=0.0308, epoch_loss=0.0511, task=1, task_score=0.4845]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:02<00:07,  5.30it/s, batch_loss=0.0308, epoch_loss=0.0511, task=1, task_score=0.4845]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:02<00:07,  5.30it/s, batch_loss=0.0317, epoch_loss=0.0496, task=1, task_score=0.3277]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:02<00:06,  5.58it/s, batch_loss=0.0317, epoch_loss=0.0496, task=1, task_score=0.3277]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:02<00:06,  5.58it/s, batch_loss=0.0311, epoch_loss=0.0483, task=1, task_score=0.3656]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:02<00:06,  5.39it/s, batch_loss=0.0311, epoch_loss=0.0483, task=1, task_score=0.3656]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:02<00:06,  5.39it/s, batch_loss=0.0311, epoch_loss=0.0471, task=1, task_score=0.3812]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:02<00:06,  5.53it/s, batch_loss=0.0311, epoch_loss=0.0471, task=1, task_score=0.3812]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:06,  5.53it/s, batch_loss=0.0649, epoch_loss=0.0482, task=0, task_score=0.2327]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:03<00:06,  5.06it/s, batch_loss=0.0649, epoch_loss=0.0482, task=0, task_score=0.2327]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:03<00:06,  5.06it/s, batch_loss=0.0321, epoch_loss=0.0473, task=1, task_score=0.2605]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:03<00:06,  4.77it/s, batch_loss=0.0321, epoch_loss=0.0473, task=1, task_score=0.2605]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:03<00:06,  4.77it/s, batch_loss=0.0650, epoch_loss=0.0483, task=0, task_score=0.1552]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:03<00:07,  4.32it/s, batch_loss=0.0650, epoch_loss=0.0483, task=0, task_score=0.1552]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:03<00:07,  4.32it/s, batch_loss=0.0319, epoch_loss=0.0474, task=1, task_score=0.4006]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:03<00:06,  4.69it/s, batch_loss=0.0319, epoch_loss=0.0474, task=1, task_score=0.4006]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:03<00:06,  4.69it/s, batch_loss=0.0320, epoch_loss=0.0466, task=1, task_score=0.3304]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:03<00:05,  5.00it/s, batch_loss=0.0320, epoch_loss=0.0466, task=1, task_score=0.3304]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:04<00:05,  5.00it/s, batch_loss=0.0319, epoch_loss=0.0459, task=1, task_score=0.3235]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:04<00:05,  5.22it/s, batch_loss=0.0319, epoch_loss=0.0459, task=1, task_score=0.3235]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:04<00:05,  5.22it/s, batch_loss=0.0649, epoch_loss=0.0468, task=0, task_score=0.1302]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:04<00:05,  4.74it/s, batch_loss=0.0649, epoch_loss=0.0468, task=0, task_score=0.1302]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:04<00:05,  4.74it/s, batch_loss=0.0316, epoch_loss=0.0461, task=1, task_score=0.3510]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:04<00:05,  5.00it/s, batch_loss=0.0316, epoch_loss=0.0461, task=1, task_score=0.3510]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:04<00:05,  5.00it/s, batch_loss=0.0650, epoch_loss=0.0469, task=0, task_score=0.1429]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:04<00:06,  3.81it/s, batch_loss=0.0650, epoch_loss=0.0469, task=0, task_score=0.1429]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:05<00:06,  3.81it/s, batch_loss=0.0649, epoch_loss=0.0476, task=0, task_score=0.1668]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:05<00:06,  4.01it/s, batch_loss=0.0649, epoch_loss=0.0476, task=0, task_score=0.1668]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:05<00:06,  4.01it/s, batch_loss=0.0650, epoch_loss=0.0483, task=0, task_score=0.1429]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  52%|█████▏    | 26/50 [00:05<00:06,  3.61it/s, batch_loss=0.0650, epoch_loss=0.0483, task=0, task_score=0.1429]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:05<00:06,  3.61it/s, batch_loss=0.0320, epoch_loss=0.0477, task=1, task_score=0.3170]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:05<00:05,  3.89it/s, batch_loss=0.0320, epoch_loss=0.0477, task=1, task_score=0.3170]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:05<00:05,  3.89it/s, batch_loss=0.0319, epoch_loss=0.0471, task=1, task_score=0.3247]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:05<00:05,  4.05it/s, batch_loss=0.0319, epoch_loss=0.0471, task=1, task_score=0.3247]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:06<00:05,  4.05it/s, batch_loss=0.0311, epoch_loss=0.0466, task=1, task_score=0.4237]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:06<00:05,  3.69it/s, batch_loss=0.0311, epoch_loss=0.0466, task=1, task_score=0.4237]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:06<00:05,  3.69it/s, batch_loss=0.0650, epoch_loss=0.0472, task=0, task_score=0.1552]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:06<00:05,  3.84it/s, batch_loss=0.0650, epoch_loss=0.0472, task=0, task_score=0.1552]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:06<00:05,  3.84it/s, batch_loss=0.0321, epoch_loss=0.0467, task=1, task_score=0.3050]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:06<00:04,  4.17it/s, batch_loss=0.0321, epoch_loss=0.0467, task=1, task_score=0.3050]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:06<00:04,  4.17it/s, batch_loss=0.0327, epoch_loss=0.0463, task=1, task_score=0.2645]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:06<00:04,  4.44it/s, batch_loss=0.0327, epoch_loss=0.0463, task=1, task_score=0.2645]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:07<00:04,  4.44it/s, batch_loss=0.0649, epoch_loss=0.0468, task=0, task_score=0.1672]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:07<00:04,  4.14it/s, batch_loss=0.0649, epoch_loss=0.0468, task=0, task_score=0.1672]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:08<00:04,  4.14it/s, batch_loss=0.0650, epoch_loss=0.0474, task=0, task_score=0.1672]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:08<00:08,  1.79it/s, batch_loss=0.0650, epoch_loss=0.0474, task=0, task_score=0.1672]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:08<00:08,  1.79it/s, batch_loss=0.0320, epoch_loss=0.0469, task=1, task_score=0.3640]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:08<00:06,  2.24it/s, batch_loss=0.0320, epoch_loss=0.0469, task=1, task_score=0.3640]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:09<00:06,  2.24it/s, batch_loss=0.0654, epoch_loss=0.0474, task=0, task_score=0.1688]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:09<00:05,  2.37it/s, batch_loss=0.0654, epoch_loss=0.0474, task=0, task_score=0.1688]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:09<00:05,  2.37it/s, batch_loss=0.0324, epoch_loss=0.0470, task=1, task_score=0.2851]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:09<00:04,  2.77it/s, batch_loss=0.0324, epoch_loss=0.0470, task=1, task_score=0.2851]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:09<00:04,  2.77it/s, batch_loss=0.0322, epoch_loss=0.0467, task=1, task_score=0.2755]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:09<00:03,  3.31it/s, batch_loss=0.0322, epoch_loss=0.0467, task=1, task_score=0.2755]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:09<00:03,  3.31it/s, batch_loss=0.0650, epoch_loss=0.0471, task=0, task_score=0.2014]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:09<00:03,  3.54it/s, batch_loss=0.0650, epoch_loss=0.0471, task=0, task_score=0.2014]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:09<00:03,  3.54it/s, batch_loss=0.0650, epoch_loss=0.0476, task=0, task_score=0.1789]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:09<00:02,  3.66it/s, batch_loss=0.0650, epoch_loss=0.0476, task=0, task_score=0.1789]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:10<00:02,  3.66it/s, batch_loss=0.0315, epoch_loss=0.0472, task=1, task_score=0.3289]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:10<00:02,  4.02it/s, batch_loss=0.0315, epoch_loss=0.0472, task=1, task_score=0.3289]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:10<00:02,  4.02it/s, batch_loss=0.0322, epoch_loss=0.0468, task=1, task_score=0.3179]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:10<00:01,  4.24it/s, batch_loss=0.0322, epoch_loss=0.0468, task=1, task_score=0.3179]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:10<00:01,  4.24it/s, batch_loss=0.0650, epoch_loss=0.0472, task=0, task_score=0.1172]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:10<00:01,  4.47it/s, batch_loss=0.0650, epoch_loss=0.0472, task=0, task_score=0.1172]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:10<00:01,  4.47it/s, batch_loss=0.0317, epoch_loss=0.0469, task=1, task_score=0.3063]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:10<00:01,  4.80it/s, batch_loss=0.0317, epoch_loss=0.0469, task=1, task_score=0.3063]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:10<00:01,  4.80it/s, batch_loss=0.0325, epoch_loss=0.0466, task=1, task_score=0.2248]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:10<00:01,  4.81it/s, batch_loss=0.0325, epoch_loss=0.0466, task=1, task_score=0.2248]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:11<00:01,  4.81it/s, batch_loss=0.0655, epoch_loss=0.0470, task=0, task_score=0.1789]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:11<00:00,  4.50it/s, batch_loss=0.0655, epoch_loss=0.0470, task=0, task_score=0.1789]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:11<00:00,  4.50it/s, batch_loss=0.0321, epoch_loss=0.0467, task=1, task_score=0.2537]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:11<00:00,  4.52it/s, batch_loss=0.0321, epoch_loss=0.0467, task=1, task_score=0.2537]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:11<00:00,  4.52it/s, batch_loss=0.0320, epoch_loss=0.0464, task=1, task_score=0.3232]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:11<00:00,  4.73it/s, batch_loss=0.0320, epoch_loss=0.0464, task=1, task_score=0.3232]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:11<00:00,  4.73it/s, batch_loss=0.0319, epoch_loss=0.0461, task=1, task_score=0.3197]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:11<00:00,  4.80it/s, batch_loss=0.0319, epoch_loss=0.0461, task=1, task_score=0.3197]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:11<00:00,  4.80it/s, batch_loss=0.0317, epoch_loss=0.0458, task=1, task_score=0.4321]\u001b[A\n",
      "Batch: 100%|██████████| 50/50 [00:11<00:00,  4.76it/s, batch_loss=0.0317, epoch_loss=0.0458, task=1, task_score=0.4321]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Evaluating model:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating model:  13%|█▎        | 5/39 [00:00<00:00, 48.67it/s]\u001b[A\n",
      "Evaluating model:  26%|██▌       | 10/39 [00:00<00:00, 47.99it/s]\u001b[A\n",
      "Evaluating model:  38%|███▊      | 15/39 [00:00<00:00, 46.00it/s]\u001b[A\n",
      "Evaluating model:  51%|█████▏    | 20/39 [00:00<00:00, 45.42it/s]\u001b[A\n",
      "Evaluating model:  67%|██████▋   | 26/39 [00:00<00:00, 42.82it/s]\u001b[A\n",
      "Evaluating model:  77%|███████▋  | 30/39 [00:00<00:00, 41.53it/s]\u001b[A\n",
      "Evaluating model:  90%|████████▉ | 35/39 [00:00<00:00, 42.28it/s]\u001b[A\n",
      "Training model:  30%|███       | 3/10 [00:34<01:19, 11.34s/it, dev_loss=0.0653, dev_score=0.3629, loss=0.0317]\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s, batch_loss=0.0650, epoch_loss=0.0650, task=0, task_score=0.1172]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:08,  5.64it/s, batch_loss=0.0650, epoch_loss=0.0650, task=0, task_score=0.1172]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:08,  5.64it/s, batch_loss=0.0324, epoch_loss=0.0487, task=1, task_score=0.2696]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:08,  5.67it/s, batch_loss=0.0324, epoch_loss=0.0487, task=1, task_score=0.2696]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:08,  5.67it/s, batch_loss=0.0650, epoch_loss=0.0541, task=0, task_score=0.1552]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:11,  4.20it/s, batch_loss=0.0650, epoch_loss=0.0541, task=0, task_score=0.1552]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:11,  4.20it/s, batch_loss=0.0313, epoch_loss=0.0484, task=1, task_score=0.4538]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:00<00:09,  4.61it/s, batch_loss=0.0313, epoch_loss=0.0484, task=1, task_score=0.4538]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:01<00:09,  4.61it/s, batch_loss=0.0651, epoch_loss=0.0517, task=0, task_score=0.4530]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:11,  4.01it/s, batch_loss=0.0651, epoch_loss=0.0517, task=0, task_score=0.4530]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:11,  4.01it/s, batch_loss=0.0650, epoch_loss=0.0539, task=0, task_score=0.1552]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  12%|█▏        | 6/50 [00:01<00:10,  4.00it/s, batch_loss=0.0650, epoch_loss=0.0539, task=0, task_score=0.1552]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:10,  4.00it/s, batch_loss=0.0314, epoch_loss=0.0507, task=1, task_score=0.4829]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:09,  4.31it/s, batch_loss=0.0314, epoch_loss=0.0507, task=1, task_score=0.4829]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:09,  4.31it/s, batch_loss=0.0650, epoch_loss=0.0525, task=0, task_score=0.2014]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:01<00:09,  4.37it/s, batch_loss=0.0650, epoch_loss=0.0525, task=0, task_score=0.2014]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:02<00:09,  4.37it/s, batch_loss=0.0312, epoch_loss=0.0501, task=1, task_score=0.3744]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:02<00:09,  4.55it/s, batch_loss=0.0312, epoch_loss=0.0501, task=1, task_score=0.3744]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:02<00:09,  4.55it/s, batch_loss=0.0650, epoch_loss=0.0516, task=0, task_score=0.1903]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:08,  4.57it/s, batch_loss=0.0650, epoch_loss=0.0516, task=0, task_score=0.1903]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:08,  4.57it/s, batch_loss=0.0650, epoch_loss=0.0528, task=0, task_score=0.4530]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:09,  4.30it/s, batch_loss=0.0650, epoch_loss=0.0528, task=0, task_score=0.4530]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:09,  4.30it/s, batch_loss=0.0316, epoch_loss=0.0511, task=1, task_score=0.3567]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:02<00:08,  4.66it/s, batch_loss=0.0316, epoch_loss=0.0511, task=1, task_score=0.3567]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:02<00:08,  4.66it/s, batch_loss=0.0648, epoch_loss=0.0521, task=0, task_score=0.5091]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:02<00:07,  4.64it/s, batch_loss=0.0648, epoch_loss=0.0521, task=0, task_score=0.5091]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:03<00:07,  4.64it/s, batch_loss=0.0650, epoch_loss=0.0530, task=0, task_score=0.4622]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:03<00:09,  3.68it/s, batch_loss=0.0650, epoch_loss=0.0530, task=0, task_score=0.4622]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:03<00:09,  3.68it/s, batch_loss=0.0316, epoch_loss=0.0516, task=1, task_score=0.4210]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:08,  4.09it/s, batch_loss=0.0316, epoch_loss=0.0516, task=1, task_score=0.4210]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:08,  4.09it/s, batch_loss=0.0317, epoch_loss=0.0504, task=1, task_score=0.3187]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:03<00:07,  4.46it/s, batch_loss=0.0317, epoch_loss=0.0504, task=1, task_score=0.3187]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:04<00:07,  4.46it/s, batch_loss=0.0649, epoch_loss=0.0512, task=0, task_score=0.2229]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:04<00:08,  3.81it/s, batch_loss=0.0649, epoch_loss=0.0512, task=0, task_score=0.2229]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:04<00:08,  3.81it/s, batch_loss=0.0650, epoch_loss=0.0520, task=0, task_score=0.1429]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:04<00:10,  2.98it/s, batch_loss=0.0650, epoch_loss=0.0520, task=0, task_score=0.1429]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:04<00:10,  2.98it/s, batch_loss=0.0315, epoch_loss=0.0509, task=1, task_score=0.3511]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:04<00:08,  3.50it/s, batch_loss=0.0315, epoch_loss=0.0509, task=1, task_score=0.3511]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:04<00:08,  3.50it/s, batch_loss=0.0315, epoch_loss=0.0499, task=1, task_score=0.4619]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:04<00:07,  3.77it/s, batch_loss=0.0315, epoch_loss=0.0499, task=1, task_score=0.4619]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:05<00:07,  3.77it/s, batch_loss=0.0319, epoch_loss=0.0491, task=1, task_score=0.3374]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:05<00:06,  4.20it/s, batch_loss=0.0319, epoch_loss=0.0491, task=1, task_score=0.3374]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:05<00:06,  4.20it/s, batch_loss=0.0317, epoch_loss=0.0483, task=1, task_score=0.4238]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:05<00:06,  4.25it/s, batch_loss=0.0317, epoch_loss=0.0483, task=1, task_score=0.4238]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:05<00:06,  4.25it/s, batch_loss=0.0318, epoch_loss=0.0476, task=1, task_score=0.3410]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:05<00:06,  4.33it/s, batch_loss=0.0318, epoch_loss=0.0476, task=1, task_score=0.3410]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:05<00:06,  4.33it/s, batch_loss=0.0311, epoch_loss=0.0469, task=1, task_score=0.3533]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:05<00:05,  4.57it/s, batch_loss=0.0311, epoch_loss=0.0469, task=1, task_score=0.3533]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:06<00:05,  4.57it/s, batch_loss=0.0650, epoch_loss=0.0476, task=0, task_score=0.1552]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:06<00:06,  3.93it/s, batch_loss=0.0650, epoch_loss=0.0476, task=0, task_score=0.1552]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:06<00:06,  3.93it/s, batch_loss=0.0651, epoch_loss=0.0483, task=0, task_score=0.4483]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:06<00:06,  3.84it/s, batch_loss=0.0651, epoch_loss=0.0483, task=0, task_score=0.4483]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:06<00:06,  3.84it/s, batch_loss=0.0310, epoch_loss=0.0476, task=1, task_score=0.4807]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:06<00:05,  4.13it/s, batch_loss=0.0310, epoch_loss=0.0476, task=1, task_score=0.4807]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:06<00:05,  4.13it/s, batch_loss=0.0649, epoch_loss=0.0483, task=0, task_score=0.1903]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:06<00:05,  4.17it/s, batch_loss=0.0649, epoch_loss=0.0483, task=0, task_score=0.1903]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:07<00:05,  4.17it/s, batch_loss=0.0650, epoch_loss=0.0488, task=0, task_score=0.4483]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:07<00:04,  4.29it/s, batch_loss=0.0650, epoch_loss=0.0488, task=0, task_score=0.4483]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:07<00:04,  4.29it/s, batch_loss=0.0319, epoch_loss=0.0483, task=1, task_score=0.4086]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:07<00:04,  4.51it/s, batch_loss=0.0319, epoch_loss=0.0483, task=1, task_score=0.4086]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:07<00:04,  4.51it/s, batch_loss=0.0316, epoch_loss=0.0477, task=1, task_score=0.2886]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:07<00:03,  4.78it/s, batch_loss=0.0316, epoch_loss=0.0477, task=1, task_score=0.2886]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:07<00:03,  4.78it/s, batch_loss=0.0649, epoch_loss=0.0483, task=0, task_score=0.2014]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:07<00:04,  4.33it/s, batch_loss=0.0649, epoch_loss=0.0483, task=0, task_score=0.2014]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:07<00:04,  4.33it/s, batch_loss=0.0308, epoch_loss=0.0477, task=1, task_score=0.4725]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:07<00:03,  4.61it/s, batch_loss=0.0308, epoch_loss=0.0477, task=1, task_score=0.4725]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:08<00:03,  4.61it/s, batch_loss=0.0316, epoch_loss=0.0473, task=1, task_score=0.2804]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:08<00:03,  4.84it/s, batch_loss=0.0316, epoch_loss=0.0473, task=1, task_score=0.2804]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:08<00:03,  4.84it/s, batch_loss=0.0650, epoch_loss=0.0478, task=0, task_score=0.1429]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:08<00:03,  4.53it/s, batch_loss=0.0650, epoch_loss=0.0478, task=0, task_score=0.1429]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:08<00:03,  4.53it/s, batch_loss=0.0315, epoch_loss=0.0473, task=1, task_score=0.3253]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:08<00:03,  4.61it/s, batch_loss=0.0315, epoch_loss=0.0473, task=1, task_score=0.3253]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:08<00:03,  4.61it/s, batch_loss=0.0650, epoch_loss=0.0478, task=0, task_score=0.2111]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:08<00:02,  4.56it/s, batch_loss=0.0650, epoch_loss=0.0478, task=0, task_score=0.2111]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:08<00:02,  4.56it/s, batch_loss=0.0651, epoch_loss=0.0483, task=0, task_score=0.5365]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:08<00:02,  4.69it/s, batch_loss=0.0651, epoch_loss=0.0483, task=0, task_score=0.5365]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:09<00:02,  4.69it/s, batch_loss=0.0654, epoch_loss=0.0487, task=0, task_score=0.1467]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  78%|███████▊  | 39/50 [00:09<00:02,  4.52it/s, batch_loss=0.0654, epoch_loss=0.0487, task=0, task_score=0.1467]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:09<00:02,  4.52it/s, batch_loss=0.0650, epoch_loss=0.0491, task=0, task_score=0.1672]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:09<00:02,  4.44it/s, batch_loss=0.0650, epoch_loss=0.0491, task=0, task_score=0.1672]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:09<00:02,  4.44it/s, batch_loss=0.0320, epoch_loss=0.0487, task=1, task_score=0.2675]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:09<00:01,  4.74it/s, batch_loss=0.0320, epoch_loss=0.0487, task=1, task_score=0.2675]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:09<00:01,  4.74it/s, batch_loss=0.0317, epoch_loss=0.0483, task=1, task_score=0.2662]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:09<00:01,  4.69it/s, batch_loss=0.0317, epoch_loss=0.0483, task=1, task_score=0.2662]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:10<00:01,  4.69it/s, batch_loss=0.0650, epoch_loss=0.0487, task=0, task_score=0.1302]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:10<00:02,  3.39it/s, batch_loss=0.0650, epoch_loss=0.0487, task=0, task_score=0.1302]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:10<00:02,  3.39it/s, batch_loss=0.0650, epoch_loss=0.0490, task=0, task_score=0.2640]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:10<00:01,  3.59it/s, batch_loss=0.0650, epoch_loss=0.0490, task=0, task_score=0.2640]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:10<00:01,  3.59it/s, batch_loss=0.0326, epoch_loss=0.0487, task=1, task_score=0.2193]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:10<00:01,  3.86it/s, batch_loss=0.0326, epoch_loss=0.0487, task=1, task_score=0.2193]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:10<00:01,  3.86it/s, batch_loss=0.0651, epoch_loss=0.0490, task=0, task_score=0.0986]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:10<00:00,  4.24it/s, batch_loss=0.0651, epoch_loss=0.0490, task=0, task_score=0.0986]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:11<00:00,  4.24it/s, batch_loss=0.0313, epoch_loss=0.0486, task=1, task_score=0.3376]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:11<00:00,  4.42it/s, batch_loss=0.0313, epoch_loss=0.0486, task=1, task_score=0.3376]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:11<00:00,  4.42it/s, batch_loss=0.0650, epoch_loss=0.0490, task=0, task_score=0.1302]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:11<00:00,  4.31it/s, batch_loss=0.0650, epoch_loss=0.0490, task=0, task_score=0.1302]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:11<00:00,  4.31it/s, batch_loss=0.0651, epoch_loss=0.0493, task=0, task_score=0.3455]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:11<00:00,  4.59it/s, batch_loss=0.0651, epoch_loss=0.0493, task=0, task_score=0.3455]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:11<00:00,  4.59it/s, batch_loss=0.0650, epoch_loss=0.0496, task=0, task_score=0.4797]\u001b[A\n",
      "Batch: 100%|██████████| 50/50 [00:11<00:00,  4.46it/s, batch_loss=0.0650, epoch_loss=0.0496, task=0, task_score=0.4797]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Evaluating model:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating model:  13%|█▎        | 5/39 [00:00<00:00, 43.59it/s]\u001b[A\n",
      "Evaluating model:  21%|██        | 8/39 [00:00<00:00, 37.75it/s]\u001b[A\n",
      "Evaluating model:  38%|███▊      | 15/39 [00:00<00:00, 43.21it/s]\u001b[A\n",
      "Evaluating model:  51%|█████▏    | 20/39 [00:00<00:00, 42.03it/s]\u001b[A\n",
      "Evaluating model:  67%|██████▋   | 26/39 [00:00<00:00, 45.14it/s]\u001b[A\n",
      "Evaluating model:  82%|████████▏ | 32/39 [00:00<00:00, 48.03it/s]\u001b[A\n",
      "Evaluating model:  97%|█████████▋| 38/39 [00:00<00:00, 51.02it/s]\u001b[A\n",
      "Training model:  40%|████      | 4/10 [00:47<01:10, 11.74s/it, dev_loss=0.0653, dev_score=0.2057, loss=0.0650]\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s, batch_loss=0.0650, epoch_loss=0.0650, task=0, task_score=0.2123]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:10,  4.73it/s, batch_loss=0.0650, epoch_loss=0.0650, task=0, task_score=0.2123]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:10,  4.73it/s, batch_loss=0.0650, epoch_loss=0.0650, task=0, task_score=0.1789]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:12,  3.73it/s, batch_loss=0.0650, epoch_loss=0.0650, task=0, task_score=0.1789]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:12,  3.73it/s, batch_loss=0.0650, epoch_loss=0.0650, task=0, task_score=0.1903]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:11,  3.97it/s, batch_loss=0.0650, epoch_loss=0.0650, task=0, task_score=0.1903]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:11,  3.97it/s, batch_loss=0.0319, epoch_loss=0.0567, task=1, task_score=0.3154]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:01<00:10,  4.38it/s, batch_loss=0.0319, epoch_loss=0.0567, task=1, task_score=0.3154]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:01<00:10,  4.38it/s, batch_loss=0.0322, epoch_loss=0.0518, task=1, task_score=0.2220]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:09,  4.73it/s, batch_loss=0.0322, epoch_loss=0.0518, task=1, task_score=0.2220]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:09,  4.73it/s, batch_loss=0.0650, epoch_loss=0.0540, task=0, task_score=0.1429]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:09,  4.45it/s, batch_loss=0.0650, epoch_loss=0.0540, task=0, task_score=0.1429]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:09,  4.45it/s, batch_loss=0.0654, epoch_loss=0.0556, task=0, task_score=0.4667]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:09,  4.62it/s, batch_loss=0.0654, epoch_loss=0.0556, task=0, task_score=0.4667]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:09,  4.62it/s, batch_loss=0.0653, epoch_loss=0.0568, task=0, task_score=0.1233]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:01<00:10,  4.17it/s, batch_loss=0.0653, epoch_loss=0.0568, task=0, task_score=0.1233]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:02<00:10,  4.17it/s, batch_loss=0.0322, epoch_loss=0.0541, task=1, task_score=0.2528]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:02<00:08,  4.68it/s, batch_loss=0.0322, epoch_loss=0.0541, task=1, task_score=0.2528]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:02<00:08,  4.68it/s, batch_loss=0.0650, epoch_loss=0.0552, task=0, task_score=0.1552]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:09,  4.29it/s, batch_loss=0.0650, epoch_loss=0.0552, task=0, task_score=0.1552]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:09,  4.29it/s, batch_loss=0.0320, epoch_loss=0.0531, task=1, task_score=0.2929]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:08,  4.58it/s, batch_loss=0.0320, epoch_loss=0.0531, task=1, task_score=0.2929]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:08,  4.58it/s, batch_loss=0.0650, epoch_loss=0.0541, task=0, task_score=0.1172]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:02<00:08,  4.33it/s, batch_loss=0.0650, epoch_loss=0.0541, task=0, task_score=0.1172]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:03<00:08,  4.33it/s, batch_loss=0.0650, epoch_loss=0.0549, task=0, task_score=0.1429]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:03<00:08,  4.26it/s, batch_loss=0.0650, epoch_loss=0.0549, task=0, task_score=0.1429]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:03<00:08,  4.26it/s, batch_loss=0.0650, epoch_loss=0.0556, task=0, task_score=0.1672]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:03<00:08,  4.42it/s, batch_loss=0.0650, epoch_loss=0.0556, task=0, task_score=0.1672]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:03<00:08,  4.42it/s, batch_loss=0.0317, epoch_loss=0.0540, task=1, task_score=0.2679]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:07,  4.84it/s, batch_loss=0.0317, epoch_loss=0.0540, task=1, task_score=0.2679]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:07,  4.84it/s, batch_loss=0.0650, epoch_loss=0.0547, task=0, task_score=0.1789]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:03<00:06,  4.93it/s, batch_loss=0.0650, epoch_loss=0.0547, task=0, task_score=0.1789]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:03<00:06,  4.93it/s, batch_loss=0.0323, epoch_loss=0.0534, task=1, task_score=0.1900]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:03<00:06,  5.17it/s, batch_loss=0.0323, epoch_loss=0.0534, task=1, task_score=0.1900]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:04<00:06,  5.17it/s, batch_loss=0.0650, epoch_loss=0.0540, task=0, task_score=0.4483]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:04<00:06,  4.79it/s, batch_loss=0.0650, epoch_loss=0.0540, task=0, task_score=0.4483]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:04<00:06,  4.79it/s, batch_loss=0.0650, epoch_loss=0.0546, task=0, task_score=0.1302]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  38%|███▊      | 19/50 [00:04<00:06,  4.81it/s, batch_loss=0.0650, epoch_loss=0.0546, task=0, task_score=0.1302]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:04<00:06,  4.81it/s, batch_loss=0.0650, epoch_loss=0.0551, task=0, task_score=0.4336]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:04<00:07,  4.19it/s, batch_loss=0.0650, epoch_loss=0.0551, task=0, task_score=0.4336]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:04<00:07,  4.19it/s, batch_loss=0.0313, epoch_loss=0.0540, task=1, task_score=0.3578]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:04<00:06,  4.65it/s, batch_loss=0.0313, epoch_loss=0.0540, task=1, task_score=0.3578]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:04<00:06,  4.65it/s, batch_loss=0.0322, epoch_loss=0.0530, task=1, task_score=0.2409]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:04<00:05,  4.96it/s, batch_loss=0.0322, epoch_loss=0.0530, task=1, task_score=0.2409]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:05<00:05,  4.96it/s, batch_loss=0.0652, epoch_loss=0.0535, task=0, task_score=0.4336]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:05<00:05,  4.64it/s, batch_loss=0.0652, epoch_loss=0.0535, task=0, task_score=0.4336]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:05<00:05,  4.64it/s, batch_loss=0.0650, epoch_loss=0.0540, task=0, task_score=0.1903]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:05<00:05,  4.47it/s, batch_loss=0.0650, epoch_loss=0.0540, task=0, task_score=0.1903]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:05<00:05,  4.47it/s, batch_loss=0.0321, epoch_loss=0.0531, task=1, task_score=0.2833]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:05<00:05,  4.95it/s, batch_loss=0.0321, epoch_loss=0.0531, task=1, task_score=0.2833]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:05<00:05,  4.95it/s, batch_loss=0.0319, epoch_loss=0.0523, task=1, task_score=0.2549]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:05<00:04,  5.41it/s, batch_loss=0.0319, epoch_loss=0.0523, task=1, task_score=0.2549]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:05<00:04,  5.41it/s, batch_loss=0.0317, epoch_loss=0.0516, task=1, task_score=0.2783]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:05<00:04,  5.52it/s, batch_loss=0.0317, epoch_loss=0.0516, task=1, task_score=0.2783]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:05<00:04,  5.52it/s, batch_loss=0.0318, epoch_loss=0.0508, task=1, task_score=0.2979]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:05<00:03,  5.54it/s, batch_loss=0.0318, epoch_loss=0.0508, task=1, task_score=0.2979]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:06<00:03,  5.54it/s, batch_loss=0.0652, epoch_loss=0.0513, task=0, task_score=0.1688]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:06<00:04,  4.97it/s, batch_loss=0.0652, epoch_loss=0.0513, task=0, task_score=0.1688]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:06<00:04,  4.97it/s, batch_loss=0.0320, epoch_loss=0.0507, task=1, task_score=0.2913]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:06<00:03,  5.19it/s, batch_loss=0.0320, epoch_loss=0.0507, task=1, task_score=0.2913]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:06<00:03,  5.19it/s, batch_loss=0.0325, epoch_loss=0.0501, task=1, task_score=0.1862]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:06<00:03,  5.29it/s, batch_loss=0.0325, epoch_loss=0.0501, task=1, task_score=0.1862]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:06<00:03,  5.29it/s, batch_loss=0.0320, epoch_loss=0.0495, task=1, task_score=0.3024]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:06<00:03,  5.55it/s, batch_loss=0.0320, epoch_loss=0.0495, task=1, task_score=0.3024]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:06<00:03,  5.55it/s, batch_loss=0.0326, epoch_loss=0.0490, task=1, task_score=0.2282]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:06<00:03,  5.32it/s, batch_loss=0.0326, epoch_loss=0.0490, task=1, task_score=0.2282]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:07<00:03,  5.32it/s, batch_loss=0.0651, epoch_loss=0.0495, task=0, task_score=0.1672]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:07<00:03,  5.16it/s, batch_loss=0.0651, epoch_loss=0.0495, task=0, task_score=0.1672]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:07<00:03,  5.16it/s, batch_loss=0.0650, epoch_loss=0.0499, task=0, task_score=0.1789]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:07<00:03,  4.77it/s, batch_loss=0.0650, epoch_loss=0.0499, task=0, task_score=0.1789]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:07<00:03,  4.77it/s, batch_loss=0.0650, epoch_loss=0.0504, task=0, task_score=0.1903]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:07<00:02,  4.70it/s, batch_loss=0.0650, epoch_loss=0.0504, task=0, task_score=0.1903]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:07<00:02,  4.70it/s, batch_loss=0.0650, epoch_loss=0.0508, task=0, task_score=0.2014]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:07<00:02,  4.65it/s, batch_loss=0.0650, epoch_loss=0.0508, task=0, task_score=0.2014]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:08<00:02,  4.65it/s, batch_loss=0.0654, epoch_loss=0.0511, task=0, task_score=0.1302]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:08<00:02,  4.84it/s, batch_loss=0.0654, epoch_loss=0.0511, task=0, task_score=0.1302]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:08<00:02,  4.84it/s, batch_loss=0.0321, epoch_loss=0.0507, task=1, task_score=0.3145]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:08<00:02,  5.12it/s, batch_loss=0.0321, epoch_loss=0.0507, task=1, task_score=0.3145]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:08<00:02,  5.12it/s, batch_loss=0.0324, epoch_loss=0.0502, task=1, task_score=0.2549]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:08<00:01,  5.29it/s, batch_loss=0.0324, epoch_loss=0.0502, task=1, task_score=0.2549]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:08<00:01,  5.29it/s, batch_loss=0.0319, epoch_loss=0.0497, task=1, task_score=0.3127]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:08<00:01,  5.52it/s, batch_loss=0.0319, epoch_loss=0.0497, task=1, task_score=0.3127]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:08<00:01,  5.52it/s, batch_loss=0.0317, epoch_loss=0.0493, task=1, task_score=0.3132]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:08<00:01,  5.47it/s, batch_loss=0.0317, epoch_loss=0.0493, task=1, task_score=0.3132]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:08<00:01,  5.47it/s, batch_loss=0.0649, epoch_loss=0.0497, task=0, task_score=0.4797]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:08<00:01,  5.30it/s, batch_loss=0.0649, epoch_loss=0.0497, task=0, task_score=0.4797]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:09<00:01,  5.30it/s, batch_loss=0.0324, epoch_loss=0.0493, task=1, task_score=0.2112]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:09<00:01,  5.41it/s, batch_loss=0.0324, epoch_loss=0.0493, task=1, task_score=0.2112]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:09<00:01,  5.41it/s, batch_loss=0.0650, epoch_loss=0.0496, task=0, task_score=0.4684]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:09<00:01,  3.86it/s, batch_loss=0.0650, epoch_loss=0.0496, task=0, task_score=0.4684]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:09<00:01,  3.86it/s, batch_loss=0.0650, epoch_loss=0.0500, task=0, task_score=0.4545]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:09<00:00,  4.10it/s, batch_loss=0.0650, epoch_loss=0.0500, task=0, task_score=0.4545]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:09<00:00,  4.10it/s, batch_loss=0.0318, epoch_loss=0.0496, task=1, task_score=0.2607]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:09<00:00,  4.55it/s, batch_loss=0.0318, epoch_loss=0.0496, task=1, task_score=0.2607]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:10<00:00,  4.55it/s, batch_loss=0.0651, epoch_loss=0.0499, task=0, task_score=0.4653]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:10<00:00,  3.92it/s, batch_loss=0.0651, epoch_loss=0.0499, task=0, task_score=0.4653]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:10<00:00,  3.92it/s, batch_loss=0.0322, epoch_loss=0.0495, task=1, task_score=0.2695]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:10<00:00,  3.93it/s, batch_loss=0.0322, epoch_loss=0.0495, task=1, task_score=0.2695]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:10<00:00,  3.93it/s, batch_loss=0.0323, epoch_loss=0.0492, task=1, task_score=0.2005]\u001b[A\n",
      "Batch: 100%|██████████| 50/50 [00:10<00:00,  4.29it/s, batch_loss=0.0323, epoch_loss=0.0492, task=1, task_score=0.2005]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Evaluating model:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating model:  13%|█▎        | 5/39 [00:00<00:00, 46.94it/s]\u001b[A\n",
      "Evaluating model:  28%|██▊       | 11/39 [00:00<00:00, 48.51it/s]\u001b[A\n",
      "Evaluating model:  36%|███▌      | 14/39 [00:00<00:00, 38.16it/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating model:  46%|████▌     | 18/39 [00:00<00:00, 38.24it/s]\u001b[A\n",
      "Evaluating model:  59%|█████▉    | 23/39 [00:00<00:00, 41.07it/s]\u001b[A\n",
      "Evaluating model:  74%|███████▍  | 29/39 [00:00<00:00, 45.15it/s]\u001b[A\n",
      "Evaluating model:  87%|████████▋ | 34/39 [00:00<00:00, 43.51it/s]\u001b[A\n",
      "Training model:  50%|█████     | 5/10 [00:59<00:58, 11.71s/it, dev_loss=0.0653, dev_score=0.4551, loss=0.0323]\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s, batch_loss=0.0647, epoch_loss=0.0647, task=0, task_score=0.4571]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:13,  3.72it/s, batch_loss=0.0647, epoch_loss=0.0647, task=0, task_score=0.4571]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:13,  3.72it/s, batch_loss=0.0646, epoch_loss=0.0647, task=0, task_score=0.4667]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:12,  3.82it/s, batch_loss=0.0646, epoch_loss=0.0647, task=0, task_score=0.4667]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:12,  3.82it/s, batch_loss=0.0320, epoch_loss=0.0538, task=1, task_score=0.2914]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:11,  4.00it/s, batch_loss=0.0320, epoch_loss=0.0538, task=1, task_score=0.2914]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:01<00:11,  4.00it/s, batch_loss=0.0656, epoch_loss=0.0567, task=0, task_score=0.4182]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:01<00:12,  3.74it/s, batch_loss=0.0656, epoch_loss=0.0567, task=0, task_score=0.4182]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:01<00:12,  3.74it/s, batch_loss=0.0651, epoch_loss=0.0584, task=0, task_score=0.4459]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:13,  3.32it/s, batch_loss=0.0651, epoch_loss=0.0584, task=0, task_score=0.4459]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:13,  3.32it/s, batch_loss=0.0323, epoch_loss=0.0541, task=1, task_score=0.2271]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:11,  3.81it/s, batch_loss=0.0323, epoch_loss=0.0541, task=1, task_score=0.2271]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:11,  3.81it/s, batch_loss=0.0314, epoch_loss=0.0508, task=1, task_score=0.3117]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:10,  4.22it/s, batch_loss=0.0314, epoch_loss=0.0508, task=1, task_score=0.3117]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:10,  4.22it/s, batch_loss=0.0314, epoch_loss=0.0484, task=1, task_score=0.3115]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:01<00:09,  4.65it/s, batch_loss=0.0314, epoch_loss=0.0484, task=1, task_score=0.3115]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:02<00:09,  4.65it/s, batch_loss=0.0649, epoch_loss=0.0502, task=0, task_score=0.5362]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:02<00:09,  4.21it/s, batch_loss=0.0649, epoch_loss=0.0502, task=0, task_score=0.5362]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:02<00:09,  4.21it/s, batch_loss=0.0315, epoch_loss=0.0484, task=1, task_score=0.2942]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:08,  4.62it/s, batch_loss=0.0315, epoch_loss=0.0484, task=1, task_score=0.2942]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:08,  4.62it/s, batch_loss=0.0316, epoch_loss=0.0468, task=1, task_score=0.3582]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:07,  5.07it/s, batch_loss=0.0316, epoch_loss=0.0468, task=1, task_score=0.3582]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:03<00:07,  5.07it/s, batch_loss=0.0646, epoch_loss=0.0483, task=0, task_score=0.6139]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:03<00:14,  2.67it/s, batch_loss=0.0646, epoch_loss=0.0483, task=0, task_score=0.6139]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:03<00:14,  2.67it/s, batch_loss=0.0650, epoch_loss=0.0496, task=0, task_score=0.5429]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:03<00:12,  2.97it/s, batch_loss=0.0650, epoch_loss=0.0496, task=0, task_score=0.5429]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:03<00:12,  2.97it/s, batch_loss=0.0318, epoch_loss=0.0483, task=1, task_score=0.2337]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:03<00:10,  3.47it/s, batch_loss=0.0318, epoch_loss=0.0483, task=1, task_score=0.2337]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:03<00:10,  3.47it/s, batch_loss=0.0311, epoch_loss=0.0472, task=1, task_score=0.4079]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:08,  3.94it/s, batch_loss=0.0311, epoch_loss=0.0472, task=1, task_score=0.4079]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:04<00:08,  3.94it/s, batch_loss=0.0647, epoch_loss=0.0483, task=0, task_score=0.5728]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:04<00:08,  4.02it/s, batch_loss=0.0647, epoch_loss=0.0483, task=0, task_score=0.5728]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:04<00:08,  4.02it/s, batch_loss=0.0649, epoch_loss=0.0493, task=0, task_score=0.5886]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:04<00:07,  4.15it/s, batch_loss=0.0649, epoch_loss=0.0493, task=0, task_score=0.5886]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:04<00:07,  4.15it/s, batch_loss=0.0650, epoch_loss=0.0501, task=0, task_score=0.4781]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:04<00:07,  4.10it/s, batch_loss=0.0650, epoch_loss=0.0501, task=0, task_score=0.4781]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:04<00:07,  4.10it/s, batch_loss=0.0650, epoch_loss=0.0509, task=0, task_score=0.4913]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:04<00:07,  4.23it/s, batch_loss=0.0650, epoch_loss=0.0509, task=0, task_score=0.4913]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:05<00:07,  4.23it/s, batch_loss=0.0322, epoch_loss=0.0500, task=1, task_score=0.2477]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:05<00:06,  4.61it/s, batch_loss=0.0322, epoch_loss=0.0500, task=1, task_score=0.2477]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:05<00:06,  4.61it/s, batch_loss=0.0652, epoch_loss=0.0507, task=0, task_score=0.4435]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:05<00:06,  4.42it/s, batch_loss=0.0652, epoch_loss=0.0507, task=0, task_score=0.4435]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:05<00:06,  4.42it/s, batch_loss=0.0320, epoch_loss=0.0499, task=1, task_score=0.2251]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:05<00:05,  4.74it/s, batch_loss=0.0320, epoch_loss=0.0499, task=1, task_score=0.2251]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:05<00:05,  4.74it/s, batch_loss=0.0314, epoch_loss=0.0491, task=1, task_score=0.3620]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:05<00:05,  5.00it/s, batch_loss=0.0314, epoch_loss=0.0491, task=1, task_score=0.3620]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:05<00:05,  5.00it/s, batch_loss=0.0649, epoch_loss=0.0497, task=0, task_score=0.6025]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:05<00:06,  4.08it/s, batch_loss=0.0649, epoch_loss=0.0497, task=0, task_score=0.6025]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:06<00:06,  4.08it/s, batch_loss=0.0648, epoch_loss=0.0503, task=0, task_score=0.5728]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:06<00:06,  3.95it/s, batch_loss=0.0648, epoch_loss=0.0503, task=0, task_score=0.5728]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:06<00:06,  3.95it/s, batch_loss=0.0308, epoch_loss=0.0496, task=1, task_score=0.3829]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:06<00:05,  4.43it/s, batch_loss=0.0308, epoch_loss=0.0496, task=1, task_score=0.3829]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:06<00:05,  4.43it/s, batch_loss=0.0318, epoch_loss=0.0489, task=1, task_score=0.2450]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:06<00:04,  4.72it/s, batch_loss=0.0318, epoch_loss=0.0489, task=1, task_score=0.2450]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:06<00:04,  4.72it/s, batch_loss=0.0328, epoch_loss=0.0483, task=1, task_score=0.1482]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:06<00:04,  5.02it/s, batch_loss=0.0328, epoch_loss=0.0483, task=1, task_score=0.1482]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:06<00:04,  5.02it/s, batch_loss=0.0311, epoch_loss=0.0477, task=1, task_score=0.3377]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:06<00:04,  5.22it/s, batch_loss=0.0311, epoch_loss=0.0477, task=1, task_score=0.3377]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:07<00:04,  5.22it/s, batch_loss=0.0650, epoch_loss=0.0483, task=0, task_score=0.4781]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:07<00:04,  4.94it/s, batch_loss=0.0650, epoch_loss=0.0483, task=0, task_score=0.4781]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:07<00:04,  4.94it/s, batch_loss=0.0646, epoch_loss=0.0488, task=0, task_score=0.5871]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:07<00:03,  4.95it/s, batch_loss=0.0646, epoch_loss=0.0488, task=0, task_score=0.5871]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:07<00:03,  4.95it/s, batch_loss=0.0314, epoch_loss=0.0483, task=1, task_score=0.3423]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  64%|██████▍   | 32/50 [00:07<00:03,  5.16it/s, batch_loss=0.0314, epoch_loss=0.0483, task=1, task_score=0.3423]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:07<00:03,  5.16it/s, batch_loss=0.0652, epoch_loss=0.0488, task=0, task_score=0.4602]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:07<00:03,  4.85it/s, batch_loss=0.0652, epoch_loss=0.0488, task=0, task_score=0.4602]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:08<00:03,  4.85it/s, batch_loss=0.0649, epoch_loss=0.0493, task=0, task_score=0.5495]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:08<00:03,  4.36it/s, batch_loss=0.0649, epoch_loss=0.0493, task=0, task_score=0.5495]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:08<00:03,  4.36it/s, batch_loss=0.0645, epoch_loss=0.0497, task=0, task_score=0.6522]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:08<00:03,  4.07it/s, batch_loss=0.0645, epoch_loss=0.0497, task=0, task_score=0.6522]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:08<00:03,  4.07it/s, batch_loss=0.0651, epoch_loss=0.0501, task=0, task_score=0.5211]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:08<00:03,  4.07it/s, batch_loss=0.0651, epoch_loss=0.0501, task=0, task_score=0.5211]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:08<00:03,  4.07it/s, batch_loss=0.0321, epoch_loss=0.0497, task=1, task_score=0.2161]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:08<00:02,  4.45it/s, batch_loss=0.0321, epoch_loss=0.0497, task=1, task_score=0.2161]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:08<00:02,  4.45it/s, batch_loss=0.0314, epoch_loss=0.0492, task=1, task_score=0.3138]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:08<00:02,  4.87it/s, batch_loss=0.0314, epoch_loss=0.0492, task=1, task_score=0.3138]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:09<00:02,  4.87it/s, batch_loss=0.0319, epoch_loss=0.0487, task=1, task_score=0.3172]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:09<00:02,  5.12it/s, batch_loss=0.0319, epoch_loss=0.0487, task=1, task_score=0.3172]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:09<00:02,  5.12it/s, batch_loss=0.0654, epoch_loss=0.0491, task=0, task_score=0.4896]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:09<00:02,  4.93it/s, batch_loss=0.0654, epoch_loss=0.0491, task=0, task_score=0.4896]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:09<00:02,  4.93it/s, batch_loss=0.0320, epoch_loss=0.0487, task=1, task_score=0.3128]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:09<00:01,  5.10it/s, batch_loss=0.0320, epoch_loss=0.0487, task=1, task_score=0.3128]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:09<00:01,  5.10it/s, batch_loss=0.0653, epoch_loss=0.0491, task=0, task_score=0.4910]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:09<00:01,  4.88it/s, batch_loss=0.0653, epoch_loss=0.0491, task=0, task_score=0.4910]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:09<00:01,  4.88it/s, batch_loss=0.0645, epoch_loss=0.0495, task=0, task_score=0.5589]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:09<00:01,  4.79it/s, batch_loss=0.0645, epoch_loss=0.0495, task=0, task_score=0.5589]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:10<00:01,  4.79it/s, batch_loss=0.0650, epoch_loss=0.0498, task=0, task_score=0.4108]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:10<00:01,  4.85it/s, batch_loss=0.0650, epoch_loss=0.0498, task=0, task_score=0.4108]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:10<00:01,  4.85it/s, batch_loss=0.0321, epoch_loss=0.0494, task=1, task_score=0.2897]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:10<00:01,  4.99it/s, batch_loss=0.0321, epoch_loss=0.0494, task=1, task_score=0.2897]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:10<00:01,  4.99it/s, batch_loss=0.0318, epoch_loss=0.0491, task=1, task_score=0.3013]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:10<00:00,  5.10it/s, batch_loss=0.0318, epoch_loss=0.0491, task=1, task_score=0.3013]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:10<00:00,  5.10it/s, batch_loss=0.0649, epoch_loss=0.0494, task=0, task_score=0.5478]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:10<00:00,  4.58it/s, batch_loss=0.0649, epoch_loss=0.0494, task=0, task_score=0.5478]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:10<00:00,  4.58it/s, batch_loss=0.0651, epoch_loss=0.0497, task=0, task_score=0.5077]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:10<00:00,  4.69it/s, batch_loss=0.0651, epoch_loss=0.0497, task=0, task_score=0.5077]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:11<00:00,  4.69it/s, batch_loss=0.0654, epoch_loss=0.0500, task=0, task_score=0.3905]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:11<00:00,  4.43it/s, batch_loss=0.0654, epoch_loss=0.0500, task=0, task_score=0.3905]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:11<00:00,  4.43it/s, batch_loss=0.0651, epoch_loss=0.0503, task=0, task_score=0.5272]\u001b[A\n",
      "Batch: 100%|██████████| 50/50 [00:11<00:00,  3.44it/s, batch_loss=0.0651, epoch_loss=0.0503, task=0, task_score=0.5272]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Evaluating model:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating model:   5%|▌         | 2/39 [00:00<00:02, 17.63it/s]\u001b[A\n",
      "Evaluating model:  18%|█▊        | 7/39 [00:00<00:01, 21.78it/s]\u001b[A\n",
      "Evaluating model:  28%|██▊       | 11/39 [00:00<00:01, 25.10it/s]\u001b[A\n",
      "Evaluating model:  44%|████▎     | 17/39 [00:00<00:00, 29.29it/s]\u001b[A\n",
      "Evaluating model:  54%|█████▍    | 21/39 [00:00<00:00, 28.70it/s]\u001b[A\n",
      "Evaluating model:  69%|██████▉   | 27/39 [00:00<00:00, 33.78it/s]\u001b[A\n",
      "Evaluating model:  79%|███████▉  | 31/39 [00:00<00:00, 35.00it/s]\u001b[A\n",
      "Evaluating model:  92%|█████████▏| 36/39 [00:00<00:00, 37.95it/s]\u001b[A\n",
      "Training model:  60%|██████    | 6/10 [01:11<00:48, 12.02s/it, dev_loss=0.0654, dev_score=0.4970, loss=0.0651]\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s, batch_loss=0.0651, epoch_loss=0.0651, task=0, task_score=0.5105]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:16,  2.95it/s, batch_loss=0.0651, epoch_loss=0.0651, task=0, task_score=0.5105]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:16,  2.95it/s, batch_loss=0.0321, epoch_loss=0.0486, task=1, task_score=0.2394]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:13,  3.45it/s, batch_loss=0.0321, epoch_loss=0.0486, task=1, task_score=0.2394]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:13,  3.45it/s, batch_loss=0.0650, epoch_loss=0.0541, task=0, task_score=0.4776]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:13,  3.59it/s, batch_loss=0.0650, epoch_loss=0.0541, task=0, task_score=0.4776]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:13,  3.59it/s, batch_loss=0.0332, epoch_loss=0.0488, task=1, task_score=0.1822]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:00<00:11,  4.02it/s, batch_loss=0.0332, epoch_loss=0.0488, task=1, task_score=0.1822]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:01<00:11,  4.02it/s, batch_loss=0.0316, epoch_loss=0.0454, task=1, task_score=0.2367]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:10,  4.41it/s, batch_loss=0.0316, epoch_loss=0.0454, task=1, task_score=0.2367]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:10,  4.41it/s, batch_loss=0.0650, epoch_loss=0.0487, task=0, task_score=0.4589]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:11,  3.85it/s, batch_loss=0.0650, epoch_loss=0.0487, task=0, task_score=0.4589]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:11,  3.85it/s, batch_loss=0.0318, epoch_loss=0.0463, task=1, task_score=0.1968]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:10,  4.27it/s, batch_loss=0.0318, epoch_loss=0.0463, task=1, task_score=0.1968]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:10,  4.27it/s, batch_loss=0.0650, epoch_loss=0.0486, task=0, task_score=0.4909]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:01<00:09,  4.30it/s, batch_loss=0.0650, epoch_loss=0.0486, task=0, task_score=0.4909]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:02<00:09,  4.30it/s, batch_loss=0.0319, epoch_loss=0.0467, task=1, task_score=0.3218]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:02<00:09,  4.55it/s, batch_loss=0.0319, epoch_loss=0.0467, task=1, task_score=0.3218]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:02<00:09,  4.55it/s, batch_loss=0.0312, epoch_loss=0.0452, task=1, task_score=0.3048]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:08,  4.81it/s, batch_loss=0.0312, epoch_loss=0.0452, task=1, task_score=0.3048]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:08,  4.81it/s, batch_loss=0.0317, epoch_loss=0.0440, task=1, task_score=0.3497]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:08,  4.86it/s, batch_loss=0.0317, epoch_loss=0.0440, task=1, task_score=0.3497]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  22%|██▏       | 11/50 [00:02<00:08,  4.86it/s, batch_loss=0.0648, epoch_loss=0.0457, task=0, task_score=0.6008]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:02<00:08,  4.54it/s, batch_loss=0.0648, epoch_loss=0.0457, task=0, task_score=0.6008]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:02<00:08,  4.54it/s, batch_loss=0.0323, epoch_loss=0.0447, task=1, task_score=0.2275]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:02<00:07,  4.83it/s, batch_loss=0.0323, epoch_loss=0.0447, task=1, task_score=0.2275]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:03<00:07,  4.83it/s, batch_loss=0.0321, epoch_loss=0.0438, task=1, task_score=0.1786]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:03<00:07,  4.61it/s, batch_loss=0.0321, epoch_loss=0.0438, task=1, task_score=0.1786]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:03<00:07,  4.61it/s, batch_loss=0.0648, epoch_loss=0.0452, task=0, task_score=0.5272]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:07,  4.46it/s, batch_loss=0.0648, epoch_loss=0.0452, task=0, task_score=0.5272]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:07,  4.46it/s, batch_loss=0.0649, epoch_loss=0.0464, task=0, task_score=0.4545]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:03<00:07,  4.45it/s, batch_loss=0.0649, epoch_loss=0.0464, task=0, task_score=0.4545]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:03<00:07,  4.45it/s, batch_loss=0.0312, epoch_loss=0.0455, task=1, task_score=0.3061]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:03<00:06,  4.73it/s, batch_loss=0.0312, epoch_loss=0.0455, task=1, task_score=0.3061]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:03<00:06,  4.73it/s, batch_loss=0.0648, epoch_loss=0.0466, task=0, task_score=0.5362]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:03<00:07,  4.51it/s, batch_loss=0.0648, epoch_loss=0.0466, task=0, task_score=0.5362]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:04<00:07,  4.51it/s, batch_loss=0.0312, epoch_loss=0.0458, task=1, task_score=0.2184]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:04<00:06,  4.92it/s, batch_loss=0.0312, epoch_loss=0.0458, task=1, task_score=0.2184]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:04<00:06,  4.92it/s, batch_loss=0.0321, epoch_loss=0.0451, task=1, task_score=0.1848]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:04<00:05,  5.07it/s, batch_loss=0.0321, epoch_loss=0.0451, task=1, task_score=0.1848]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:04<00:05,  5.07it/s, batch_loss=0.0650, epoch_loss=0.0460, task=0, task_score=0.4922]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:04<00:07,  4.11it/s, batch_loss=0.0650, epoch_loss=0.0460, task=0, task_score=0.4922]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:04<00:07,  4.11it/s, batch_loss=0.0652, epoch_loss=0.0469, task=0, task_score=0.3970]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:04<00:06,  4.23it/s, batch_loss=0.0652, epoch_loss=0.0469, task=0, task_score=0.3970]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:05<00:06,  4.23it/s, batch_loss=0.0649, epoch_loss=0.0477, task=0, task_score=0.4452]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:05<00:06,  4.23it/s, batch_loss=0.0649, epoch_loss=0.0477, task=0, task_score=0.4452]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:05<00:06,  4.23it/s, batch_loss=0.0326, epoch_loss=0.0471, task=1, task_score=0.2191]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:05<00:05,  4.60it/s, batch_loss=0.0326, epoch_loss=0.0471, task=1, task_score=0.2191]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:05<00:05,  4.60it/s, batch_loss=0.0650, epoch_loss=0.0478, task=0, task_score=0.4622]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:05<00:05,  4.20it/s, batch_loss=0.0650, epoch_loss=0.0478, task=0, task_score=0.4622]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:05<00:05,  4.20it/s, batch_loss=0.0324, epoch_loss=0.0472, task=1, task_score=0.1498]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:05<00:05,  4.59it/s, batch_loss=0.0324, epoch_loss=0.0472, task=1, task_score=0.1498]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:05<00:05,  4.59it/s, batch_loss=0.0649, epoch_loss=0.0478, task=0, task_score=0.4797]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:05<00:05,  4.56it/s, batch_loss=0.0649, epoch_loss=0.0478, task=0, task_score=0.4797]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:06<00:05,  4.56it/s, batch_loss=0.0323, epoch_loss=0.0473, task=1, task_score=0.1240]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:06<00:04,  4.82it/s, batch_loss=0.0323, epoch_loss=0.0473, task=1, task_score=0.1240]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:06<00:04,  4.82it/s, batch_loss=0.0323, epoch_loss=0.0468, task=1, task_score=0.1961]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:06<00:04,  5.01it/s, batch_loss=0.0323, epoch_loss=0.0468, task=1, task_score=0.1961]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:06<00:04,  5.01it/s, batch_loss=0.0647, epoch_loss=0.0474, task=0, task_score=0.5248]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:06<00:04,  4.56it/s, batch_loss=0.0647, epoch_loss=0.0474, task=0, task_score=0.5248]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:06<00:04,  4.56it/s, batch_loss=0.0645, epoch_loss=0.0479, task=0, task_score=0.5628]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:06<00:04,  4.48it/s, batch_loss=0.0645, epoch_loss=0.0479, task=0, task_score=0.5628]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:07<00:04,  4.48it/s, batch_loss=0.0325, epoch_loss=0.0474, task=1, task_score=0.1060]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:07<00:03,  4.79it/s, batch_loss=0.0325, epoch_loss=0.0474, task=1, task_score=0.1060]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:07<00:03,  4.79it/s, batch_loss=0.0324, epoch_loss=0.0470, task=1, task_score=0.1413]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:07<00:03,  4.98it/s, batch_loss=0.0324, epoch_loss=0.0470, task=1, task_score=0.1413]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:07<00:03,  4.98it/s, batch_loss=0.0654, epoch_loss=0.0475, task=0, task_score=0.4393]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:07<00:03,  4.16it/s, batch_loss=0.0654, epoch_loss=0.0475, task=0, task_score=0.4393]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:07<00:03,  4.16it/s, batch_loss=0.0649, epoch_loss=0.0480, task=0, task_score=0.5873]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:07<00:03,  4.10it/s, batch_loss=0.0649, epoch_loss=0.0480, task=0, task_score=0.5873]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:08<00:03,  4.10it/s, batch_loss=0.0651, epoch_loss=0.0485, task=0, task_score=0.4386]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:08<00:03,  4.22it/s, batch_loss=0.0651, epoch_loss=0.0485, task=0, task_score=0.4386]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:08<00:03,  4.22it/s, batch_loss=0.0647, epoch_loss=0.0489, task=0, task_score=0.5390]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:08<00:03,  4.13it/s, batch_loss=0.0647, epoch_loss=0.0489, task=0, task_score=0.5390]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:08<00:03,  4.13it/s, batch_loss=0.0331, epoch_loss=0.0485, task=1, task_score=0.1548]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:08<00:02,  4.54it/s, batch_loss=0.0331, epoch_loss=0.0485, task=1, task_score=0.1548]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:08<00:02,  4.54it/s, batch_loss=0.0647, epoch_loss=0.0489, task=0, task_score=0.5530]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:08<00:02,  4.23it/s, batch_loss=0.0647, epoch_loss=0.0489, task=0, task_score=0.5530]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:08<00:02,  4.23it/s, batch_loss=0.0324, epoch_loss=0.0485, task=1, task_score=0.1742]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:08<00:02,  4.54it/s, batch_loss=0.0324, epoch_loss=0.0485, task=1, task_score=0.1742]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:09<00:02,  4.54it/s, batch_loss=0.0323, epoch_loss=0.0481, task=1, task_score=0.1630]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:09<00:01,  4.73it/s, batch_loss=0.0323, epoch_loss=0.0481, task=1, task_score=0.1630]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:09<00:01,  4.73it/s, batch_loss=0.0327, epoch_loss=0.0478, task=1, task_score=0.1519]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:09<00:01,  5.09it/s, batch_loss=0.0327, epoch_loss=0.0478, task=1, task_score=0.1519]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:09<00:01,  5.09it/s, batch_loss=0.0654, epoch_loss=0.0482, task=0, task_score=0.4896]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:09<00:01,  4.38it/s, batch_loss=0.0654, epoch_loss=0.0482, task=0, task_score=0.4896]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:09<00:01,  4.38it/s, batch_loss=0.0323, epoch_loss=0.0478, task=1, task_score=0.1831]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:09<00:01,  4.70it/s, batch_loss=0.0323, epoch_loss=0.0478, task=1, task_score=0.1831]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  88%|████████▊ | 44/50 [00:09<00:01,  4.70it/s, batch_loss=0.0649, epoch_loss=0.0482, task=0, task_score=0.4545]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:09<00:01,  4.45it/s, batch_loss=0.0649, epoch_loss=0.0482, task=0, task_score=0.4545]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:10<00:01,  4.45it/s, batch_loss=0.0653, epoch_loss=0.0486, task=0, task_score=0.4922]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:10<00:00,  4.36it/s, batch_loss=0.0653, epoch_loss=0.0486, task=0, task_score=0.4922]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:10<00:00,  4.36it/s, batch_loss=0.0324, epoch_loss=0.0482, task=1, task_score=0.0811]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:10<00:00,  4.45it/s, batch_loss=0.0324, epoch_loss=0.0482, task=1, task_score=0.0811]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:10<00:00,  4.45it/s, batch_loss=0.0649, epoch_loss=0.0486, task=0, task_score=0.5748]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:10<00:00,  4.37it/s, batch_loss=0.0649, epoch_loss=0.0486, task=0, task_score=0.5748]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:10<00:00,  4.37it/s, batch_loss=0.0321, epoch_loss=0.0482, task=1, task_score=0.2567]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:10<00:00,  4.58it/s, batch_loss=0.0321, epoch_loss=0.0482, task=1, task_score=0.2567]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:11<00:00,  4.58it/s, batch_loss=0.0649, epoch_loss=0.0486, task=0, task_score=0.5135]\u001b[A\n",
      "Batch: 100%|██████████| 50/50 [00:11<00:00,  4.14it/s, batch_loss=0.0649, epoch_loss=0.0486, task=0, task_score=0.5135]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Evaluating model:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating model:   8%|▊         | 3/39 [00:00<00:01, 26.01it/s]\u001b[A\n",
      "Evaluating model:  15%|█▌        | 6/39 [00:00<00:01, 26.99it/s]\u001b[A\n",
      "Evaluating model:  21%|██        | 8/39 [00:00<00:01, 23.09it/s]\u001b[A\n",
      "Evaluating model:  28%|██▊       | 11/39 [00:00<00:01, 24.23it/s]\u001b[A\n",
      "Evaluating model:  36%|███▌      | 14/39 [00:00<00:01, 24.58it/s]\u001b[A\n",
      "Evaluating model:  46%|████▌     | 18/39 [00:00<00:00, 26.31it/s]\u001b[A\n",
      "Evaluating model:  54%|█████▍    | 21/39 [00:00<00:00, 22.18it/s]\u001b[A\n",
      "Evaluating model:  64%|██████▍   | 25/39 [00:00<00:00, 24.50it/s]\u001b[A\n",
      "Evaluating model:  72%|███████▏  | 28/39 [00:01<00:00, 23.90it/s]\u001b[A\n",
      "Evaluating model:  82%|████████▏ | 32/39 [00:01<00:00, 26.30it/s]\u001b[A\n",
      "Evaluating model:  90%|████████▉ | 35/39 [00:01<00:00, 24.26it/s]\u001b[A\n",
      "Evaluating model:  97%|█████████▋| 38/39 [00:01<00:00, 24.95it/s]\u001b[A\n",
      "Training model:  70%|███████   | 7/10 [01:24<00:36, 12.26s/it, dev_loss=0.0652, dev_score=0.5229, loss=0.0649]\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s, batch_loss=0.0323, epoch_loss=0.0323, task=1, task_score=0.2855]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:08,  5.84it/s, batch_loss=0.0323, epoch_loss=0.0323, task=1, task_score=0.2855]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:08,  5.84it/s, batch_loss=0.0325, epoch_loss=0.0324, task=1, task_score=0.2134]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:08,  5.69it/s, batch_loss=0.0325, epoch_loss=0.0324, task=1, task_score=0.2134]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:08,  5.69it/s, batch_loss=0.0649, epoch_loss=0.0432, task=0, task_score=0.5514]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:09,  4.91it/s, batch_loss=0.0649, epoch_loss=0.0432, task=0, task_score=0.5514]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:09,  4.91it/s, batch_loss=0.0323, epoch_loss=0.0405, task=1, task_score=0.2349]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:00<00:08,  5.14it/s, batch_loss=0.0323, epoch_loss=0.0405, task=1, task_score=0.2349]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:01<00:08,  5.14it/s, batch_loss=0.0646, epoch_loss=0.0453, task=0, task_score=0.5194]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:09,  4.51it/s, batch_loss=0.0646, epoch_loss=0.0453, task=0, task_score=0.5194]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:09,  4.51it/s, batch_loss=0.0646, epoch_loss=0.0485, task=0, task_score=0.5749]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:10,  4.39it/s, batch_loss=0.0646, epoch_loss=0.0485, task=0, task_score=0.5749]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:10,  4.39it/s, batch_loss=0.0322, epoch_loss=0.0462, task=1, task_score=0.1859]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:09,  4.49it/s, batch_loss=0.0322, epoch_loss=0.0462, task=1, task_score=0.1859]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:09,  4.49it/s, batch_loss=0.0321, epoch_loss=0.0445, task=1, task_score=0.2593]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:01<00:08,  4.71it/s, batch_loss=0.0321, epoch_loss=0.0445, task=1, task_score=0.2593]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:02<00:08,  4.71it/s, batch_loss=0.0646, epoch_loss=0.0467, task=0, task_score=0.5305]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:02<00:09,  4.20it/s, batch_loss=0.0646, epoch_loss=0.0467, task=0, task_score=0.5305]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:02<00:09,  4.20it/s, batch_loss=0.0322, epoch_loss=0.0452, task=1, task_score=0.2786]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:08,  4.52it/s, batch_loss=0.0322, epoch_loss=0.0452, task=1, task_score=0.2786]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:08,  4.52it/s, batch_loss=0.0724, epoch_loss=0.0461, task=1, task_score=0.1587]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:07,  5.27it/s, batch_loss=0.0724, epoch_loss=0.0461, task=1, task_score=0.1587]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:07,  5.27it/s, batch_loss=0.0643, epoch_loss=0.0477, task=0, task_score=0.6591]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:02<00:08,  4.59it/s, batch_loss=0.0643, epoch_loss=0.0477, task=0, task_score=0.6591]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:02<00:08,  4.59it/s, batch_loss=0.0323, epoch_loss=0.0465, task=1, task_score=0.1684]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:02<00:07,  4.78it/s, batch_loss=0.0323, epoch_loss=0.0465, task=1, task_score=0.1684]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:02<00:07,  4.78it/s, batch_loss=0.0322, epoch_loss=0.0454, task=1, task_score=0.3443]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:02<00:07,  4.88it/s, batch_loss=0.0322, epoch_loss=0.0454, task=1, task_score=0.3443]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:03<00:07,  4.88it/s, batch_loss=0.0651, epoch_loss=0.0468, task=0, task_score=0.4776]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:09,  3.52it/s, batch_loss=0.0651, epoch_loss=0.0468, task=0, task_score=0.4776]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:09,  3.52it/s, batch_loss=0.0318, epoch_loss=0.0458, task=1, task_score=0.4636]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:03<00:08,  3.88it/s, batch_loss=0.0318, epoch_loss=0.0458, task=1, task_score=0.4636]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:03<00:08,  3.88it/s, batch_loss=0.0317, epoch_loss=0.0450, task=1, task_score=0.3534]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:03<00:07,  4.23it/s, batch_loss=0.0317, epoch_loss=0.0450, task=1, task_score=0.3534]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:04<00:07,  4.23it/s, batch_loss=0.0652, epoch_loss=0.0461, task=0, task_score=0.5278]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:04<00:08,  3.92it/s, batch_loss=0.0652, epoch_loss=0.0461, task=0, task_score=0.5278]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:04<00:08,  3.92it/s, batch_loss=0.0325, epoch_loss=0.0454, task=1, task_score=0.2044]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:04<00:07,  4.31it/s, batch_loss=0.0325, epoch_loss=0.0454, task=1, task_score=0.2044]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:04<00:07,  4.31it/s, batch_loss=0.0323, epoch_loss=0.0447, task=1, task_score=0.2713]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:04<00:06,  4.57it/s, batch_loss=0.0323, epoch_loss=0.0447, task=1, task_score=0.2713]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:04<00:06,  4.57it/s, batch_loss=0.0320, epoch_loss=0.0441, task=1, task_score=0.2634]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:04<00:05,  4.86it/s, batch_loss=0.0320, epoch_loss=0.0441, task=1, task_score=0.2634]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:04<00:05,  4.86it/s, batch_loss=0.0322, epoch_loss=0.0435, task=1, task_score=0.3072]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:04<00:05,  5.06it/s, batch_loss=0.0322, epoch_loss=0.0435, task=1, task_score=0.3072]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:05<00:05,  5.06it/s, batch_loss=0.0320, epoch_loss=0.0430, task=1, task_score=0.2712]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  46%|████▌     | 23/50 [00:05<00:05,  5.25it/s, batch_loss=0.0320, epoch_loss=0.0430, task=1, task_score=0.2712]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:05<00:05,  5.25it/s, batch_loss=0.0647, epoch_loss=0.0439, task=0, task_score=0.5393]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:05<00:05,  4.61it/s, batch_loss=0.0647, epoch_loss=0.0439, task=0, task_score=0.5393]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:05<00:05,  4.61it/s, batch_loss=0.0650, epoch_loss=0.0448, task=0, task_score=0.4684]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:05<00:05,  4.42it/s, batch_loss=0.0650, epoch_loss=0.0448, task=0, task_score=0.4684]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:05<00:05,  4.42it/s, batch_loss=0.0319, epoch_loss=0.0443, task=1, task_score=0.3082]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:05<00:05,  4.53it/s, batch_loss=0.0319, epoch_loss=0.0443, task=1, task_score=0.3082]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:05<00:05,  4.53it/s, batch_loss=0.0320, epoch_loss=0.0438, task=1, task_score=0.3183]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:05<00:04,  4.85it/s, batch_loss=0.0320, epoch_loss=0.0438, task=1, task_score=0.3183]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:06<00:04,  4.85it/s, batch_loss=0.0653, epoch_loss=0.0446, task=0, task_score=0.4231]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:06<00:04,  4.61it/s, batch_loss=0.0653, epoch_loss=0.0446, task=0, task_score=0.4231]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:06<00:04,  4.61it/s, batch_loss=0.0655, epoch_loss=0.0453, task=0, task_score=0.3637]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:06<00:05,  4.15it/s, batch_loss=0.0655, epoch_loss=0.0453, task=0, task_score=0.3637]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:06<00:05,  4.15it/s, batch_loss=0.0319, epoch_loss=0.0449, task=1, task_score=0.2752]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:06<00:04,  4.42it/s, batch_loss=0.0319, epoch_loss=0.0449, task=1, task_score=0.2752]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:06<00:04,  4.42it/s, batch_loss=0.0324, epoch_loss=0.0445, task=1, task_score=0.2319]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:06<00:04,  4.57it/s, batch_loss=0.0324, epoch_loss=0.0445, task=1, task_score=0.2319]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:07<00:04,  4.57it/s, batch_loss=0.0322, epoch_loss=0.0441, task=1, task_score=0.2928]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:07<00:04,  4.50it/s, batch_loss=0.0322, epoch_loss=0.0441, task=1, task_score=0.2928]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:07<00:04,  4.50it/s, batch_loss=0.0316, epoch_loss=0.0437, task=1, task_score=0.2786]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:07<00:03,  4.48it/s, batch_loss=0.0316, epoch_loss=0.0437, task=1, task_score=0.2786]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:07<00:03,  4.48it/s, batch_loss=0.0324, epoch_loss=0.0434, task=1, task_score=0.2172]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:07<00:03,  4.71it/s, batch_loss=0.0324, epoch_loss=0.0434, task=1, task_score=0.2172]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:07<00:03,  4.71it/s, batch_loss=0.0318, epoch_loss=0.0430, task=1, task_score=0.3011]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:07<00:03,  4.91it/s, batch_loss=0.0318, epoch_loss=0.0430, task=1, task_score=0.3011]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:07<00:03,  4.91it/s, batch_loss=0.0651, epoch_loss=0.0436, task=0, task_score=0.4684]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:07<00:03,  4.56it/s, batch_loss=0.0651, epoch_loss=0.0436, task=0, task_score=0.4684]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:08<00:03,  4.56it/s, batch_loss=0.0649, epoch_loss=0.0442, task=0, task_score=0.5135]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:08<00:02,  4.35it/s, batch_loss=0.0649, epoch_loss=0.0442, task=0, task_score=0.5135]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:08<00:02,  4.35it/s, batch_loss=0.0650, epoch_loss=0.0448, task=0, task_score=0.5135]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:08<00:03,  3.67it/s, batch_loss=0.0650, epoch_loss=0.0448, task=0, task_score=0.5135]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:08<00:03,  3.67it/s, batch_loss=0.0679, epoch_loss=0.0450, task=1, task_score=0.2440]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:08<00:02,  4.19it/s, batch_loss=0.0679, epoch_loss=0.0450, task=1, task_score=0.2440]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:09<00:02,  4.19it/s, batch_loss=0.0649, epoch_loss=0.0455, task=0, task_score=0.5084]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:09<00:02,  3.82it/s, batch_loss=0.0649, epoch_loss=0.0455, task=0, task_score=0.5084]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:09<00:02,  3.82it/s, batch_loss=0.0320, epoch_loss=0.0452, task=1, task_score=0.3851]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:09<00:02,  3.77it/s, batch_loss=0.0320, epoch_loss=0.0452, task=1, task_score=0.3851]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:09<00:02,  3.77it/s, batch_loss=0.0327, epoch_loss=0.0449, task=1, task_score=0.2225]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:09<00:02,  3.87it/s, batch_loss=0.0327, epoch_loss=0.0449, task=1, task_score=0.2225]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:09<00:02,  3.87it/s, batch_loss=0.0324, epoch_loss=0.0446, task=1, task_score=0.3032]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:09<00:01,  4.27it/s, batch_loss=0.0324, epoch_loss=0.0446, task=1, task_score=0.3032]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:09<00:01,  4.27it/s, batch_loss=0.0322, epoch_loss=0.0443, task=1, task_score=0.3053]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:09<00:01,  4.52it/s, batch_loss=0.0322, epoch_loss=0.0443, task=1, task_score=0.3053]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:10<00:01,  4.52it/s, batch_loss=0.0325, epoch_loss=0.0440, task=1, task_score=0.2772]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:10<00:01,  4.78it/s, batch_loss=0.0325, epoch_loss=0.0440, task=1, task_score=0.2772]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:10<00:01,  4.78it/s, batch_loss=0.0649, epoch_loss=0.0445, task=0, task_score=0.5152]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:10<00:00,  4.28it/s, batch_loss=0.0649, epoch_loss=0.0445, task=0, task_score=0.5152]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:10<00:00,  4.28it/s, batch_loss=0.0326, epoch_loss=0.0442, task=1, task_score=0.2723]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:10<00:00,  4.62it/s, batch_loss=0.0326, epoch_loss=0.0442, task=1, task_score=0.2723]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:10<00:00,  4.62it/s, batch_loss=0.0650, epoch_loss=0.0447, task=0, task_score=0.4386]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:10<00:00,  4.23it/s, batch_loss=0.0650, epoch_loss=0.0447, task=0, task_score=0.4386]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:11<00:00,  4.23it/s, batch_loss=0.0650, epoch_loss=0.0451, task=0, task_score=0.4113]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:11<00:00,  3.99it/s, batch_loss=0.0650, epoch_loss=0.0451, task=0, task_score=0.4113]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:11<00:00,  3.99it/s, batch_loss=0.0319, epoch_loss=0.0448, task=1, task_score=0.3052]\u001b[A\n",
      "Batch: 100%|██████████| 50/50 [00:11<00:00,  4.27it/s, batch_loss=0.0319, epoch_loss=0.0448, task=1, task_score=0.3052]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Evaluating model:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating model:  10%|█         | 4/39 [00:00<00:00, 35.51it/s]\u001b[A\n",
      "Evaluating model:  21%|██        | 8/39 [00:00<00:00, 35.06it/s]\u001b[A\n",
      "Evaluating model:  31%|███       | 12/39 [00:00<00:00, 33.94it/s]\u001b[A\n",
      "Evaluating model:  38%|███▊      | 15/39 [00:00<00:00, 31.52it/s]\u001b[A\n",
      "Evaluating model:  46%|████▌     | 18/39 [00:00<00:00, 30.75it/s]\u001b[A\n",
      "Evaluating model:  56%|█████▋    | 22/39 [00:00<00:00, 32.13it/s]\u001b[A\n",
      "Evaluating model:  64%|██████▍   | 25/39 [00:00<00:00, 24.63it/s]\u001b[A\n",
      "Evaluating model:  74%|███████▍  | 29/39 [00:00<00:00, 26.97it/s]\u001b[A\n",
      "Evaluating model:  85%|████████▍ | 33/39 [00:01<00:00, 28.83it/s]\u001b[A\n",
      "Evaluating model:  97%|█████████▋| 38/39 [00:01<00:00, 32.16it/s]\u001b[A\n",
      "Training model:  80%|████████  | 8/10 [01:37<00:24, 12.40s/it, dev_loss=0.0653, dev_score=0.4760, loss=0.0319]\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s, batch_loss=0.0323, epoch_loss=0.0323, task=1, task_score=0.3963]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:08,  5.63it/s, batch_loss=0.0323, epoch_loss=0.0323, task=1, task_score=0.3963]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:08,  5.63it/s, batch_loss=0.0651, epoch_loss=0.0487, task=0, task_score=0.3883]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:   4%|▍         | 2/50 [00:00<00:09,  5.08it/s, batch_loss=0.0651, epoch_loss=0.0487, task=0, task_score=0.3883]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:09,  5.08it/s, batch_loss=0.0649, epoch_loss=0.0541, task=0, task_score=0.4789]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:10,  4.50it/s, batch_loss=0.0649, epoch_loss=0.0541, task=0, task_score=0.4789]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:10,  4.50it/s, batch_loss=0.0648, epoch_loss=0.0568, task=0, task_score=0.4818]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:00<00:10,  4.28it/s, batch_loss=0.0648, epoch_loss=0.0568, task=0, task_score=0.4818]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:01<00:10,  4.28it/s, batch_loss=0.0649, epoch_loss=0.0584, task=0, task_score=0.4910]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:10,  4.17it/s, batch_loss=0.0649, epoch_loss=0.0584, task=0, task_score=0.4910]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:10,  4.17it/s, batch_loss=0.0327, epoch_loss=0.0541, task=1, task_score=0.2286]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:09,  4.55it/s, batch_loss=0.0327, epoch_loss=0.0541, task=1, task_score=0.2286]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:09,  4.55it/s, batch_loss=0.0649, epoch_loss=0.0557, task=0, task_score=0.4571]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:10,  4.11it/s, batch_loss=0.0649, epoch_loss=0.0557, task=0, task_score=0.4571]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:10,  4.11it/s, batch_loss=0.0653, epoch_loss=0.0569, task=0, task_score=0.5022]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:01<00:10,  3.83it/s, batch_loss=0.0653, epoch_loss=0.0569, task=0, task_score=0.5022]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:02<00:10,  3.83it/s, batch_loss=0.0656, epoch_loss=0.0578, task=0, task_score=0.4108]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:02<00:10,  4.06it/s, batch_loss=0.0656, epoch_loss=0.0578, task=0, task_score=0.4108]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:02<00:10,  4.06it/s, batch_loss=0.0323, epoch_loss=0.0553, task=1, task_score=0.2383]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:08,  4.49it/s, batch_loss=0.0323, epoch_loss=0.0553, task=1, task_score=0.2383]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:08,  4.49it/s, batch_loss=0.0649, epoch_loss=0.0562, task=0, task_score=0.5516]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:08,  4.57it/s, batch_loss=0.0649, epoch_loss=0.0562, task=0, task_score=0.5516]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:08,  4.57it/s, batch_loss=0.0650, epoch_loss=0.0569, task=0, task_score=0.4298]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:02<00:09,  4.11it/s, batch_loss=0.0650, epoch_loss=0.0569, task=0, task_score=0.4298]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:03<00:09,  4.11it/s, batch_loss=0.0649, epoch_loss=0.0575, task=0, task_score=0.5272]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:03<00:08,  4.19it/s, batch_loss=0.0649, epoch_loss=0.0575, task=0, task_score=0.5272]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:03<00:08,  4.19it/s, batch_loss=0.0319, epoch_loss=0.0557, task=1, task_score=0.3842]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:03<00:07,  4.50it/s, batch_loss=0.0319, epoch_loss=0.0557, task=1, task_score=0.3842]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:03<00:07,  4.50it/s, batch_loss=0.0322, epoch_loss=0.0541, task=1, task_score=0.2923]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:08,  4.31it/s, batch_loss=0.0322, epoch_loss=0.0541, task=1, task_score=0.2923]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:08,  4.31it/s, batch_loss=0.0649, epoch_loss=0.0548, task=0, task_score=0.5305]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:03<00:08,  3.99it/s, batch_loss=0.0649, epoch_loss=0.0548, task=0, task_score=0.5305]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:04<00:08,  3.99it/s, batch_loss=0.0326, epoch_loss=0.0535, task=1, task_score=0.2450]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:04<00:07,  4.34it/s, batch_loss=0.0326, epoch_loss=0.0535, task=1, task_score=0.2450]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:04<00:07,  4.34it/s, batch_loss=0.0652, epoch_loss=0.0541, task=0, task_score=0.4896]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:04<00:07,  4.23it/s, batch_loss=0.0652, epoch_loss=0.0541, task=0, task_score=0.4896]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:04<00:07,  4.23it/s, batch_loss=0.0649, epoch_loss=0.0547, task=0, task_score=0.5319]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:04<00:07,  4.21it/s, batch_loss=0.0649, epoch_loss=0.0547, task=0, task_score=0.5319]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:04<00:07,  4.21it/s, batch_loss=0.0651, epoch_loss=0.0552, task=0, task_score=0.5156]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:04<00:07,  4.17it/s, batch_loss=0.0651, epoch_loss=0.0552, task=0, task_score=0.5156]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:04<00:07,  4.17it/s, batch_loss=0.0324, epoch_loss=0.0541, task=1, task_score=0.3428]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:04<00:06,  4.48it/s, batch_loss=0.0324, epoch_loss=0.0541, task=1, task_score=0.3428]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:05<00:06,  4.48it/s, batch_loss=0.0328, epoch_loss=0.0532, task=1, task_score=0.1747]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:05<00:05,  4.78it/s, batch_loss=0.0328, epoch_loss=0.0532, task=1, task_score=0.1747]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:05<00:05,  4.78it/s, batch_loss=0.0650, epoch_loss=0.0537, task=0, task_score=0.4571]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:05<00:05,  4.70it/s, batch_loss=0.0650, epoch_loss=0.0537, task=0, task_score=0.4571]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:05<00:05,  4.70it/s, batch_loss=0.0650, epoch_loss=0.0542, task=0, task_score=0.4213]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:05<00:05,  4.63it/s, batch_loss=0.0650, epoch_loss=0.0542, task=0, task_score=0.4213]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:05<00:05,  4.63it/s, batch_loss=0.0650, epoch_loss=0.0546, task=0, task_score=0.4910]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:05<00:05,  4.29it/s, batch_loss=0.0650, epoch_loss=0.0546, task=0, task_score=0.4910]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:06<00:05,  4.29it/s, batch_loss=0.0650, epoch_loss=0.0550, task=0, task_score=0.2342]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:06<00:05,  4.48it/s, batch_loss=0.0650, epoch_loss=0.0550, task=0, task_score=0.2342]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:06<00:05,  4.48it/s, batch_loss=0.0650, epoch_loss=0.0554, task=0, task_score=0.5628]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:06<00:05,  4.46it/s, batch_loss=0.0650, epoch_loss=0.0554, task=0, task_score=0.5628]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:06<00:05,  4.46it/s, batch_loss=0.0647, epoch_loss=0.0557, task=0, task_score=0.5105]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:06<00:04,  4.51it/s, batch_loss=0.0647, epoch_loss=0.0557, task=0, task_score=0.5105]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:06<00:04,  4.51it/s, batch_loss=0.0322, epoch_loss=0.0549, task=1, task_score=0.2586]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:06<00:04,  4.79it/s, batch_loss=0.0322, epoch_loss=0.0549, task=1, task_score=0.2586]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:06<00:04,  4.79it/s, batch_loss=0.0651, epoch_loss=0.0552, task=0, task_score=0.4545]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:06<00:04,  4.73it/s, batch_loss=0.0651, epoch_loss=0.0552, task=0, task_score=0.4545]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:07<00:04,  4.73it/s, batch_loss=0.0650, epoch_loss=0.0555, task=0, task_score=0.4679]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:07<00:05,  3.77it/s, batch_loss=0.0650, epoch_loss=0.0555, task=0, task_score=0.4679]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:07<00:05,  3.77it/s, batch_loss=0.0319, epoch_loss=0.0548, task=1, task_score=0.2674]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:07<00:04,  4.24it/s, batch_loss=0.0319, epoch_loss=0.0548, task=1, task_score=0.2674]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:07<00:04,  4.24it/s, batch_loss=0.0650, epoch_loss=0.0551, task=0, task_score=0.2229]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:07<00:04,  3.90it/s, batch_loss=0.0650, epoch_loss=0.0551, task=0, task_score=0.2229]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:07<00:04,  3.90it/s, batch_loss=0.0650, epoch_loss=0.0554, task=0, task_score=0.1789]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:07<00:04,  3.99it/s, batch_loss=0.0650, epoch_loss=0.0554, task=0, task_score=0.1789]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:08<00:04,  3.99it/s, batch_loss=0.0650, epoch_loss=0.0557, task=0, task_score=0.2632]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  70%|███████   | 35/50 [00:08<00:03,  3.91it/s, batch_loss=0.0650, epoch_loss=0.0557, task=0, task_score=0.2632]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:08<00:03,  3.91it/s, batch_loss=0.0323, epoch_loss=0.0550, task=1, task_score=0.2419]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:08<00:03,  4.08it/s, batch_loss=0.0323, epoch_loss=0.0550, task=1, task_score=0.2419]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:08<00:03,  4.08it/s, batch_loss=0.0324, epoch_loss=0.0544, task=1, task_score=0.2005]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:08<00:02,  4.36it/s, batch_loss=0.0324, epoch_loss=0.0544, task=1, task_score=0.2005]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:08<00:02,  4.36it/s, batch_loss=0.0650, epoch_loss=0.0547, task=0, task_score=0.1172]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:08<00:02,  4.03it/s, batch_loss=0.0650, epoch_loss=0.0547, task=0, task_score=0.1172]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:09<00:02,  4.03it/s, batch_loss=0.0326, epoch_loss=0.0541, task=1, task_score=0.2038]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:09<00:02,  4.31it/s, batch_loss=0.0326, epoch_loss=0.0541, task=1, task_score=0.2038]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:09<00:02,  4.31it/s, batch_loss=0.0650, epoch_loss=0.0544, task=0, task_score=0.3905]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:09<00:02,  4.02it/s, batch_loss=0.0650, epoch_loss=0.0544, task=0, task_score=0.3905]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:09<00:02,  4.02it/s, batch_loss=0.0650, epoch_loss=0.0547, task=0, task_score=0.4234]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:09<00:02,  4.19it/s, batch_loss=0.0650, epoch_loss=0.0547, task=0, task_score=0.4234]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:09<00:02,  4.19it/s, batch_loss=0.0328, epoch_loss=0.0541, task=1, task_score=0.1804]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:09<00:01,  4.46it/s, batch_loss=0.0328, epoch_loss=0.0541, task=1, task_score=0.1804]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:10<00:01,  4.46it/s, batch_loss=0.0650, epoch_loss=0.0544, task=0, task_score=0.1552]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:10<00:01,  3.69it/s, batch_loss=0.0650, epoch_loss=0.0544, task=0, task_score=0.1552]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:10<00:01,  3.69it/s, batch_loss=0.0652, epoch_loss=0.0546, task=0, task_score=0.4483]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:10<00:01,  3.57it/s, batch_loss=0.0652, epoch_loss=0.0546, task=0, task_score=0.4483]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:10<00:01,  3.57it/s, batch_loss=0.0650, epoch_loss=0.0549, task=0, task_score=0.1172]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:10<00:01,  3.64it/s, batch_loss=0.0650, epoch_loss=0.0549, task=0, task_score=0.1172]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:11<00:01,  3.64it/s, batch_loss=0.0657, epoch_loss=0.0551, task=0, task_score=0.1467]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:11<00:01,  3.69it/s, batch_loss=0.0657, epoch_loss=0.0551, task=0, task_score=0.1467]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:11<00:01,  3.69it/s, batch_loss=0.0650, epoch_loss=0.0553, task=0, task_score=0.1672]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:11<00:00,  3.65it/s, batch_loss=0.0650, epoch_loss=0.0553, task=0, task_score=0.1672]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:11<00:00,  3.65it/s, batch_loss=0.0331, epoch_loss=0.0548, task=1, task_score=0.2260]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:11<00:00,  3.94it/s, batch_loss=0.0331, epoch_loss=0.0548, task=1, task_score=0.2260]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:11<00:00,  3.94it/s, batch_loss=0.0325, epoch_loss=0.0544, task=1, task_score=0.1964]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:11<00:00,  4.13it/s, batch_loss=0.0325, epoch_loss=0.0544, task=1, task_score=0.1964]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:11<00:00,  4.13it/s, batch_loss=0.0325, epoch_loss=0.0539, task=1, task_score=0.1988]\u001b[A\n",
      "Batch: 100%|██████████| 50/50 [00:11<00:00,  4.36it/s, batch_loss=0.0325, epoch_loss=0.0539, task=1, task_score=0.1988]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Evaluating model:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating model:   3%|▎         | 1/39 [00:00<00:03,  9.96it/s]\u001b[A\n",
      "Evaluating model:  10%|█         | 4/39 [00:00<00:02, 12.29it/s]\u001b[A\n",
      "Evaluating model:  21%|██        | 8/39 [00:00<00:02, 15.23it/s]\u001b[A\n",
      "Evaluating model:  28%|██▊       | 11/39 [00:00<00:01, 17.83it/s]\u001b[A\n",
      "Evaluating model:  38%|███▊      | 15/39 [00:00<00:01, 21.03it/s]\u001b[A\n",
      "Evaluating model:  46%|████▌     | 18/39 [00:00<00:00, 22.70it/s]\u001b[A\n",
      "Evaluating model:  54%|█████▍    | 21/39 [00:00<00:00, 23.30it/s]\u001b[A\n",
      "Evaluating model:  62%|██████▏   | 24/39 [00:00<00:00, 22.56it/s]\u001b[A\n",
      "Evaluating model:  72%|███████▏  | 28/39 [00:01<00:00, 25.30it/s]\u001b[A\n",
      "Evaluating model:  85%|████████▍ | 33/39 [00:01<00:00, 29.65it/s]\u001b[A\n",
      "Evaluating model:  95%|█████████▍| 37/39 [00:01<00:00, 31.01it/s]\u001b[A\n",
      "                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: Terminate\n",
      "Loading weights from epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "train_mtl_model(**modelling_vars, **batch_writing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1-score': [0.1656626310434239, 0.16474607084212997, 0.3628525784808495, 0.2057478353597029, 0.45509745543704383, 0.4970382299397844, 0.5228508795354752, 0.4760422276980435, 0.38235553670499867], 'precision': [0.5017581480139763, 0.5034403374896287, 0.49785796921926306, 0.5047894779895528, 0.5520911969897047, 0.5572674792282613, 0.5826826218550243, 0.550113937807486, 0.47901324015752633], 'recall': [0.5112941971323474, 0.5242604037906881, 0.498619957537155, 0.5108661070782805, 0.5292692792072291, 0.5325882110415087, 0.5479663420732219, 0.5280007574125222, 0.4876298388207742], 'accuracy': [0.18328623334679048, 0.1828825191764231, 0.37706903512313283, 0.21396851029471134, 0.5010092854259185, 0.5785224061364553, 0.6112232539362131, 0.540976988292289, 0.4113847396043601], 'loss': [0.06545948106336844, 0.06538571202567281, 0.06533544969308458, 0.065346574321311, 0.06526330964046474, 0.06538201244694598, 0.06518948852991836, 0.06531957334503802, 0.06541401819206795]}\n"
     ]
    }
   ],
   "source": [
    "print(dev_metrics.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s, batch_loss=0.0646, epoch_loss=0.0646, task=0, task_score=0.5995]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:12,  3.78it/s, batch_loss=0.0646, epoch_loss=0.0646, task=0, task_score=0.5995]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:12,  3.78it/s, batch_loss=0.0647, epoch_loss=0.0647, task=0, task_score=0.5594]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:12,  3.81it/s, batch_loss=0.0647, epoch_loss=0.0647, task=0, task_score=0.5594]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:01<00:12,  3.81it/s, batch_loss=0.0647, epoch_loss=0.0647, task=0, task_score=0.5319]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:01<00:16,  2.83it/s, batch_loss=0.0647, epoch_loss=0.0647, task=0, task_score=0.5319]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:01<00:16,  2.83it/s, batch_loss=0.0322, epoch_loss=0.0566, task=1, task_score=0.3101]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:01<00:14,  3.14it/s, batch_loss=0.0322, epoch_loss=0.0566, task=1, task_score=0.3101]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:01<00:14,  3.14it/s, batch_loss=0.0644, epoch_loss=0.0581, task=0, task_score=0.5594]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:13,  3.40it/s, batch_loss=0.0644, epoch_loss=0.0581, task=0, task_score=0.5594]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:13,  3.40it/s, batch_loss=0.0322, epoch_loss=0.0538, task=1, task_score=0.2417]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:11,  3.70it/s, batch_loss=0.0322, epoch_loss=0.0538, task=1, task_score=0.2417]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:11,  3.70it/s, batch_loss=0.0322, epoch_loss=0.0507, task=1, task_score=0.3491]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:02<00:11,  3.91it/s, batch_loss=0.0322, epoch_loss=0.0507, task=1, task_score=0.3491]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:02<00:11,  3.91it/s, batch_loss=0.0656, epoch_loss=0.0526, task=0, task_score=0.4393]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:02<00:11,  3.51it/s, batch_loss=0.0656, epoch_loss=0.0526, task=0, task_score=0.4393]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:02<00:11,  3.51it/s, batch_loss=0.0319, epoch_loss=0.0503, task=1, task_score=0.3024]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:02<00:10,  3.76it/s, batch_loss=0.0319, epoch_loss=0.0503, task=1, task_score=0.3024]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:02<00:10,  3.76it/s, batch_loss=0.0324, epoch_loss=0.0485, task=1, task_score=0.3073]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:09,  4.07it/s, batch_loss=0.0324, epoch_loss=0.0485, task=1, task_score=0.3073]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:09,  4.07it/s, batch_loss=0.0321, epoch_loss=0.0470, task=1, task_score=0.2803]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:09,  4.33it/s, batch_loss=0.0321, epoch_loss=0.0470, task=1, task_score=0.2803]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:03<00:09,  4.33it/s, batch_loss=0.0320, epoch_loss=0.0458, task=1, task_score=0.4106]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:03<00:08,  4.48it/s, batch_loss=0.0320, epoch_loss=0.0458, task=1, task_score=0.4106]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:03<00:08,  4.48it/s, batch_loss=0.0320, epoch_loss=0.0447, task=1, task_score=0.3321]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:03<00:07,  4.77it/s, batch_loss=0.0320, epoch_loss=0.0447, task=1, task_score=0.3321]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:03<00:07,  4.77it/s, batch_loss=0.0321, epoch_loss=0.0438, task=1, task_score=0.2854]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:03<00:07,  4.89it/s, batch_loss=0.0321, epoch_loss=0.0438, task=1, task_score=0.2854]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:03<00:07,  4.89it/s, batch_loss=0.0645, epoch_loss=0.0452, task=0, task_score=0.5319]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:08,  4.37it/s, batch_loss=0.0645, epoch_loss=0.0452, task=0, task_score=0.5319]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:04<00:08,  4.37it/s, batch_loss=0.0652, epoch_loss=0.0464, task=0, task_score=0.5156]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:04<00:08,  4.01it/s, batch_loss=0.0652, epoch_loss=0.0464, task=0, task_score=0.5156]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:04<00:08,  4.01it/s, batch_loss=0.0331, epoch_loss=0.0456, task=1, task_score=0.2354]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:04<00:07,  4.26it/s, batch_loss=0.0331, epoch_loss=0.0456, task=1, task_score=0.2354]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:04<00:07,  4.26it/s, batch_loss=0.0645, epoch_loss=0.0467, task=0, task_score=0.5509]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:04<00:11,  2.74it/s, batch_loss=0.0645, epoch_loss=0.0467, task=0, task_score=0.5509]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:05<00:11,  2.74it/s, batch_loss=0.0645, epoch_loss=0.0476, task=0, task_score=0.5509]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:05<00:11,  2.72it/s, batch_loss=0.0645, epoch_loss=0.0476, task=0, task_score=0.5509]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:05<00:11,  2.72it/s, batch_loss=0.0322, epoch_loss=0.0469, task=1, task_score=0.2790]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:05<00:09,  3.10it/s, batch_loss=0.0322, epoch_loss=0.0469, task=1, task_score=0.2790]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:05<00:09,  3.10it/s, batch_loss=0.0321, epoch_loss=0.0462, task=1, task_score=0.3209]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:05<00:08,  3.39it/s, batch_loss=0.0321, epoch_loss=0.0462, task=1, task_score=0.3209]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:06<00:08,  3.39it/s, batch_loss=0.0644, epoch_loss=0.0470, task=0, task_score=0.6257]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:06<00:08,  3.38it/s, batch_loss=0.0644, epoch_loss=0.0470, task=0, task_score=0.6257]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:06<00:08,  3.38it/s, batch_loss=0.0317, epoch_loss=0.0463, task=1, task_score=0.4600]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:06<00:07,  3.69it/s, batch_loss=0.0317, epoch_loss=0.0463, task=1, task_score=0.4600]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:06<00:07,  3.69it/s, batch_loss=0.0655, epoch_loss=0.0471, task=0, task_score=0.5031]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:06<00:07,  3.68it/s, batch_loss=0.0655, epoch_loss=0.0471, task=0, task_score=0.5031]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:06<00:07,  3.68it/s, batch_loss=0.0317, epoch_loss=0.0465, task=1, task_score=0.3542]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:06<00:06,  3.73it/s, batch_loss=0.0317, epoch_loss=0.0465, task=1, task_score=0.3542]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:07<00:06,  3.73it/s, batch_loss=0.0647, epoch_loss=0.0472, task=0, task_score=0.5039]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:07<00:06,  3.87it/s, batch_loss=0.0647, epoch_loss=0.0472, task=0, task_score=0.5039]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:07<00:06,  3.87it/s, batch_loss=0.0324, epoch_loss=0.0467, task=1, task_score=0.3260]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:07<00:05,  4.20it/s, batch_loss=0.0324, epoch_loss=0.0467, task=1, task_score=0.3260]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:07<00:05,  4.20it/s, batch_loss=0.0322, epoch_loss=0.0461, task=1, task_score=0.2816]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:07<00:05,  4.33it/s, batch_loss=0.0322, epoch_loss=0.0461, task=1, task_score=0.2816]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:07<00:05,  4.33it/s, batch_loss=0.0646, epoch_loss=0.0468, task=0, task_score=0.4797]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:07<00:04,  4.20it/s, batch_loss=0.0646, epoch_loss=0.0468, task=0, task_score=0.4797]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:08<00:04,  4.20it/s, batch_loss=0.0649, epoch_loss=0.0474, task=0, task_score=0.4776]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:08<00:04,  4.14it/s, batch_loss=0.0649, epoch_loss=0.0474, task=0, task_score=0.4776]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:08<00:04,  4.14it/s, batch_loss=0.0649, epoch_loss=0.0479, task=0, task_score=0.5084]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:08<00:04,  3.86it/s, batch_loss=0.0649, epoch_loss=0.0479, task=0, task_score=0.5084]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:08<00:04,  3.86it/s, batch_loss=0.0651, epoch_loss=0.0485, task=0, task_score=0.4691]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:08<00:04,  3.97it/s, batch_loss=0.0651, epoch_loss=0.0485, task=0, task_score=0.4691]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:08<00:04,  3.97it/s, batch_loss=0.0650, epoch_loss=0.0490, task=0, task_score=0.5022]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  66%|██████▌   | 33/50 [00:08<00:04,  4.16it/s, batch_loss=0.0650, epoch_loss=0.0490, task=0, task_score=0.5022]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:08<00:04,  4.16it/s, batch_loss=0.0655, epoch_loss=0.0495, task=0, task_score=0.3905]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:08<00:03,  4.17it/s, batch_loss=0.0655, epoch_loss=0.0495, task=0, task_score=0.3905]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:09<00:03,  4.17it/s, batch_loss=0.0324, epoch_loss=0.0490, task=1, task_score=0.2407]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:09<00:03,  4.43it/s, batch_loss=0.0324, epoch_loss=0.0490, task=1, task_score=0.2407]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:09<00:03,  4.43it/s, batch_loss=0.0648, epoch_loss=0.0494, task=0, task_score=0.5514]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:09<00:03,  4.43it/s, batch_loss=0.0648, epoch_loss=0.0494, task=0, task_score=0.5514]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:09<00:03,  4.43it/s, batch_loss=0.0651, epoch_loss=0.0498, task=0, task_score=0.4589]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:09<00:03,  4.33it/s, batch_loss=0.0651, epoch_loss=0.0498, task=0, task_score=0.4589]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:09<00:03,  4.33it/s, batch_loss=0.0646, epoch_loss=0.0502, task=0, task_score=0.5194]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:09<00:02,  4.25it/s, batch_loss=0.0646, epoch_loss=0.0502, task=0, task_score=0.5194]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:10<00:02,  4.25it/s, batch_loss=0.0647, epoch_loss=0.0506, task=0, task_score=0.5194]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:10<00:02,  3.90it/s, batch_loss=0.0647, epoch_loss=0.0506, task=0, task_score=0.5194]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:10<00:02,  3.90it/s, batch_loss=0.0652, epoch_loss=0.0510, task=0, task_score=0.3905]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:10<00:02,  4.02it/s, batch_loss=0.0652, epoch_loss=0.0510, task=0, task_score=0.3905]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:10<00:02,  4.02it/s, batch_loss=0.0326, epoch_loss=0.0505, task=1, task_score=0.1809]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:10<00:02,  4.37it/s, batch_loss=0.0326, epoch_loss=0.0505, task=1, task_score=0.1809]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:10<00:02,  4.37it/s, batch_loss=0.0332, epoch_loss=0.0501, task=1, task_score=0.2366]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:10<00:01,  4.74it/s, batch_loss=0.0332, epoch_loss=0.0501, task=1, task_score=0.2366]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:11<00:01,  4.74it/s, batch_loss=0.0649, epoch_loss=0.0505, task=0, task_score=0.5152]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:11<00:01,  4.62it/s, batch_loss=0.0649, epoch_loss=0.0505, task=0, task_score=0.5152]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:11<00:01,  4.62it/s, batch_loss=0.0320, epoch_loss=0.0500, task=1, task_score=0.3479]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:11<00:01,  4.73it/s, batch_loss=0.0320, epoch_loss=0.0500, task=1, task_score=0.3479]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:11<00:01,  4.73it/s, batch_loss=0.0649, epoch_loss=0.0504, task=0, task_score=0.4922]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:11<00:01,  4.52it/s, batch_loss=0.0649, epoch_loss=0.0504, task=0, task_score=0.4922]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:11<00:01,  4.52it/s, batch_loss=0.0323, epoch_loss=0.0500, task=1, task_score=0.2444]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:11<00:00,  4.71it/s, batch_loss=0.0323, epoch_loss=0.0500, task=1, task_score=0.2444]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:11<00:00,  4.71it/s, batch_loss=0.0316, epoch_loss=0.0496, task=1, task_score=0.3770]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:11<00:00,  4.89it/s, batch_loss=0.0316, epoch_loss=0.0496, task=1, task_score=0.3770]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:12<00:00,  4.89it/s, batch_loss=0.0319, epoch_loss=0.0492, task=1, task_score=0.4675]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:12<00:00,  5.11it/s, batch_loss=0.0319, epoch_loss=0.0492, task=1, task_score=0.4675]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:12<00:00,  5.11it/s, batch_loss=0.0323, epoch_loss=0.0489, task=1, task_score=0.2454]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:12<00:00,  5.29it/s, batch_loss=0.0323, epoch_loss=0.0489, task=1, task_score=0.2454]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:12<00:00,  5.29it/s, batch_loss=0.0647, epoch_loss=0.0492, task=0, task_score=0.5622]\u001b[A\n",
      "Batch: 100%|██████████| 50/50 [00:12<00:00,  4.31it/s, batch_loss=0.0647, epoch_loss=0.0492, task=0, task_score=0.5622]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Evaluating model:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating model:   3%|▎         | 1/39 [00:00<00:04,  8.28it/s]\u001b[A\n",
      "Evaluating model:   8%|▊         | 3/39 [00:00<00:03,  9.62it/s]\u001b[A\n",
      "Evaluating model:  13%|█▎        | 5/39 [00:00<00:03, 10.83it/s]\u001b[A\n",
      "Evaluating model:  15%|█▌        | 6/39 [00:00<00:03, 10.28it/s]\u001b[A\n",
      "Evaluating model:  21%|██        | 8/39 [00:00<00:02, 11.90it/s]\u001b[A\n",
      "Evaluating model:  26%|██▌       | 10/39 [00:00<00:02, 13.15it/s]\u001b[A\n",
      "Evaluating model:  31%|███       | 12/39 [00:00<00:01, 14.04it/s]\u001b[A\n",
      "Evaluating model:  38%|███▊      | 15/39 [00:00<00:01, 16.17it/s]\u001b[A\n",
      "Evaluating model:  46%|████▌     | 18/39 [00:01<00:01, 17.96it/s]\u001b[A\n",
      "Evaluating model:  51%|█████▏    | 20/39 [00:01<00:01, 17.21it/s]\u001b[A\n",
      "Evaluating model:  59%|█████▉    | 23/39 [00:01<00:00, 19.73it/s]\u001b[A\n",
      "Evaluating model:  67%|██████▋   | 26/39 [00:01<00:00, 21.25it/s]\u001b[A\n",
      "Evaluating model:  74%|███████▍  | 29/39 [00:01<00:00, 22.55it/s]\u001b[A\n",
      "Evaluating model:  82%|████████▏ | 32/39 [00:01<00:00, 22.52it/s]\u001b[A\n",
      "Evaluating model:  90%|████████▉ | 35/39 [00:01<00:00, 21.93it/s]\u001b[A\n",
      "Evaluating model:  97%|█████████▋| 38/39 [00:02<00:00, 19.04it/s]\u001b[A\n",
      "Training model:  10%|█         | 1/10 [00:14<02:13, 14.78s/it, dev_loss=0.0651, dev_score=0.5129, loss=0.0647]\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s, batch_loss=0.0650, epoch_loss=0.0650, task=0, task_score=0.4589]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:11,  4.13it/s, batch_loss=0.0650, epoch_loss=0.0650, task=0, task_score=0.4589]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:11,  4.13it/s, batch_loss=0.0319, epoch_loss=0.0485, task=1, task_score=0.3241]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:10,  4.41it/s, batch_loss=0.0319, epoch_loss=0.0485, task=1, task_score=0.3241]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:10,  4.41it/s, batch_loss=0.0644, epoch_loss=0.0538, task=0, task_score=0.5797]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:11,  4.08it/s, batch_loss=0.0644, epoch_loss=0.0538, task=0, task_score=0.5797]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:11,  4.08it/s, batch_loss=0.0322, epoch_loss=0.0484, task=1, task_score=0.2776]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:00<00:10,  4.20it/s, batch_loss=0.0322, epoch_loss=0.0484, task=1, task_score=0.2776]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:01<00:10,  4.20it/s, batch_loss=0.0650, epoch_loss=0.0517, task=0, task_score=0.5039]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:11,  4.07it/s, batch_loss=0.0650, epoch_loss=0.0517, task=0, task_score=0.5039]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:11,  4.07it/s, batch_loss=0.0318, epoch_loss=0.0484, task=1, task_score=0.3376]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:10,  4.24it/s, batch_loss=0.0318, epoch_loss=0.0484, task=1, task_score=0.3376]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:10,  4.24it/s, batch_loss=0.0700, epoch_loss=0.0495, task=1, task_score=0.2162]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:08,  4.80it/s, batch_loss=0.0700, epoch_loss=0.0495, task=1, task_score=0.2162]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:08,  4.80it/s, batch_loss=0.0649, epoch_loss=0.0516, task=0, task_score=0.5656]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:01<00:11,  3.76it/s, batch_loss=0.0649, epoch_loss=0.0516, task=0, task_score=0.5656]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:02<00:11,  3.76it/s, batch_loss=0.0321, epoch_loss=0.0493, task=1, task_score=0.3344]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:02<00:10,  3.86it/s, batch_loss=0.0321, epoch_loss=0.0493, task=1, task_score=0.3344]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:02<00:10,  3.86it/s, batch_loss=0.0322, epoch_loss=0.0475, task=1, task_score=0.2396]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:09,  4.24it/s, batch_loss=0.0322, epoch_loss=0.0475, task=1, task_score=0.2396]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  20%|██        | 10/50 [00:02<00:09,  4.24it/s, batch_loss=0.0647, epoch_loss=0.0491, task=0, task_score=0.5995]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:09,  4.13it/s, batch_loss=0.0647, epoch_loss=0.0491, task=0, task_score=0.5995]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:09,  4.13it/s, batch_loss=0.0328, epoch_loss=0.0477, task=1, task_score=0.2253]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:02<00:08,  4.29it/s, batch_loss=0.0328, epoch_loss=0.0477, task=1, task_score=0.2253]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:03<00:08,  4.29it/s, batch_loss=0.0317, epoch_loss=0.0464, task=1, task_score=0.3261]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:03<00:08,  4.31it/s, batch_loss=0.0317, epoch_loss=0.0464, task=1, task_score=0.3261]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:03<00:08,  4.31it/s, batch_loss=0.0321, epoch_loss=0.0453, task=1, task_score=0.3000]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:03<00:08,  4.44it/s, batch_loss=0.0321, epoch_loss=0.0453, task=1, task_score=0.3000]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:03<00:08,  4.44it/s, batch_loss=0.0645, epoch_loss=0.0467, task=0, task_score=0.5765]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:08,  4.05it/s, batch_loss=0.0645, epoch_loss=0.0467, task=0, task_score=0.5765]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:08,  4.05it/s, batch_loss=0.0323, epoch_loss=0.0457, task=1, task_score=0.2888]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:03<00:08,  4.19it/s, batch_loss=0.0323, epoch_loss=0.0457, task=1, task_score=0.2888]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:04<00:08,  4.19it/s, batch_loss=0.0653, epoch_loss=0.0469, task=0, task_score=0.4167]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:04<00:08,  4.08it/s, batch_loss=0.0653, epoch_loss=0.0469, task=0, task_score=0.4167]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:04<00:08,  4.08it/s, batch_loss=0.0319, epoch_loss=0.0461, task=1, task_score=0.3558]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:04<00:07,  4.36it/s, batch_loss=0.0319, epoch_loss=0.0461, task=1, task_score=0.3558]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:04<00:07,  4.36it/s, batch_loss=0.0327, epoch_loss=0.0453, task=1, task_score=0.2162]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:04<00:06,  4.54it/s, batch_loss=0.0327, epoch_loss=0.0453, task=1, task_score=0.2162]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:04<00:06,  4.54it/s, batch_loss=0.0650, epoch_loss=0.0463, task=0, task_score=0.4776]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:04<00:06,  4.33it/s, batch_loss=0.0650, epoch_loss=0.0463, task=0, task_score=0.4776]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:04<00:06,  4.33it/s, batch_loss=0.0318, epoch_loss=0.0456, task=1, task_score=0.3759]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:04<00:06,  4.43it/s, batch_loss=0.0318, epoch_loss=0.0456, task=1, task_score=0.3759]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:05<00:06,  4.43it/s, batch_loss=0.0321, epoch_loss=0.0450, task=1, task_score=0.2508]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:05<00:06,  4.52it/s, batch_loss=0.0321, epoch_loss=0.0450, task=1, task_score=0.2508]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:05<00:06,  4.52it/s, batch_loss=0.0648, epoch_loss=0.0459, task=0, task_score=0.5194]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:05<00:06,  4.21it/s, batch_loss=0.0648, epoch_loss=0.0459, task=0, task_score=0.5194]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:05<00:06,  4.21it/s, batch_loss=0.0651, epoch_loss=0.0467, task=0, task_score=0.3992]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:05<00:06,  4.19it/s, batch_loss=0.0651, epoch_loss=0.0467, task=0, task_score=0.3992]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:05<00:06,  4.19it/s, batch_loss=0.0651, epoch_loss=0.0475, task=0, task_score=0.4108]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:05<00:06,  3.94it/s, batch_loss=0.0651, epoch_loss=0.0475, task=0, task_score=0.4108]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:06<00:06,  3.94it/s, batch_loss=0.0319, epoch_loss=0.0468, task=1, task_score=0.3720]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:06<00:05,  4.14it/s, batch_loss=0.0319, epoch_loss=0.0468, task=1, task_score=0.3720]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:06<00:05,  4.14it/s, batch_loss=0.0327, epoch_loss=0.0463, task=1, task_score=0.2424]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:06<00:05,  4.30it/s, batch_loss=0.0327, epoch_loss=0.0463, task=1, task_score=0.2424]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:06<00:05,  4.30it/s, batch_loss=0.0323, epoch_loss=0.0458, task=1, task_score=0.3079]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:06<00:04,  4.53it/s, batch_loss=0.0323, epoch_loss=0.0458, task=1, task_score=0.3079]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:06<00:04,  4.53it/s, batch_loss=0.0325, epoch_loss=0.0453, task=1, task_score=0.3365]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:06<00:04,  4.53it/s, batch_loss=0.0325, epoch_loss=0.0453, task=1, task_score=0.3365]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:07<00:04,  4.53it/s, batch_loss=0.0324, epoch_loss=0.0449, task=1, task_score=0.3000]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:07<00:04,  4.43it/s, batch_loss=0.0324, epoch_loss=0.0449, task=1, task_score=0.3000]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:07<00:04,  4.43it/s, batch_loss=0.0649, epoch_loss=0.0455, task=0, task_score=0.5249]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:07<00:05,  3.69it/s, batch_loss=0.0649, epoch_loss=0.0455, task=0, task_score=0.5249]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:07<00:05,  3.69it/s, batch_loss=0.0651, epoch_loss=0.0462, task=0, task_score=0.4079]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:07<00:04,  3.62it/s, batch_loss=0.0651, epoch_loss=0.0462, task=0, task_score=0.4079]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:07<00:04,  3.62it/s, batch_loss=0.0651, epoch_loss=0.0468, task=0, task_score=0.4805]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:07<00:04,  3.73it/s, batch_loss=0.0651, epoch_loss=0.0468, task=0, task_score=0.4805]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:08<00:04,  3.73it/s, batch_loss=0.0323, epoch_loss=0.0463, task=1, task_score=0.2622]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:08<00:03,  4.08it/s, batch_loss=0.0323, epoch_loss=0.0463, task=1, task_score=0.2622]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:08<00:03,  4.08it/s, batch_loss=0.0656, epoch_loss=0.0469, task=0, task_score=0.4921]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:08<00:03,  4.11it/s, batch_loss=0.0656, epoch_loss=0.0469, task=0, task_score=0.4921]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:08<00:03,  4.11it/s, batch_loss=0.0652, epoch_loss=0.0474, task=0, task_score=0.4182]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:08<00:03,  3.88it/s, batch_loss=0.0652, epoch_loss=0.0474, task=0, task_score=0.4182]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:08<00:03,  3.88it/s, batch_loss=0.0329, epoch_loss=0.0470, task=1, task_score=0.1926]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:08<00:03,  4.21it/s, batch_loss=0.0329, epoch_loss=0.0470, task=1, task_score=0.1926]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:09<00:03,  4.21it/s, batch_loss=0.0323, epoch_loss=0.0466, task=1, task_score=0.2483]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:09<00:02,  4.31it/s, batch_loss=0.0323, epoch_loss=0.0466, task=1, task_score=0.2483]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:09<00:02,  4.31it/s, batch_loss=0.0653, epoch_loss=0.0471, task=0, task_score=0.5393]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:09<00:02,  4.10it/s, batch_loss=0.0653, epoch_loss=0.0471, task=0, task_score=0.5393]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:09<00:02,  4.10it/s, batch_loss=0.0647, epoch_loss=0.0475, task=0, task_score=0.5152]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:09<00:02,  3.50it/s, batch_loss=0.0647, epoch_loss=0.0475, task=0, task_score=0.5152]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:09<00:02,  3.50it/s, batch_loss=0.0651, epoch_loss=0.0480, task=0, task_score=0.4079]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:09<00:02,  3.56it/s, batch_loss=0.0651, epoch_loss=0.0480, task=0, task_score=0.4079]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:10<00:02,  3.56it/s, batch_loss=0.0655, epoch_loss=0.0484, task=0, task_score=0.4572]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:10<00:02,  3.69it/s, batch_loss=0.0655, epoch_loss=0.0484, task=0, task_score=0.4572]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:10<00:02,  3.69it/s, batch_loss=0.0643, epoch_loss=0.0488, task=0, task_score=0.5973]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:10<00:01,  3.63it/s, batch_loss=0.0643, epoch_loss=0.0488, task=0, task_score=0.5973]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  86%|████████▌ | 43/50 [00:11<00:01,  3.63it/s, batch_loss=0.0652, epoch_loss=0.0492, task=0, task_score=0.4231]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:11<00:02,  2.82it/s, batch_loss=0.0652, epoch_loss=0.0492, task=0, task_score=0.4231]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:11<00:02,  2.82it/s, batch_loss=0.0323, epoch_loss=0.0488, task=1, task_score=0.2773]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:11<00:01,  3.22it/s, batch_loss=0.0323, epoch_loss=0.0488, task=1, task_score=0.2773]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:11<00:01,  3.22it/s, batch_loss=0.0322, epoch_loss=0.0484, task=1, task_score=0.2962]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:11<00:01,  3.68it/s, batch_loss=0.0322, epoch_loss=0.0484, task=1, task_score=0.2962]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:11<00:01,  3.68it/s, batch_loss=0.0650, epoch_loss=0.0488, task=0, task_score=0.5509]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:11<00:00,  3.76it/s, batch_loss=0.0650, epoch_loss=0.0488, task=0, task_score=0.5509]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:11<00:00,  3.76it/s, batch_loss=0.0650, epoch_loss=0.0491, task=0, task_score=0.4971]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:11<00:00,  3.73it/s, batch_loss=0.0650, epoch_loss=0.0491, task=0, task_score=0.4971]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:12<00:00,  3.73it/s, batch_loss=0.0649, epoch_loss=0.0494, task=0, task_score=0.5156]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:12<00:00,  3.28it/s, batch_loss=0.0649, epoch_loss=0.0494, task=0, task_score=0.5156]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:12<00:00,  3.28it/s, batch_loss=0.0324, epoch_loss=0.0491, task=1, task_score=0.2912]\u001b[A\n",
      "Batch: 100%|██████████| 50/50 [00:12<00:00,  3.71it/s, batch_loss=0.0324, epoch_loss=0.0491, task=1, task_score=0.2912]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Evaluating model:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating model:   5%|▌         | 2/39 [00:00<00:02, 16.78it/s]\u001b[A\n",
      "Evaluating model:  13%|█▎        | 5/39 [00:00<00:01, 19.19it/s]\u001b[A\n",
      "Evaluating model:  21%|██        | 8/39 [00:00<00:01, 20.62it/s]\u001b[A\n",
      "Evaluating model:  28%|██▊       | 11/39 [00:00<00:01, 21.75it/s]\u001b[A\n",
      "Evaluating model:  36%|███▌      | 14/39 [00:00<00:01, 23.33it/s]\u001b[A\n",
      "Evaluating model:  44%|████▎     | 17/39 [00:00<00:00, 24.59it/s]\u001b[A\n",
      "Evaluating model:  51%|█████▏    | 20/39 [00:00<00:00, 20.94it/s]\u001b[A\n",
      "Evaluating model:  59%|█████▉    | 23/39 [00:00<00:00, 22.19it/s]\u001b[A\n",
      "Evaluating model:  67%|██████▋   | 26/39 [00:01<00:00, 21.53it/s]\u001b[A\n",
      "Evaluating model:  74%|███████▍  | 29/39 [00:01<00:00, 22.33it/s]\u001b[A\n",
      "Evaluating model:  82%|████████▏ | 32/39 [00:01<00:00, 23.92it/s]\u001b[A\n",
      "Evaluating model:  90%|████████▉ | 35/39 [00:01<00:00, 19.82it/s]\u001b[A\n",
      "Evaluating model:  97%|█████████▋| 38/39 [00:01<00:00, 21.92it/s]\u001b[A\n",
      "Training model:  20%|██        | 2/10 [00:29<01:57, 14.68s/it, dev_loss=0.0653, dev_score=0.5178, loss=0.0324]\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s, batch_loss=0.0320, epoch_loss=0.0320, task=1, task_score=0.3238]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:07,  6.14it/s, batch_loss=0.0320, epoch_loss=0.0320, task=1, task_score=0.3238]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:07,  6.14it/s, batch_loss=0.0692, epoch_loss=0.0415, task=1, task_score=0.3250]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:07,  6.55it/s, batch_loss=0.0692, epoch_loss=0.0415, task=1, task_score=0.3250]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:07,  6.55it/s, batch_loss=0.0688, epoch_loss=0.0471, task=1, task_score=0.2632]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:07,  6.16it/s, batch_loss=0.0688, epoch_loss=0.0471, task=1, task_score=0.2632]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:07,  6.16it/s, batch_loss=0.0324, epoch_loss=0.0416, task=1, task_score=0.2969]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:00<00:08,  5.57it/s, batch_loss=0.0324, epoch_loss=0.0416, task=1, task_score=0.2969]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:00<00:08,  5.57it/s, batch_loss=0.0322, epoch_loss=0.0391, task=1, task_score=0.3166]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:00<00:08,  5.57it/s, batch_loss=0.0322, epoch_loss=0.0391, task=1, task_score=0.3166]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:08,  5.57it/s, batch_loss=0.0331, epoch_loss=0.0378, task=1, task_score=0.2010]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:07,  5.70it/s, batch_loss=0.0331, epoch_loss=0.0378, task=1, task_score=0.2010]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:07,  5.70it/s, batch_loss=0.0314, epoch_loss=0.0367, task=1, task_score=0.3781]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:07,  5.44it/s, batch_loss=0.0314, epoch_loss=0.0367, task=1, task_score=0.3781]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:07,  5.44it/s, batch_loss=0.0320, epoch_loss=0.0360, task=1, task_score=0.2886]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:01<00:07,  5.49it/s, batch_loss=0.0320, epoch_loss=0.0360, task=1, task_score=0.2886]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:01<00:07,  5.49it/s, batch_loss=0.0654, epoch_loss=0.0398, task=0, task_score=0.4971]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:01<00:09,  4.39it/s, batch_loss=0.0654, epoch_loss=0.0398, task=0, task_score=0.4971]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:01<00:09,  4.39it/s, batch_loss=0.0323, epoch_loss=0.0390, task=1, task_score=0.3252]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:01<00:08,  4.62it/s, batch_loss=0.0323, epoch_loss=0.0390, task=1, task_score=0.3252]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:08,  4.62it/s, batch_loss=0.0324, epoch_loss=0.0383, task=1, task_score=0.2718]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:08,  4.78it/s, batch_loss=0.0324, epoch_loss=0.0383, task=1, task_score=0.2718]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:08,  4.78it/s, batch_loss=0.0654, epoch_loss=0.0408, task=0, task_score=0.5319]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:02<00:08,  4.28it/s, batch_loss=0.0654, epoch_loss=0.0408, task=0, task_score=0.5319]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:02<00:08,  4.28it/s, batch_loss=0.0653, epoch_loss=0.0429, task=0, task_score=0.5072]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:02<00:09,  4.00it/s, batch_loss=0.0653, epoch_loss=0.0429, task=0, task_score=0.5072]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:02<00:09,  4.00it/s, batch_loss=0.0654, epoch_loss=0.0447, task=0, task_score=0.3905]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:02<00:08,  4.15it/s, batch_loss=0.0654, epoch_loss=0.0447, task=0, task_score=0.3905]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:03<00:08,  4.15it/s, batch_loss=0.0652, epoch_loss=0.0462, task=0, task_score=0.4108]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:08,  4.19it/s, batch_loss=0.0652, epoch_loss=0.0462, task=0, task_score=0.4108]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:08,  4.19it/s, batch_loss=0.0703, epoch_loss=0.0468, task=1, task_score=0.3778]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:03<00:06,  4.86it/s, batch_loss=0.0703, epoch_loss=0.0468, task=1, task_score=0.3778]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:03<00:06,  4.86it/s, batch_loss=0.0649, epoch_loss=0.0480, task=0, task_score=0.5765]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:03<00:07,  4.57it/s, batch_loss=0.0649, epoch_loss=0.0480, task=0, task_score=0.5765]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:03<00:07,  4.57it/s, batch_loss=0.0653, epoch_loss=0.0491, task=0, task_score=0.4080]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:03<00:07,  4.45it/s, batch_loss=0.0653, epoch_loss=0.0491, task=0, task_score=0.4080]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:03<00:07,  4.45it/s, batch_loss=0.0328, epoch_loss=0.0481, task=1, task_score=0.2189]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:03<00:06,  4.70it/s, batch_loss=0.0328, epoch_loss=0.0481, task=1, task_score=0.2189]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:04<00:06,  4.70it/s, batch_loss=0.0648, epoch_loss=0.0490, task=0, task_score=0.5000]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:04<00:08,  3.63it/s, batch_loss=0.0648, epoch_loss=0.0490, task=0, task_score=0.5000]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:04<00:08,  3.63it/s, batch_loss=0.0320, epoch_loss=0.0481, task=1, task_score=0.2704]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:04<00:07,  4.04it/s, batch_loss=0.0320, epoch_loss=0.0481, task=1, task_score=0.2704]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  42%|████▏     | 21/50 [00:04<00:07,  4.04it/s, batch_loss=0.0322, epoch_loss=0.0474, task=1, task_score=0.2718]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:04<00:06,  4.36it/s, batch_loss=0.0322, epoch_loss=0.0474, task=1, task_score=0.2718]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:04<00:06,  4.36it/s, batch_loss=0.0650, epoch_loss=0.0482, task=0, task_score=0.4488]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:04<00:06,  4.36it/s, batch_loss=0.0650, epoch_loss=0.0482, task=0, task_score=0.4488]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:05<00:06,  4.36it/s, batch_loss=0.0650, epoch_loss=0.0489, task=0, task_score=0.5039]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:05<00:06,  4.07it/s, batch_loss=0.0650, epoch_loss=0.0489, task=0, task_score=0.5039]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:05<00:06,  4.07it/s, batch_loss=0.0318, epoch_loss=0.0482, task=1, task_score=0.3451]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:05<00:05,  4.51it/s, batch_loss=0.0318, epoch_loss=0.0482, task=1, task_score=0.3451]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:05<00:05,  4.51it/s, batch_loss=0.0647, epoch_loss=0.0489, task=0, task_score=0.5646]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:05<00:05,  4.38it/s, batch_loss=0.0647, epoch_loss=0.0489, task=0, task_score=0.5646]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:05<00:05,  4.38it/s, batch_loss=0.0318, epoch_loss=0.0482, task=1, task_score=0.3363]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:05<00:05,  4.60it/s, batch_loss=0.0318, epoch_loss=0.0482, task=1, task_score=0.3363]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:06<00:05,  4.60it/s, batch_loss=0.0650, epoch_loss=0.0489, task=0, task_score=0.4688]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:06<00:04,  4.53it/s, batch_loss=0.0650, epoch_loss=0.0489, task=0, task_score=0.4688]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:06<00:04,  4.53it/s, batch_loss=0.0329, epoch_loss=0.0483, task=1, task_score=0.2553]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:06<00:04,  4.74it/s, batch_loss=0.0329, epoch_loss=0.0483, task=1, task_score=0.2553]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:06<00:04,  4.74it/s, batch_loss=0.0647, epoch_loss=0.0488, task=0, task_score=0.5022]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:06<00:04,  4.45it/s, batch_loss=0.0647, epoch_loss=0.0488, task=0, task_score=0.5022]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:06<00:04,  4.45it/s, batch_loss=0.0316, epoch_loss=0.0483, task=1, task_score=0.3998]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:06<00:03,  4.77it/s, batch_loss=0.0316, epoch_loss=0.0483, task=1, task_score=0.3998]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:07<00:03,  4.77it/s, batch_loss=0.0648, epoch_loss=0.0488, task=0, task_score=0.4684]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:07<00:04,  3.92it/s, batch_loss=0.0648, epoch_loss=0.0488, task=0, task_score=0.4684]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:07<00:04,  3.92it/s, batch_loss=0.0320, epoch_loss=0.0483, task=1, task_score=0.3440]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:07<00:03,  4.31it/s, batch_loss=0.0320, epoch_loss=0.0483, task=1, task_score=0.3440]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:07<00:03,  4.31it/s, batch_loss=0.0649, epoch_loss=0.0488, task=0, task_score=0.4572]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:07<00:03,  4.23it/s, batch_loss=0.0649, epoch_loss=0.0488, task=0, task_score=0.4572]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:07<00:03,  4.23it/s, batch_loss=0.0327, epoch_loss=0.0483, task=1, task_score=0.2614]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:07<00:03,  4.68it/s, batch_loss=0.0327, epoch_loss=0.0483, task=1, task_score=0.2614]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:07<00:03,  4.68it/s, batch_loss=0.0654, epoch_loss=0.0488, task=0, task_score=0.4691]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:07<00:03,  4.62it/s, batch_loss=0.0654, epoch_loss=0.0488, task=0, task_score=0.4691]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:08<00:03,  4.62it/s, batch_loss=0.0646, epoch_loss=0.0493, task=0, task_score=0.6382]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:08<00:02,  4.49it/s, batch_loss=0.0646, epoch_loss=0.0493, task=0, task_score=0.6382]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:08<00:02,  4.49it/s, batch_loss=0.0652, epoch_loss=0.0497, task=0, task_score=0.3720]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:08<00:02,  4.42it/s, batch_loss=0.0652, epoch_loss=0.0497, task=0, task_score=0.3720]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:08<00:02,  4.42it/s, batch_loss=0.0649, epoch_loss=0.0501, task=0, task_score=0.4805]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:08<00:02,  4.34it/s, batch_loss=0.0649, epoch_loss=0.0501, task=0, task_score=0.4805]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:08<00:02,  4.34it/s, batch_loss=0.0329, epoch_loss=0.0497, task=1, task_score=0.2307]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:08<00:02,  4.72it/s, batch_loss=0.0329, epoch_loss=0.0497, task=1, task_score=0.2307]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:08<00:02,  4.72it/s, batch_loss=0.0326, epoch_loss=0.0492, task=1, task_score=0.2565]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:08<00:01,  4.73it/s, batch_loss=0.0326, epoch_loss=0.0492, task=1, task_score=0.2565]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:09<00:01,  4.73it/s, batch_loss=0.0649, epoch_loss=0.0496, task=0, task_score=0.5039]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:09<00:01,  4.38it/s, batch_loss=0.0649, epoch_loss=0.0496, task=0, task_score=0.5039]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:09<00:01,  4.38it/s, batch_loss=0.0320, epoch_loss=0.0492, task=1, task_score=0.2209]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:09<00:01,  4.74it/s, batch_loss=0.0320, epoch_loss=0.0492, task=1, task_score=0.2209]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:09<00:01,  4.74it/s, batch_loss=0.0649, epoch_loss=0.0496, task=0, task_score=0.5759]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:09<00:01,  4.38it/s, batch_loss=0.0649, epoch_loss=0.0496, task=0, task_score=0.5759]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:09<00:01,  4.38it/s, batch_loss=0.0323, epoch_loss=0.0492, task=1, task_score=0.2064]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:09<00:01,  4.71it/s, batch_loss=0.0323, epoch_loss=0.0492, task=1, task_score=0.2064]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:10<00:01,  4.71it/s, batch_loss=0.0647, epoch_loss=0.0495, task=0, task_score=0.5248]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:10<00:00,  4.72it/s, batch_loss=0.0647, epoch_loss=0.0495, task=0, task_score=0.5248]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:10<00:00,  4.72it/s, batch_loss=0.0326, epoch_loss=0.0491, task=1, task_score=0.1536]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:10<00:00,  5.04it/s, batch_loss=0.0326, epoch_loss=0.0491, task=1, task_score=0.1536]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:10<00:00,  5.04it/s, batch_loss=0.0646, epoch_loss=0.0495, task=0, task_score=0.5749]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:10<00:00,  3.89it/s, batch_loss=0.0646, epoch_loss=0.0495, task=0, task_score=0.5749]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:10<00:00,  3.89it/s, batch_loss=0.0648, epoch_loss=0.0498, task=0, task_score=0.5636]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:10<00:00,  3.78it/s, batch_loss=0.0648, epoch_loss=0.0498, task=0, task_score=0.5636]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:11<00:00,  3.78it/s, batch_loss=0.0324, epoch_loss=0.0494, task=1, task_score=0.2565]\u001b[A\n",
      "Batch: 100%|██████████| 50/50 [00:11<00:00,  4.04it/s, batch_loss=0.0324, epoch_loss=0.0494, task=1, task_score=0.2565]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Evaluating model:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating model:   5%|▌         | 2/39 [00:00<00:02, 18.05it/s]\u001b[A\n",
      "Evaluating model:  13%|█▎        | 5/39 [00:00<00:01, 19.32it/s]\u001b[A\n",
      "Evaluating model:  23%|██▎       | 9/39 [00:00<00:01, 22.22it/s]\u001b[A\n",
      "Evaluating model:  33%|███▎      | 13/39 [00:00<00:01, 25.25it/s]\u001b[A\n",
      "Evaluating model:  41%|████      | 16/39 [00:00<00:01, 22.53it/s]\u001b[A\n",
      "Evaluating model:  49%|████▊     | 19/39 [00:00<00:00, 24.34it/s]\u001b[A\n",
      "Evaluating model:  56%|█████▋    | 22/39 [00:00<00:00, 25.21it/s]\u001b[A\n",
      "Evaluating model:  67%|██████▋   | 26/39 [00:00<00:00, 27.08it/s]\u001b[A\n",
      "Evaluating model:  77%|███████▋  | 30/39 [00:01<00:00, 29.45it/s]\u001b[A\n",
      "Evaluating model:  87%|████████▋ | 34/39 [00:01<00:00, 30.90it/s]\u001b[A\n",
      "Evaluating model:  97%|█████████▋| 38/39 [00:01<00:00, 31.51it/s]\u001b[A\n",
      "Training model:  30%|███       | 3/10 [00:41<01:38, 14.08s/it, dev_loss=0.0651, dev_score=0.5324, loss=0.0324]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s, batch_loss=0.0321, epoch_loss=0.0321, task=1, task_score=0.2528]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:07,  6.62it/s, batch_loss=0.0321, epoch_loss=0.0321, task=1, task_score=0.2528]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:07,  6.62it/s, batch_loss=0.0646, epoch_loss=0.0483, task=0, task_score=0.6382]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:08,  5.67it/s, batch_loss=0.0646, epoch_loss=0.0483, task=0, task_score=0.6382]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:08,  5.67it/s, batch_loss=0.0652, epoch_loss=0.0539, task=0, task_score=0.5656]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:10,  4.65it/s, batch_loss=0.0652, epoch_loss=0.0539, task=0, task_score=0.5656]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:10,  4.65it/s, batch_loss=0.0323, epoch_loss=0.0485, task=1, task_score=0.1465]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:00<00:09,  4.88it/s, batch_loss=0.0323, epoch_loss=0.0485, task=1, task_score=0.1465]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:01<00:09,  4.88it/s, batch_loss=0.0324, epoch_loss=0.0453, task=1, task_score=0.1706]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:08,  5.05it/s, batch_loss=0.0324, epoch_loss=0.0453, task=1, task_score=0.1706]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:08,  5.05it/s, batch_loss=0.0653, epoch_loss=0.0486, task=0, task_score=0.3828]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:09,  4.79it/s, batch_loss=0.0653, epoch_loss=0.0486, task=0, task_score=0.3828]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:09,  4.79it/s, batch_loss=0.0319, epoch_loss=0.0462, task=1, task_score=0.2281]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:08,  5.09it/s, batch_loss=0.0319, epoch_loss=0.0462, task=1, task_score=0.2281]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:08,  5.09it/s, batch_loss=0.0650, epoch_loss=0.0486, task=0, task_score=0.4873]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:01<00:08,  4.94it/s, batch_loss=0.0650, epoch_loss=0.0486, task=0, task_score=0.4873]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:01<00:08,  4.94it/s, batch_loss=0.0319, epoch_loss=0.0467, task=1, task_score=0.2371]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:01<00:08,  4.99it/s, batch_loss=0.0319, epoch_loss=0.0467, task=1, task_score=0.2371]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:02<00:08,  4.99it/s, batch_loss=0.0649, epoch_loss=0.0486, task=0, task_score=0.5417]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:08,  4.82it/s, batch_loss=0.0649, epoch_loss=0.0486, task=0, task_score=0.5417]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:08,  4.82it/s, batch_loss=0.0325, epoch_loss=0.0471, task=1, task_score=0.1832]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:07,  5.09it/s, batch_loss=0.0325, epoch_loss=0.0471, task=1, task_score=0.1832]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:07,  5.09it/s, batch_loss=0.0651, epoch_loss=0.0486, task=0, task_score=0.5530]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:02<00:07,  4.92it/s, batch_loss=0.0651, epoch_loss=0.0486, task=0, task_score=0.5530]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:02<00:07,  4.92it/s, batch_loss=0.0644, epoch_loss=0.0498, task=0, task_score=0.6158]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:02<00:08,  4.41it/s, batch_loss=0.0644, epoch_loss=0.0498, task=0, task_score=0.6158]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:02<00:08,  4.41it/s, batch_loss=0.0317, epoch_loss=0.0485, task=1, task_score=0.3052]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:02<00:07,  4.65it/s, batch_loss=0.0317, epoch_loss=0.0485, task=1, task_score=0.3052]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:03<00:07,  4.65it/s, batch_loss=0.0322, epoch_loss=0.0474, task=1, task_score=0.1985]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:07,  5.00it/s, batch_loss=0.0322, epoch_loss=0.0474, task=1, task_score=0.1985]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:07,  5.00it/s, batch_loss=0.0321, epoch_loss=0.0465, task=1, task_score=0.2513]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:03<00:06,  5.14it/s, batch_loss=0.0321, epoch_loss=0.0465, task=1, task_score=0.2513]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:03<00:06,  5.14it/s, batch_loss=0.0325, epoch_loss=0.0456, task=1, task_score=0.1703]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:03<00:06,  5.31it/s, batch_loss=0.0325, epoch_loss=0.0456, task=1, task_score=0.1703]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:03<00:06,  5.31it/s, batch_loss=0.0325, epoch_loss=0.0449, task=1, task_score=0.1359]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:03<00:06,  5.33it/s, batch_loss=0.0325, epoch_loss=0.0449, task=1, task_score=0.1359]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:03<00:06,  5.33it/s, batch_loss=0.0326, epoch_loss=0.0443, task=1, task_score=0.2019]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:03<00:05,  5.44it/s, batch_loss=0.0326, epoch_loss=0.0443, task=1, task_score=0.2019]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:04<00:05,  5.44it/s, batch_loss=0.0649, epoch_loss=0.0453, task=0, task_score=0.6297]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:04<00:05,  5.08it/s, batch_loss=0.0649, epoch_loss=0.0453, task=0, task_score=0.6297]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:04<00:05,  5.08it/s, batch_loss=0.0649, epoch_loss=0.0462, task=0, task_score=0.4679]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:04<00:06,  4.74it/s, batch_loss=0.0649, epoch_loss=0.0462, task=0, task_score=0.4679]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:04<00:06,  4.74it/s, batch_loss=0.0648, epoch_loss=0.0471, task=0, task_score=0.4971]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:04<00:06,  4.59it/s, batch_loss=0.0648, epoch_loss=0.0471, task=0, task_score=0.4971]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:04<00:06,  4.59it/s, batch_loss=0.0653, epoch_loss=0.0479, task=0, task_score=0.3905]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:04<00:06,  4.25it/s, batch_loss=0.0653, epoch_loss=0.0479, task=0, task_score=0.3905]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:04<00:06,  4.25it/s, batch_loss=0.0324, epoch_loss=0.0472, task=1, task_score=0.1743]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:04<00:05,  4.59it/s, batch_loss=0.0324, epoch_loss=0.0472, task=1, task_score=0.1743]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:05<00:05,  4.59it/s, batch_loss=0.0650, epoch_loss=0.0479, task=0, task_score=0.5084]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:05<00:05,  4.56it/s, batch_loss=0.0650, epoch_loss=0.0479, task=0, task_score=0.5084]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:05<00:05,  4.56it/s, batch_loss=0.0650, epoch_loss=0.0486, task=0, task_score=0.5319]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:05<00:05,  4.45it/s, batch_loss=0.0650, epoch_loss=0.0486, task=0, task_score=0.5319]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:05<00:05,  4.45it/s, batch_loss=0.0318, epoch_loss=0.0480, task=1, task_score=0.3015]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:05<00:04,  4.77it/s, batch_loss=0.0318, epoch_loss=0.0480, task=1, task_score=0.3015]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:05<00:04,  4.77it/s, batch_loss=0.0647, epoch_loss=0.0486, task=0, task_score=0.5541]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:05<00:04,  4.53it/s, batch_loss=0.0647, epoch_loss=0.0486, task=0, task_score=0.5541]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:06<00:04,  4.53it/s, batch_loss=0.0647, epoch_loss=0.0491, task=0, task_score=0.5478]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:06<00:05,  4.11it/s, batch_loss=0.0647, epoch_loss=0.0491, task=0, task_score=0.5478]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:06<00:05,  4.11it/s, batch_loss=0.0646, epoch_loss=0.0496, task=0, task_score=0.6769]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:06<00:05,  3.43it/s, batch_loss=0.0646, epoch_loss=0.0496, task=0, task_score=0.6769]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:06<00:05,  3.43it/s, batch_loss=0.0649, epoch_loss=0.0501, task=0, task_score=0.5000]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:06<00:05,  3.59it/s, batch_loss=0.0649, epoch_loss=0.0501, task=0, task_score=0.5000]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:07<00:05,  3.59it/s, batch_loss=0.0324, epoch_loss=0.0496, task=1, task_score=0.2148]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:07<00:04,  3.82it/s, batch_loss=0.0324, epoch_loss=0.0496, task=1, task_score=0.2148]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:07<00:04,  3.82it/s, batch_loss=0.0325, epoch_loss=0.0491, task=1, task_score=0.1781]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:07<00:04,  3.71it/s, batch_loss=0.0325, epoch_loss=0.0491, task=1, task_score=0.1781]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  66%|██████▌   | 33/50 [00:07<00:04,  3.71it/s, batch_loss=0.0320, epoch_loss=0.0486, task=1, task_score=0.2397]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:07<00:03,  4.03it/s, batch_loss=0.0320, epoch_loss=0.0486, task=1, task_score=0.2397]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:07<00:03,  4.03it/s, batch_loss=0.0324, epoch_loss=0.0481, task=1, task_score=0.1934]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:07<00:03,  4.10it/s, batch_loss=0.0324, epoch_loss=0.0481, task=1, task_score=0.1934]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:08<00:03,  4.10it/s, batch_loss=0.0319, epoch_loss=0.0476, task=1, task_score=0.2475]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:08<00:03,  3.99it/s, batch_loss=0.0319, epoch_loss=0.0476, task=1, task_score=0.2475]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:08<00:03,  3.99it/s, batch_loss=0.0655, epoch_loss=0.0481, task=0, task_score=0.4253]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:08<00:03,  3.58it/s, batch_loss=0.0655, epoch_loss=0.0481, task=0, task_score=0.4253]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:08<00:03,  3.58it/s, batch_loss=0.0651, epoch_loss=0.0486, task=0, task_score=0.4514]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:08<00:03,  3.86it/s, batch_loss=0.0651, epoch_loss=0.0486, task=0, task_score=0.4514]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:08<00:03,  3.86it/s, batch_loss=0.0656, epoch_loss=0.0490, task=0, task_score=0.5478]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:08<00:03,  3.64it/s, batch_loss=0.0656, epoch_loss=0.0490, task=0, task_score=0.5478]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:09<00:03,  3.64it/s, batch_loss=0.0319, epoch_loss=0.0486, task=1, task_score=0.3131]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:09<00:02,  4.08it/s, batch_loss=0.0319, epoch_loss=0.0486, task=1, task_score=0.3131]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:09<00:02,  4.08it/s, batch_loss=0.0648, epoch_loss=0.0490, task=0, task_score=0.5429]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:09<00:02,  3.97it/s, batch_loss=0.0648, epoch_loss=0.0490, task=0, task_score=0.5429]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:09<00:02,  3.97it/s, batch_loss=0.0648, epoch_loss=0.0494, task=0, task_score=0.5173]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:09<00:02,  3.93it/s, batch_loss=0.0648, epoch_loss=0.0494, task=0, task_score=0.5173]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:09<00:02,  3.93it/s, batch_loss=0.0325, epoch_loss=0.0490, task=1, task_score=0.2570]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:09<00:01,  4.22it/s, batch_loss=0.0325, epoch_loss=0.0490, task=1, task_score=0.2570]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:10<00:01,  4.22it/s, batch_loss=0.0649, epoch_loss=0.0493, task=0, task_score=0.5211]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:10<00:01,  3.97it/s, batch_loss=0.0649, epoch_loss=0.0493, task=0, task_score=0.5211]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:10<00:01,  3.97it/s, batch_loss=0.0650, epoch_loss=0.0497, task=0, task_score=0.5656]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:10<00:01,  4.04it/s, batch_loss=0.0650, epoch_loss=0.0497, task=0, task_score=0.5656]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:10<00:01,  4.04it/s, batch_loss=0.0649, epoch_loss=0.0500, task=0, task_score=0.5609]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:10<00:00,  4.01it/s, batch_loss=0.0649, epoch_loss=0.0500, task=0, task_score=0.5609]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:10<00:00,  4.01it/s, batch_loss=0.0320, epoch_loss=0.0496, task=1, task_score=0.3859]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:10<00:00,  4.37it/s, batch_loss=0.0320, epoch_loss=0.0496, task=1, task_score=0.3859]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:10<00:00,  4.37it/s, batch_loss=0.0317, epoch_loss=0.0492, task=1, task_score=0.4540]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:10<00:00,  4.34it/s, batch_loss=0.0317, epoch_loss=0.0492, task=1, task_score=0.4540]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:11<00:00,  4.34it/s, batch_loss=0.0329, epoch_loss=0.0489, task=1, task_score=0.1648]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:11<00:00,  4.59it/s, batch_loss=0.0329, epoch_loss=0.0489, task=1, task_score=0.1648]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:11<00:00,  4.59it/s, batch_loss=0.0653, epoch_loss=0.0492, task=0, task_score=0.4781]\u001b[A\n",
      "Batch: 100%|██████████| 50/50 [00:11<00:00,  4.53it/s, batch_loss=0.0653, epoch_loss=0.0492, task=0, task_score=0.4781]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Evaluating model:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating model:   3%|▎         | 1/39 [00:00<00:05,  6.77it/s]\u001b[A\n",
      "Evaluating model:  10%|█         | 4/39 [00:00<00:04,  8.60it/s]\u001b[A\n",
      "Evaluating model:  21%|██        | 8/39 [00:00<00:02, 11.18it/s]\u001b[A\n",
      "Evaluating model:  28%|██▊       | 11/39 [00:00<00:02, 13.19it/s]\u001b[A\n",
      "Evaluating model:  36%|███▌      | 14/39 [00:00<00:01, 15.67it/s]\u001b[A\n",
      "Evaluating model:  44%|████▎     | 17/39 [00:00<00:01, 18.04it/s]\u001b[A\n",
      "Evaluating model:  51%|█████▏    | 20/39 [00:00<00:00, 20.23it/s]\u001b[A\n",
      "Evaluating model:  64%|██████▍   | 25/39 [00:00<00:00, 24.18it/s]\u001b[A\n",
      "Evaluating model:  74%|███████▍  | 29/39 [00:01<00:00, 24.26it/s]\u001b[A\n",
      "Evaluating model:  82%|████████▏ | 32/39 [00:01<00:00, 25.45it/s]\u001b[A\n",
      "Evaluating model:  90%|████████▉ | 35/39 [00:01<00:00, 25.14it/s]\u001b[A\n",
      "Evaluating model: 100%|██████████| 39/39 [00:01<00:00, 26.53it/s]\u001b[A\n",
      "Training model:  40%|████      | 4/10 [00:54<01:22, 13.76s/it, dev_loss=0.0652, dev_score=0.5555, loss=0.0653]\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s, batch_loss=0.0323, epoch_loss=0.0323, task=1, task_score=0.2333]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:08,  5.94it/s, batch_loss=0.0323, epoch_loss=0.0323, task=1, task_score=0.2333]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:08,  5.94it/s, batch_loss=0.0645, epoch_loss=0.0484, task=0, task_score=0.6444]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:09,  4.92it/s, batch_loss=0.0645, epoch_loss=0.0484, task=0, task_score=0.6444]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:09,  4.92it/s, batch_loss=0.0325, epoch_loss=0.0431, task=1, task_score=0.2453]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:10,  4.53it/s, batch_loss=0.0325, epoch_loss=0.0431, task=1, task_score=0.2453]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:10,  4.53it/s, batch_loss=0.0320, epoch_loss=0.0403, task=1, task_score=0.3250]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:00<00:10,  4.40it/s, batch_loss=0.0320, epoch_loss=0.0403, task=1, task_score=0.3250]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:01<00:10,  4.40it/s, batch_loss=0.0316, epoch_loss=0.0386, task=1, task_score=0.3565]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:09,  4.63it/s, batch_loss=0.0316, epoch_loss=0.0386, task=1, task_score=0.3565]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:09,  4.63it/s, batch_loss=0.0318, epoch_loss=0.0375, task=1, task_score=0.3885]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:09,  4.86it/s, batch_loss=0.0318, epoch_loss=0.0375, task=1, task_score=0.3885]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:09,  4.86it/s, batch_loss=0.0315, epoch_loss=0.0366, task=1, task_score=0.3259]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:08,  5.01it/s, batch_loss=0.0315, epoch_loss=0.0366, task=1, task_score=0.3259]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:08,  5.01it/s, batch_loss=0.0321, epoch_loss=0.0360, task=1, task_score=0.2065]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:01<00:08,  4.91it/s, batch_loss=0.0321, epoch_loss=0.0360, task=1, task_score=0.2065]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:02<00:08,  4.91it/s, batch_loss=0.0646, epoch_loss=0.0392, task=0, task_score=0.6410]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:02<00:09,  4.26it/s, batch_loss=0.0646, epoch_loss=0.0392, task=0, task_score=0.6410]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:02<00:09,  4.26it/s, batch_loss=0.0643, epoch_loss=0.0417, task=0, task_score=0.6949]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:10,  3.89it/s, batch_loss=0.0643, epoch_loss=0.0417, task=0, task_score=0.6949]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:10,  3.89it/s, batch_loss=0.0329, epoch_loss=0.0409, task=1, task_score=0.1843]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:09,  4.21it/s, batch_loss=0.0329, epoch_loss=0.0409, task=1, task_score=0.1843]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:09,  4.21it/s, batch_loss=0.0321, epoch_loss=0.0402, task=1, task_score=0.2264]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  24%|██▍       | 12/50 [00:02<00:08,  4.27it/s, batch_loss=0.0321, epoch_loss=0.0402, task=1, task_score=0.2264]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:03<00:08,  4.27it/s, batch_loss=0.0650, epoch_loss=0.0421, task=0, task_score=0.5105]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:03<00:09,  3.92it/s, batch_loss=0.0650, epoch_loss=0.0421, task=0, task_score=0.5105]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:03<00:09,  3.92it/s, batch_loss=0.0652, epoch_loss=0.0437, task=0, task_score=0.5278]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:03<00:10,  3.50it/s, batch_loss=0.0652, epoch_loss=0.0437, task=0, task_score=0.5278]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:03<00:10,  3.50it/s, batch_loss=0.0322, epoch_loss=0.0430, task=1, task_score=0.1842]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:08,  3.90it/s, batch_loss=0.0322, epoch_loss=0.0430, task=1, task_score=0.1842]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:08,  3.90it/s, batch_loss=0.0652, epoch_loss=0.0444, task=0, task_score=0.4667]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:03<00:09,  3.69it/s, batch_loss=0.0652, epoch_loss=0.0444, task=0, task_score=0.4667]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:04<00:09,  3.69it/s, batch_loss=0.0651, epoch_loss=0.0456, task=0, task_score=0.4868]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:04<00:08,  3.89it/s, batch_loss=0.0651, epoch_loss=0.0456, task=0, task_score=0.4868]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:04<00:08,  3.89it/s, batch_loss=0.0655, epoch_loss=0.0467, task=0, task_score=0.4511]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:04<00:07,  4.15it/s, batch_loss=0.0655, epoch_loss=0.0467, task=0, task_score=0.4511]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:04<00:07,  4.15it/s, batch_loss=0.0323, epoch_loss=0.0459, task=1, task_score=0.2271]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:04<00:06,  4.55it/s, batch_loss=0.0323, epoch_loss=0.0459, task=1, task_score=0.2271]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:04<00:06,  4.55it/s, batch_loss=0.0647, epoch_loss=0.0469, task=0, task_score=0.4545]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:04<00:06,  4.32it/s, batch_loss=0.0647, epoch_loss=0.0469, task=0, task_score=0.4545]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:04<00:06,  4.32it/s, batch_loss=0.0321, epoch_loss=0.0462, task=1, task_score=0.2365]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:04<00:06,  4.62it/s, batch_loss=0.0321, epoch_loss=0.0462, task=1, task_score=0.2365]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:05<00:06,  4.62it/s, batch_loss=0.0650, epoch_loss=0.0470, task=0, task_score=0.4828]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:05<00:06,  4.59it/s, batch_loss=0.0650, epoch_loss=0.0470, task=0, task_score=0.4828]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:05<00:06,  4.59it/s, batch_loss=0.0322, epoch_loss=0.0464, task=1, task_score=0.1920]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:05<00:05,  4.88it/s, batch_loss=0.0322, epoch_loss=0.0464, task=1, task_score=0.1920]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:05<00:05,  4.88it/s, batch_loss=0.0650, epoch_loss=0.0472, task=0, task_score=0.5365]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:05<00:05,  4.59it/s, batch_loss=0.0650, epoch_loss=0.0472, task=0, task_score=0.5365]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:05<00:05,  4.59it/s, batch_loss=0.0325, epoch_loss=0.0466, task=1, task_score=0.1886]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:05<00:05,  4.84it/s, batch_loss=0.0325, epoch_loss=0.0466, task=1, task_score=0.1886]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:06<00:05,  4.84it/s, batch_loss=0.0652, epoch_loss=0.0473, task=0, task_score=0.4182]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:06<00:06,  3.45it/s, batch_loss=0.0652, epoch_loss=0.0473, task=0, task_score=0.4182]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:06<00:06,  3.45it/s, batch_loss=0.0650, epoch_loss=0.0479, task=0, task_score=0.5646]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:06<00:06,  3.57it/s, batch_loss=0.0650, epoch_loss=0.0479, task=0, task_score=0.5646]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:06<00:06,  3.57it/s, batch_loss=0.0323, epoch_loss=0.0474, task=1, task_score=0.2768]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:06<00:05,  3.91it/s, batch_loss=0.0323, epoch_loss=0.0474, task=1, task_score=0.2768]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:06<00:05,  3.91it/s, batch_loss=0.0649, epoch_loss=0.0480, task=0, task_score=0.5385]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:06<00:05,  3.86it/s, batch_loss=0.0649, epoch_loss=0.0480, task=0, task_score=0.5385]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:07<00:05,  3.86it/s, batch_loss=0.0650, epoch_loss=0.0486, task=0, task_score=0.5983]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:07<00:05,  3.81it/s, batch_loss=0.0650, epoch_loss=0.0486, task=0, task_score=0.5983]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:07<00:05,  3.81it/s, batch_loss=0.0648, epoch_loss=0.0491, task=0, task_score=0.5749]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:07<00:05,  3.67it/s, batch_loss=0.0648, epoch_loss=0.0491, task=0, task_score=0.5749]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:07<00:05,  3.67it/s, batch_loss=0.0325, epoch_loss=0.0486, task=1, task_score=0.2437]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:07<00:04,  4.08it/s, batch_loss=0.0325, epoch_loss=0.0486, task=1, task_score=0.2437]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:07<00:04,  4.08it/s, batch_loss=0.0323, epoch_loss=0.0481, task=1, task_score=0.2592]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:07<00:03,  4.46it/s, batch_loss=0.0323, epoch_loss=0.0481, task=1, task_score=0.2592]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:08<00:03,  4.46it/s, batch_loss=0.0646, epoch_loss=0.0486, task=0, task_score=0.5852]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:08<00:03,  4.40it/s, batch_loss=0.0646, epoch_loss=0.0486, task=0, task_score=0.5852]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:08<00:03,  4.40it/s, batch_loss=0.0321, epoch_loss=0.0481, task=1, task_score=0.2913]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:08<00:03,  4.73it/s, batch_loss=0.0321, epoch_loss=0.0481, task=1, task_score=0.2913]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:08<00:03,  4.73it/s, batch_loss=0.0655, epoch_loss=0.0486, task=0, task_score=0.4393]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:08<00:03,  4.63it/s, batch_loss=0.0655, epoch_loss=0.0486, task=0, task_score=0.4393]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:08<00:03,  4.63it/s, batch_loss=0.0648, epoch_loss=0.0490, task=0, task_score=0.5628]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:08<00:02,  4.34it/s, batch_loss=0.0648, epoch_loss=0.0490, task=0, task_score=0.5628]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:08<00:02,  4.34it/s, batch_loss=0.0321, epoch_loss=0.0486, task=1, task_score=0.2856]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:08<00:02,  4.72it/s, batch_loss=0.0321, epoch_loss=0.0486, task=1, task_score=0.2856]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:09<00:02,  4.72it/s, batch_loss=0.0323, epoch_loss=0.0481, task=1, task_score=0.2733]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:09<00:02,  5.00it/s, batch_loss=0.0323, epoch_loss=0.0481, task=1, task_score=0.2733]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:09<00:02,  5.00it/s, batch_loss=0.0647, epoch_loss=0.0486, task=0, task_score=0.5609]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:09<00:02,  4.52it/s, batch_loss=0.0647, epoch_loss=0.0486, task=0, task_score=0.5609]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:09<00:02,  4.52it/s, batch_loss=0.0327, epoch_loss=0.0482, task=1, task_score=0.1894]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:09<00:01,  4.74it/s, batch_loss=0.0327, epoch_loss=0.0482, task=1, task_score=0.1894]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:09<00:01,  4.74it/s, batch_loss=0.0647, epoch_loss=0.0486, task=0, task_score=0.6158]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:09<00:01,  4.55it/s, batch_loss=0.0647, epoch_loss=0.0486, task=0, task_score=0.6158]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:10<00:01,  4.55it/s, batch_loss=0.0644, epoch_loss=0.0489, task=0, task_score=0.5749]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:10<00:01,  4.48it/s, batch_loss=0.0644, epoch_loss=0.0489, task=0, task_score=0.5749]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:10<00:01,  4.48it/s, batch_loss=0.0325, epoch_loss=0.0486, task=1, task_score=0.1845]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:10<00:01,  4.85it/s, batch_loss=0.0325, epoch_loss=0.0486, task=1, task_score=0.1845]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:10<00:01,  4.85it/s, batch_loss=0.0324, epoch_loss=0.0482, task=1, task_score=0.2191]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  90%|█████████ | 45/50 [00:10<00:01,  4.97it/s, batch_loss=0.0324, epoch_loss=0.0482, task=1, task_score=0.2191]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:10<00:01,  4.97it/s, batch_loss=0.0658, epoch_loss=0.0486, task=0, task_score=0.4781]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:10<00:00,  4.74it/s, batch_loss=0.0658, epoch_loss=0.0486, task=0, task_score=0.4781]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:10<00:00,  4.74it/s, batch_loss=0.0651, epoch_loss=0.0489, task=0, task_score=0.4583]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:10<00:00,  4.39it/s, batch_loss=0.0651, epoch_loss=0.0489, task=0, task_score=0.4583]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:11<00:00,  4.39it/s, batch_loss=0.0323, epoch_loss=0.0486, task=1, task_score=0.1999]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:11<00:00,  4.61it/s, batch_loss=0.0323, epoch_loss=0.0486, task=1, task_score=0.1999]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:11<00:00,  4.61it/s, batch_loss=0.0649, epoch_loss=0.0489, task=0, task_score=0.4393]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:11<00:00,  4.46it/s, batch_loss=0.0649, epoch_loss=0.0489, task=0, task_score=0.4393]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:11<00:00,  4.46it/s, batch_loss=0.0316, epoch_loss=0.0486, task=1, task_score=0.2539]\u001b[A\n",
      "Batch: 100%|██████████| 50/50 [00:11<00:00,  4.80it/s, batch_loss=0.0316, epoch_loss=0.0486, task=1, task_score=0.2539]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Evaluating model:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating model:   8%|▊         | 3/39 [00:00<00:01, 24.89it/s]\u001b[A\n",
      "Evaluating model:  18%|█▊        | 7/39 [00:00<00:01, 26.82it/s]\u001b[A\n",
      "Evaluating model:  23%|██▎       | 9/39 [00:00<00:01, 21.31it/s]\u001b[A\n",
      "Evaluating model:  33%|███▎      | 13/39 [00:00<00:01, 24.45it/s]\u001b[A\n",
      "Evaluating model:  44%|████▎     | 17/39 [00:00<00:00, 27.67it/s]\u001b[A\n",
      "Evaluating model:  54%|█████▍    | 21/39 [00:00<00:00, 29.49it/s]\u001b[A\n",
      "Evaluating model:  62%|██████▏   | 24/39 [00:00<00:00, 29.02it/s]\u001b[A\n",
      "Evaluating model:  69%|██████▉   | 27/39 [00:00<00:00, 28.45it/s]\u001b[A\n",
      "Evaluating model:  77%|███████▋  | 30/39 [00:01<00:00, 27.47it/s]\u001b[A\n",
      "Evaluating model:  87%|████████▋ | 34/39 [00:01<00:00, 27.64it/s]\u001b[A\n",
      "Evaluating model:  95%|█████████▍| 37/39 [00:01<00:00, 27.62it/s]\u001b[A\n",
      "Training model:  50%|█████     | 5/10 [01:07<01:07, 13.51s/it, dev_loss=0.0655, dev_score=0.5000, loss=0.0316]\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s, batch_loss=0.0322, epoch_loss=0.0322, task=1, task_score=0.2778]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:08,  5.67it/s, batch_loss=0.0322, epoch_loss=0.0322, task=1, task_score=0.2778]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:08,  5.67it/s, batch_loss=0.0648, epoch_loss=0.0485, task=0, task_score=0.5530]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:10,  4.61it/s, batch_loss=0.0648, epoch_loss=0.0485, task=0, task_score=0.5530]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:10,  4.61it/s, batch_loss=0.0322, epoch_loss=0.0431, task=1, task_score=0.2652]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:09,  4.90it/s, batch_loss=0.0322, epoch_loss=0.0431, task=1, task_score=0.2652]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:00<00:09,  4.90it/s, batch_loss=0.0649, epoch_loss=0.0485, task=0, task_score=0.5765]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:00<00:10,  4.59it/s, batch_loss=0.0649, epoch_loss=0.0485, task=0, task_score=0.5765]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:01<00:10,  4.59it/s, batch_loss=0.0655, epoch_loss=0.0519, task=0, task_score=0.3871]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:09,  4.52it/s, batch_loss=0.0655, epoch_loss=0.0519, task=0, task_score=0.3871]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:01<00:09,  4.52it/s, batch_loss=0.0316, epoch_loss=0.0485, task=1, task_score=0.2457]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:09,  4.82it/s, batch_loss=0.0316, epoch_loss=0.0485, task=1, task_score=0.2457]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:01<00:09,  4.82it/s, batch_loss=0.0324, epoch_loss=0.0462, task=1, task_score=0.1823]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:08,  5.02it/s, batch_loss=0.0324, epoch_loss=0.0462, task=1, task_score=0.1823]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:01<00:08,  5.02it/s, batch_loss=0.0653, epoch_loss=0.0486, task=0, task_score=0.4019]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:01<00:08,  4.79it/s, batch_loss=0.0653, epoch_loss=0.0486, task=0, task_score=0.4019]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:01<00:08,  4.79it/s, batch_loss=0.0323, epoch_loss=0.0468, task=1, task_score=0.2558]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:01<00:07,  5.15it/s, batch_loss=0.0323, epoch_loss=0.0468, task=1, task_score=0.2558]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:02<00:07,  5.15it/s, batch_loss=0.0652, epoch_loss=0.0486, task=0, task_score=0.4253]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:08,  4.88it/s, batch_loss=0.0652, epoch_loss=0.0486, task=0, task_score=0.4253]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:02<00:08,  4.88it/s, batch_loss=0.0322, epoch_loss=0.0471, task=1, task_score=0.2928]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:07,  5.02it/s, batch_loss=0.0322, epoch_loss=0.0471, task=1, task_score=0.2928]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:02<00:07,  5.02it/s, batch_loss=0.0648, epoch_loss=0.0486, task=0, task_score=0.5609]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:02<00:08,  4.34it/s, batch_loss=0.0648, epoch_loss=0.0486, task=0, task_score=0.5609]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:02<00:08,  4.34it/s, batch_loss=0.0329, epoch_loss=0.0474, task=1, task_score=0.2383]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:02<00:07,  4.77it/s, batch_loss=0.0329, epoch_loss=0.0474, task=1, task_score=0.2383]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:03<00:07,  4.77it/s, batch_loss=0.0646, epoch_loss=0.0486, task=0, task_score=0.6410]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:03<00:09,  3.80it/s, batch_loss=0.0646, epoch_loss=0.0486, task=0, task_score=0.6410]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:03<00:09,  3.80it/s, batch_loss=0.0326, epoch_loss=0.0476, task=1, task_score=0.1888]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:08,  4.23it/s, batch_loss=0.0326, epoch_loss=0.0476, task=1, task_score=0.1888]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:03<00:08,  4.23it/s, batch_loss=0.0322, epoch_loss=0.0466, task=1, task_score=0.2615]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:03<00:07,  4.54it/s, batch_loss=0.0322, epoch_loss=0.0466, task=1, task_score=0.2615]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:03<00:07,  4.54it/s, batch_loss=0.0654, epoch_loss=0.0477, task=0, task_score=0.4074]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:03<00:07,  4.52it/s, batch_loss=0.0654, epoch_loss=0.0477, task=0, task_score=0.4074]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:03<00:07,  4.52it/s, batch_loss=0.0324, epoch_loss=0.0469, task=1, task_score=0.2548]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:03<00:06,  4.86it/s, batch_loss=0.0324, epoch_loss=0.0469, task=1, task_score=0.2548]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:04<00:06,  4.86it/s, batch_loss=0.0325, epoch_loss=0.0461, task=1, task_score=0.1856]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:04<00:06,  5.01it/s, batch_loss=0.0325, epoch_loss=0.0461, task=1, task_score=0.1856]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:04<00:06,  5.01it/s, batch_loss=0.0648, epoch_loss=0.0470, task=0, task_score=0.6158]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:04<00:06,  4.69it/s, batch_loss=0.0648, epoch_loss=0.0470, task=0, task_score=0.6158]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:04<00:06,  4.69it/s, batch_loss=0.0321, epoch_loss=0.0463, task=1, task_score=0.3482]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:04<00:05,  5.06it/s, batch_loss=0.0321, epoch_loss=0.0463, task=1, task_score=0.3482]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:04<00:05,  5.06it/s, batch_loss=0.0647, epoch_loss=0.0472, task=0, task_score=0.5591]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:04<00:05,  4.72it/s, batch_loss=0.0647, epoch_loss=0.0472, task=0, task_score=0.5591]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:04<00:05,  4.72it/s, batch_loss=0.0321, epoch_loss=0.0465, task=1, task_score=0.2868]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:04<00:05,  4.92it/s, batch_loss=0.0321, epoch_loss=0.0465, task=1, task_score=0.2868]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  46%|████▌     | 23/50 [00:05<00:05,  4.92it/s, batch_loss=0.0319, epoch_loss=0.0459, task=1, task_score=0.3227]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:05<00:05,  5.18it/s, batch_loss=0.0319, epoch_loss=0.0459, task=1, task_score=0.3227]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:05<00:05,  5.18it/s, batch_loss=0.0322, epoch_loss=0.0454, task=1, task_score=0.3706]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:05<00:04,  5.35it/s, batch_loss=0.0322, epoch_loss=0.0454, task=1, task_score=0.3706]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:05<00:04,  5.35it/s, batch_loss=0.0321, epoch_loss=0.0448, task=1, task_score=0.2587]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:05<00:04,  5.29it/s, batch_loss=0.0321, epoch_loss=0.0448, task=1, task_score=0.2587]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:05<00:04,  5.29it/s, batch_loss=0.0321, epoch_loss=0.0444, task=1, task_score=0.1888]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:05<00:04,  5.37it/s, batch_loss=0.0321, epoch_loss=0.0444, task=1, task_score=0.1888]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:05<00:04,  5.37it/s, batch_loss=0.0329, epoch_loss=0.0440, task=1, task_score=0.1832]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:05<00:04,  5.33it/s, batch_loss=0.0329, epoch_loss=0.0440, task=1, task_score=0.1832]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:05<00:04,  5.33it/s, batch_loss=0.0323, epoch_loss=0.0436, task=1, task_score=0.2351]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:05<00:03,  5.56it/s, batch_loss=0.0323, epoch_loss=0.0436, task=1, task_score=0.2351]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:06<00:03,  5.56it/s, batch_loss=0.0329, epoch_loss=0.0432, task=1, task_score=0.2059]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:06<00:03,  5.51it/s, batch_loss=0.0329, epoch_loss=0.0432, task=1, task_score=0.2059]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:06<00:03,  5.51it/s, batch_loss=0.0651, epoch_loss=0.0439, task=0, task_score=0.4386]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:06<00:04,  4.54it/s, batch_loss=0.0651, epoch_loss=0.0439, task=0, task_score=0.4386]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:06<00:04,  4.54it/s, batch_loss=0.0645, epoch_loss=0.0446, task=0, task_score=0.6621]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:06<00:04,  4.18it/s, batch_loss=0.0645, epoch_loss=0.0446, task=0, task_score=0.6621]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:07<00:04,  4.18it/s, batch_loss=0.0648, epoch_loss=0.0452, task=0, task_score=0.6343]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:07<00:04,  4.08it/s, batch_loss=0.0648, epoch_loss=0.0452, task=0, task_score=0.6343]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:07<00:04,  4.08it/s, batch_loss=0.0654, epoch_loss=0.0458, task=0, task_score=0.5362]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:07<00:03,  4.31it/s, batch_loss=0.0654, epoch_loss=0.0458, task=0, task_score=0.5362]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:07<00:03,  4.31it/s, batch_loss=0.0651, epoch_loss=0.0463, task=0, task_score=0.4971]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:07<00:03,  4.25it/s, batch_loss=0.0651, epoch_loss=0.0463, task=0, task_score=0.4971]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:07<00:03,  4.25it/s, batch_loss=0.0646, epoch_loss=0.0468, task=0, task_score=0.4896]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:07<00:03,  3.93it/s, batch_loss=0.0646, epoch_loss=0.0468, task=0, task_score=0.4896]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:08<00:03,  3.93it/s, batch_loss=0.0648, epoch_loss=0.0473, task=0, task_score=0.5319]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:08<00:03,  3.84it/s, batch_loss=0.0648, epoch_loss=0.0473, task=0, task_score=0.5319]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:08<00:03,  3.84it/s, batch_loss=0.0323, epoch_loss=0.0469, task=1, task_score=0.2435]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:08<00:02,  4.30it/s, batch_loss=0.0323, epoch_loss=0.0469, task=1, task_score=0.2435]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:08<00:02,  4.30it/s, batch_loss=0.0652, epoch_loss=0.0474, task=0, task_score=0.4781]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:08<00:02,  3.96it/s, batch_loss=0.0652, epoch_loss=0.0474, task=0, task_score=0.4781]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:08<00:02,  3.96it/s, batch_loss=0.0649, epoch_loss=0.0478, task=0, task_score=0.6429]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:08<00:02,  4.08it/s, batch_loss=0.0649, epoch_loss=0.0478, task=0, task_score=0.6429]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:08<00:02,  4.08it/s, batch_loss=0.0319, epoch_loss=0.0474, task=1, task_score=0.3908]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:08<00:01,  4.52it/s, batch_loss=0.0319, epoch_loss=0.0474, task=1, task_score=0.3908]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:09<00:01,  4.52it/s, batch_loss=0.0649, epoch_loss=0.0478, task=0, task_score=0.5495]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:09<00:01,  4.13it/s, batch_loss=0.0649, epoch_loss=0.0478, task=0, task_score=0.5495]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:09<00:01,  4.13it/s, batch_loss=0.0325, epoch_loss=0.0475, task=1, task_score=0.1821]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:09<00:01,  4.64it/s, batch_loss=0.0325, epoch_loss=0.0475, task=1, task_score=0.1821]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:09<00:01,  4.64it/s, batch_loss=0.0315, epoch_loss=0.0471, task=1, task_score=0.2550]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:09<00:01,  4.98it/s, batch_loss=0.0315, epoch_loss=0.0471, task=1, task_score=0.2550]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:09<00:01,  4.98it/s, batch_loss=0.0321, epoch_loss=0.0468, task=1, task_score=0.1847]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:09<00:00,  5.20it/s, batch_loss=0.0321, epoch_loss=0.0468, task=1, task_score=0.1847]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:09<00:00,  5.20it/s, batch_loss=0.0644, epoch_loss=0.0472, task=0, task_score=0.6410]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:09<00:00,  4.44it/s, batch_loss=0.0644, epoch_loss=0.0472, task=0, task_score=0.6410]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:10<00:00,  4.44it/s, batch_loss=0.0650, epoch_loss=0.0476, task=0, task_score=0.5365]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:10<00:00,  4.47it/s, batch_loss=0.0650, epoch_loss=0.0476, task=0, task_score=0.5365]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:10<00:00,  4.47it/s, batch_loss=0.0652, epoch_loss=0.0479, task=0, task_score=0.4602]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:10<00:00,  4.40it/s, batch_loss=0.0652, epoch_loss=0.0479, task=0, task_score=0.4602]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:10<00:00,  4.40it/s, batch_loss=0.0328, epoch_loss=0.0476, task=1, task_score=0.2156]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:10<00:00,  4.89it/s, batch_loss=0.0328, epoch_loss=0.0476, task=1, task_score=0.2156]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:10<00:00,  4.89it/s, batch_loss=0.0317, epoch_loss=0.0473, task=1, task_score=0.2693]\u001b[A\n",
      "Batch: 100%|██████████| 50/50 [00:10<00:00,  5.25it/s, batch_loss=0.0317, epoch_loss=0.0473, task=1, task_score=0.2693]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Evaluating model:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating model:   8%|▊         | 3/39 [00:00<00:01, 26.82it/s]\u001b[A\n",
      "Evaluating model:  21%|██        | 8/39 [00:00<00:01, 29.85it/s]\u001b[A\n",
      "Evaluating model:  26%|██▌       | 10/39 [00:00<00:01, 25.29it/s]\u001b[A\n",
      "Evaluating model:  38%|███▊      | 15/39 [00:00<00:00, 29.03it/s]\u001b[A\n",
      "Evaluating model:  49%|████▊     | 19/39 [00:00<00:00, 30.89it/s]\u001b[A\n",
      "Evaluating model:  59%|█████▉    | 23/39 [00:00<00:00, 31.89it/s]\u001b[A\n",
      "Evaluating model:  69%|██████▉   | 27/39 [00:00<00:00, 32.78it/s]\u001b[A\n",
      "Evaluating model:  79%|███████▉  | 31/39 [00:00<00:00, 33.34it/s]\u001b[A\n",
      "Evaluating model:  90%|████████▉ | 35/39 [00:01<00:00, 33.82it/s]\u001b[A\n",
      "Evaluating model: 100%|██████████| 39/39 [00:01<00:00, 34.42it/s]\u001b[A\n",
      "                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: Terminate\n",
      "Loading weights from epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "run_mtl_model(train = True, **modelling_vars, **batch_writing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
