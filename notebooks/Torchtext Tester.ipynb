{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipdb\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from argparse import ArgumentParser\n",
    "import mlearn.modeling.multitask as mtl\n",
    "from mlearn.utils.metrics import Metrics\n",
    "from mlearn.data.batching import TorchtextExtractor\n",
    "from mlearn.data.clean import Cleaner, Preprocessors\n",
    "from mlearn.utils.train import run_mtl_model, train_mtl_model\n",
    "from torchtext.data import TabularDataset, Field, LabelField, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data inputs and outputs\n",
    "main = 'davidson'\n",
    "auxi = ['waseem']\n",
    "datadir = '../data/json/'\n",
    "results = '../results/'\n",
    "save_model = '../results/'\n",
    "\n",
    "# Cleaning and metrics\n",
    "cleaners = ['lower', 'username', 'url']\n",
    "metrics = ['f1-score', 'precision', 'recall', 'accuracy']\n",
    "display_metric = stop_metric = 'f1-score'\n",
    "dev_metrics = Metrics(metrics, display_metric, stop_metric)\n",
    "train_metrics = Metrics(metrics, display_metric, stop_metric)\n",
    "\n",
    "# Experiment\n",
    "experiment = 'word'\n",
    "tokenizer = 'bpe'\n",
    "seed = 42\n",
    "\n",
    "# Modelling\n",
    "# All models\n",
    "model = 'mlp'\n",
    "patience = 1\n",
    "encoding = 'onehot'\n",
    "loss = 'nlll'\n",
    "optimizer = 'adam'\n",
    "shuffle = True\n",
    "gpu = False\n",
    "batch_first = True\n",
    "clip = 1.0\n",
    "\n",
    "# LSTM\n",
    "layers = 1\n",
    "\n",
    "# CNN\n",
    "window_sizes = \"2,3,4\"\n",
    "filters = 128\n",
    "\n",
    "# Hyper Parameters\n",
    "embedding = 64\n",
    "hidden = [\"64,64\"]\n",
    "shared = 64\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.02\n",
    "dropout = 0.2\n",
    "nonlinearity = 'tanh'\n",
    "\n",
    "# MTL specific\n",
    "batches_epoch = 50\n",
    "loss_weights = [1.0, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise random seeds\n",
    "torch.random.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "# Set up experiment and cleaner\n",
    "c = Cleaner(processes = cleaners)\n",
    "exp = Preprocessors('data/').select_experiment(experiment)\n",
    "onehot = True if encoding == 'onehot' else False\n",
    "\n",
    "# Load tokenizers\n",
    "if tokenizer == 'spacy':\n",
    "    selected_tok  = c.tokenize\n",
    "elif tokenizer == 'bpe':\n",
    "    selected_tok = c.bpe_tokenize\n",
    "elif tokenizer == 'ekphrasis' and args.experiment == 'word':\n",
    "    selected_tok = c.ekphrasis_tokenize\n",
    "    annotate = {'elongated', 'emphasis'}\n",
    "    flters = [f\"<{filtr}>\" for filtr in annotate]\n",
    "    c._load_ekphrasis(annotate, flters)\n",
    "elif tokenizer == 'ekphrasis' and args.experiment == 'liwc':\n",
    "    ekphr = c.ekphrasis_tokenize\n",
    "    annotate = {'elongated', 'emphasis'}\n",
    "    flters = [f\"<{filtr}>\" for filtr in annotate]\n",
    "    c._load_ekphrasis(annotate, flters)\n",
    "\n",
    "    def liwc_toks(doc):\n",
    "        tokens = ekphr(doc)\n",
    "        tokens = exp(tokens)\n",
    "        return tokens\n",
    "    selected_tok = liwc_toks\n",
    "tokenizer = selected_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up fields\n",
    "text = Field(tokenize = tokenizer, lower = True, batch_first = True)\n",
    "label = LabelField()\n",
    "fields = {'text': ('text', text), 'label': ('label', label)}  # Because we load from json we just need this.\n",
    "\n",
    "# Load main task training data\n",
    "if main == 'davidson':\n",
    "    train, dev, test = TabularDataset.splits(datadir, train = 'davidson_binary_train.json',\n",
    "                                             validation = 'davidson_binary_dev.json',\n",
    "                                             test = 'davidson_binary_test.json',\n",
    "                                             format = 'json', skip_header = True, fields = fields)\n",
    "text.build_vocab(train)\n",
    "label.build_vocab(train)\n",
    "main = {'train': train, 'dev': dev, 'test': test, 'text': text, 'labels': label, 'name': main}\n",
    "\n",
    "# Load aux tasks\n",
    "auxillary = []\n",
    "for i, aux in enumerate(auxi):\n",
    "    # Set up fields\n",
    "    text = Field(tokenize = tokenizer, lower = True, batch_first = True)\n",
    "    label = LabelField()\n",
    "    fields = {'text': ('text', text), 'label': ('label', label)}  # Because we load from json we just need this.\n",
    "\n",
    "    if aux == 'davidson':\n",
    "        train, dev, test = TabularDataset.splits(datadir, train = 'davidson_binary_train.json',\n",
    "                                                 validation = 'davidson_binary_dev.json',\n",
    "                                                 test = 'davidson_binary_test.json',\n",
    "                                                 format = 'json', skip_header = True, fields = fields)\n",
    "    elif aux == 'hoover':\n",
    "        train, dev, test = TabularDataset.splits(datadir, train = 'hoover_train.json',\n",
    "                                                 validation = 'hoover_dev.json',\n",
    "                                                 test = 'hoover_test.json',\n",
    "                                                 format = 'json', skip_header = True, fields = fields)\n",
    "    elif aux == 'oraby_factfeel':\n",
    "        train, dev, test = TabularDataset.splits(datadir, train = 'oraby_fact_feel_train.json',\n",
    "                                                 validation = 'oraby_fact_feel_dev.json',\n",
    "                                                 test = 'oraby_fact_feel_test.json',\n",
    "                                                 format = 'json', skip_header = True, fields = fields)\n",
    "    elif aux == 'oraby_sarcasm':\n",
    "        train, dev, test = TabularDataset.splits(datadir, train = 'oraby_sarcasm_train.json',\n",
    "                                                 validation = 'oraby_sarcasm_dev.json',\n",
    "                                                 test = 'oraby_sarcasm_test.json',\n",
    "                                                 format = 'json', skip_header = True, fields = fields)\n",
    "    elif aux == 'waseem':\n",
    "        train, dev, test = TabularDataset.splits(datadir, train = 'waseem_train.json',\n",
    "                                                 validation = 'waseem_dev.json',\n",
    "                                                 test = 'waseem_test.json',\n",
    "                                                 format = 'json', skip_header = True, fields = fields)\n",
    "    elif aux == 'waseem_hovy':\n",
    "        train, dev, test = TabularDataset.splits(datadir, train = 'waseem_hovy_train.json',\n",
    "                                                 validation = 'waseem_hovy_dev.json',\n",
    "                                                 test = 'waseem_hovy_test.json',\n",
    "                                                 format = 'json', skip_header = True, fields = fields)\n",
    "    text.build_vocab(train)\n",
    "    label.build_vocab(train)\n",
    "    auxillary.append({'train': train, 'dev': dev, 'test': test, 'text': text, 'labels': label, 'name': aux, 'task_id': i + 1})\n",
    "    if len(auxillary) == len(auxi): break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'shared_dim': 64, 'batch_first': True, 'hidden_dims': [64, 64], 'input_dims': [18176, 9826], 'output_dims': [2, 4]}\n"
     ]
    }
   ],
   "source": [
    "# Hyper parameters\n",
    "dropout = dropout\n",
    "nonlinearity = nonlinearity\n",
    "learning_rate = learning_rate\n",
    "epochs = epochs\n",
    "batch_size = batch_size\n",
    "batch_count = batches_epoch\n",
    "loss_weights = loss_weights\n",
    "\n",
    "params = dict(shared_dim = shared,\n",
    "              batch_first = True,\n",
    "              hidden_dims = [int(hidden) for hidden in hidden[0].split(',')],\n",
    "              input_dims = [len(main['text'].vocab.stoi)] + [len(aux['text'].vocab.stoi) for aux in auxillary],\n",
    "              output_dims = [len(main['labels'].vocab.stoi)] + [len(aux['labels'].vocab.stoi) for aux in auxillary],\n",
    "              )\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OnehotMLPClassifier(\n",
      "  (all_parameters): ParameterList(\n",
      "      (0): Parameter containing: [torch.FloatTensor of size 64x18176]\n",
      "      (1): Parameter containing: [torch.FloatTensor of size 64]\n",
      "      (2): Parameter containing: [torch.FloatTensor of size 64x9826]\n",
      "      (3): Parameter containing: [torch.FloatTensor of size 64]\n",
      "      (4): Parameter containing: [torch.FloatTensor of size 64x64]\n",
      "      (5): Parameter containing: [torch.FloatTensor of size 64]\n",
      "      (6): Parameter containing: [torch.FloatTensor of size 64x64]\n",
      "      (7): Parameter containing: [torch.FloatTensor of size 64]\n",
      "      (8): Parameter containing: [torch.FloatTensor of size 64x64]\n",
      "      (9): Parameter containing: [torch.FloatTensor of size 64]\n",
      "      (10): Parameter containing: [torch.FloatTensor of size 2x64]\n",
      "      (11): Parameter containing: [torch.FloatTensor of size 2]\n",
      "      (12): Parameter containing: [torch.FloatTensor of size 4x64]\n",
      "      (13): Parameter containing: [torch.FloatTensor of size 4]\n",
      "  )\n",
      "  (shared): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (softmax): LogSoftmax()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "if not onehot:\n",
    "    params.update({'embedding_dims': embedding})\n",
    "if model == 'lstm':\n",
    "    params.update({'no_layers': layers})\n",
    "    model = mtl.OnehotLSTMClassifier if onehot else mtl.EmbeddingLSTMClassifier\n",
    "else:\n",
    "    params.update({'non-linearity': nonlinearity})\n",
    "    model = mtl.OnehotMLPClassifier if onehot else mtl.EmbeddingMLPClassifier\n",
    "\n",
    "    if model == 'cnn':\n",
    "        params.update({'window_sizes': [int(win) for win in window_sizes[0].split(',')],\n",
    "                       'num_filters': filters})\n",
    "        model = mtl.OnehotCNNClassifier if onehot else mtl.EmbeddingCNNClassifier\n",
    "    elif model == 'mlp':\n",
    "        model = mtl.OnehotMLPClassifier if onehot else mtl.EmbeddingMLPClassifier\n",
    "\n",
    "model = model(**params)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Info about losses: https://bit.ly/3irxvYK\n",
    "if loss == 'nlll':\n",
    "    loss = torch.nn.NLLLoss()\n",
    "elif loss == 'crossentropy':\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Set optimizer\n",
    "if optimizer == 'adam':\n",
    "    optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
    "elif optimizer == 'sgd':\n",
    "    optimizer = torch.optim.SGD(model.parameters(), learning_rate)\n",
    "elif optimizer == 'asgd':\n",
    "    optimizer = torch.optim.ASGD(model.parameters(), learning_rate)\n",
    "elif optimizer == 'adamw':\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onehot\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 58, 18176])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch data\n",
    "batchers = []\n",
    "test_batchers = []\n",
    "if onehot:\n",
    "    print(\"onehot\")\n",
    "    train_buckets = BucketIterator(dataset = main['train'], batch_size = batch_size, sort_key = lambda x: len(x))\n",
    "    train = TorchtextExtractor('text', 'label', main['name'], train_buckets, len(main['text'].vocab.stoi))\n",
    "    batchers.append(train)\n",
    "\n",
    "    dev_buckets = BucketIterator(dataset = main['dev'], batch_size = 64, sort_key = lambda x: len(x))\n",
    "    dev = TorchtextExtractor('text', 'label', main['name'], dev_buckets, len(main['text'].vocab.stoi))\n",
    "\n",
    "    test_buckets = BucketIterator(dataset = main['test'], batch_size = 64, sort_key = lambda x: len(x))\n",
    "    main_test = TorchtextExtractor('text', 'label', main['name'], test_buckets, len(main['text'].vocab.stoi))\n",
    "\n",
    "    for aux in auxillary:\n",
    "        train_buckets = BucketIterator(dataset = aux['train'], batch_size = batch_size, sort_key = lambda x: len(x))\n",
    "        train = TorchtextExtractor('text', 'label', aux['name'], train_buckets, len(aux['text'].vocab.stoi))\n",
    "        batchers.append(train)\n",
    "\n",
    "        test_buckets = BucketIterator(dataset = aux['test'], batch_size = 64, sort_key = lambda x: len(x))\n",
    "        test = TorchtextExtractor('text', 'label', aux['name'], test_buckets, len(aux['text'].vocab.stoi))\n",
    "        test_batchers.append(test)\n",
    "            \n",
    "else:\n",
    "    print(\"embedding\")\n",
    "    train_buckets = BucketIterator(dataset = main['train'], batch_size = batch_size, sort_key = lambda x: len(x))\n",
    "    main_train = TorchtextExtractor('text', 'label', main['name'], train_buckets)\n",
    "    batchers.append(main_train)\n",
    "\n",
    "    dev_buckets = BucketIterator(dataset = main['dev'], batch_size = 64, sort_key = lambda x: len(x))\n",
    "    dev = TorchtextExtractor('text', 'label', main['name'], dev_buckets)\n",
    "\n",
    "    test_buckets = BucketIterator(dataset = main['test'], batch_size = 64, sort_key = lambda x: len(x))\n",
    "    main_test = TorchtextExtractor('text', 'label', main['name'], test_buckets)\n",
    "\n",
    "    for aux in auxillary:\n",
    "        train_buckets = BucketIterator(dataset = aux['train'], batch_size = batch_size, sort_key = lambda x: len(x))\n",
    "        train = TorchtextExtractor('text', 'label', aux['name'], train_buckets)\n",
    "        batchers.append(train)\n",
    "\n",
    "        test_buckets = BucketIterator(dataset = aux['test'], batch_size = 64, sort_key = lambda x: len(x))\n",
    "        test = TorchtextExtractor('text', 'label', aux['name'], test_buckets)\n",
    "        test_batchers.append(test)\n",
    "next(iter(batchers[0]))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 64]\n",
       "\t[.text]:[torch.LongTensor of size 64x41]\n",
       "\t[.label]:[torch.LongTensor of size 64]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_writing = dict(batch_writer = csv.writer(open('test', 'w')),\n",
    "                     model_hdr = ['name'], main_name = 'davidson', hyper_info = [embedding],\n",
    "                     metric_hdr = ['f1-score'], writer = csv.writer(open('test2', 'w')), data_name = 'davidson')\n",
    "modelling_vars = dict(model = model, \n",
    "                      batchers = batchers, \n",
    "                      optimizer = optimizer, \n",
    "                      loss = loss,\n",
    "                      metrics = train_metrics, \n",
    "                      batch_size = batch_size, \n",
    "                      epochs = epochs, \n",
    "                      clip = clip,\n",
    "                      early_stopping = patience, \n",
    "                      save_model = results, \n",
    "                      dev = dev, \n",
    "                      dev_metrics = dev_metrics,\n",
    "                      dev_task_id = 0, \n",
    "                      batches_per_epoch = batches_epoch, \n",
    "                      low = False, \n",
    "                      shuffle = False, \n",
    "                      dataset_weights = None, \n",
    "                      loss_weights = loss_weights, \n",
    "                      gpu = False, \n",
    "                      hyperopt = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training model:   0%|          | 0/10 [00:00<?, ?it/s]\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s, batch_loss=0.0282, epoch_loss=0.0282, task=1, task_score=0.0012]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:20,  2.37it/s, batch_loss=0.0282, epoch_loss=0.0282, task=1, task_score=0.0012]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:01<00:20,  2.37it/s, batch_loss=0.0662, epoch_loss=0.0472, task=0, task_score=0.0152]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:01<00:30,  1.57it/s, batch_loss=0.0662, epoch_loss=0.0472, task=0, task_score=0.0152]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:01<00:30,  1.57it/s, batch_loss=0.0285, epoch_loss=0.0410, task=1, task_score=0.0409]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:01<00:26,  1.77it/s, batch_loss=0.0285, epoch_loss=0.0410, task=1, task_score=0.0409]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:02<00:26,  1.77it/s, batch_loss=0.0261, epoch_loss=0.0372, task=1, task_score=0.0478]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:02<00:23,  1.98it/s, batch_loss=0.0261, epoch_loss=0.0372, task=1, task_score=0.0478]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:03<00:23,  1.98it/s, batch_loss=0.0714, epoch_loss=0.0441, task=0, task_score=0.0044]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:03<00:33,  1.34it/s, batch_loss=0.0714, epoch_loss=0.0441, task=0, task_score=0.0044]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:04<00:33,  1.34it/s, batch_loss=0.0559, epoch_loss=0.0460, task=0, task_score=0.0295]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:04<00:34,  1.27it/s, batch_loss=0.0559, epoch_loss=0.0460, task=0, task_score=0.0295]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:04<00:34,  1.27it/s, batch_loss=0.0191, epoch_loss=0.0422, task=1, task_score=0.0339]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:04<00:28,  1.51it/s, batch_loss=0.0191, epoch_loss=0.0422, task=1, task_score=0.0339]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:05<00:28,  1.51it/s, batch_loss=0.0424, epoch_loss=0.0422, task=0, task_score=0.0320]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:05<00:28,  1.48it/s, batch_loss=0.0424, epoch_loss=0.0422, task=0, task_score=0.0320]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:06<00:28,  1.48it/s, batch_loss=0.0376, epoch_loss=0.0417, task=0, task_score=0.0428]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:06<00:29,  1.38it/s, batch_loss=0.0376, epoch_loss=0.0417, task=0, task_score=0.0428]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:07<00:29,  1.38it/s, batch_loss=0.0382, epoch_loss=0.0413, task=0, task_score=0.0318]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:07<00:30,  1.31it/s, batch_loss=0.0382, epoch_loss=0.0413, task=0, task_score=0.0318]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:08<00:30,  1.31it/s, batch_loss=0.0377, epoch_loss=0.0410, task=0, task_score=0.0320]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:08<00:30,  1.26it/s, batch_loss=0.0377, epoch_loss=0.0410, task=0, task_score=0.0320]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:09<00:30,  1.26it/s, batch_loss=0.0328, epoch_loss=0.0403, task=0, task_score=0.0350]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:09<00:30,  1.23it/s, batch_loss=0.0328, epoch_loss=0.0403, task=0, task_score=0.0350]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:09<00:30,  1.23it/s, batch_loss=0.0345, epoch_loss=0.0399, task=0, task_score=0.0348]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:09<00:31,  1.18it/s, batch_loss=0.0345, epoch_loss=0.0399, task=0, task_score=0.0348]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:10<00:31,  1.18it/s, batch_loss=0.0278, epoch_loss=0.0390, task=0, task_score=0.0405]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:10<00:29,  1.22it/s, batch_loss=0.0278, epoch_loss=0.0390, task=0, task_score=0.0405]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:11<00:29,  1.22it/s, batch_loss=0.0164, epoch_loss=0.0375, task=1, task_score=0.0543]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:11<00:24,  1.42it/s, batch_loss=0.0164, epoch_loss=0.0375, task=1, task_score=0.0543]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:11<00:24,  1.42it/s, batch_loss=0.0331, epoch_loss=0.0372, task=0, task_score=0.0545]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:11<00:23,  1.43it/s, batch_loss=0.0331, epoch_loss=0.0372, task=0, task_score=0.0545]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:12<00:23,  1.43it/s, batch_loss=0.0297, epoch_loss=0.0368, task=0, task_score=0.0630]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:12<00:23,  1.43it/s, batch_loss=0.0297, epoch_loss=0.0368, task=0, task_score=0.0630]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:12<00:23,  1.43it/s, batch_loss=0.0149, epoch_loss=0.0356, task=1, task_score=0.0466]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:12<00:19,  1.66it/s, batch_loss=0.0149, epoch_loss=0.0356, task=1, task_score=0.0466]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:13<00:19,  1.66it/s, batch_loss=0.0331, epoch_loss=0.0354, task=0, task_score=0.0428]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:13<00:19,  1.59it/s, batch_loss=0.0331, epoch_loss=0.0354, task=0, task_score=0.0428]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:14<00:19,  1.59it/s, batch_loss=0.0314, epoch_loss=0.0352, task=0, task_score=0.0421]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:14<00:20,  1.45it/s, batch_loss=0.0314, epoch_loss=0.0352, task=0, task_score=0.0421]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:15<00:20,  1.45it/s, batch_loss=0.0297, epoch_loss=0.0350, task=0, task_score=0.0341]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:15<00:20,  1.43it/s, batch_loss=0.0297, epoch_loss=0.0350, task=0, task_score=0.0341]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:15<00:20,  1.43it/s, batch_loss=0.0128, epoch_loss=0.0340, task=1, task_score=0.0388]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:15<00:16,  1.67it/s, batch_loss=0.0128, epoch_loss=0.0340, task=1, task_score=0.0388]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:16<00:16,  1.67it/s, batch_loss=0.0380, epoch_loss=0.0341, task=0, task_score=0.0471]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:16<00:21,  1.24it/s, batch_loss=0.0380, epoch_loss=0.0341, task=0, task_score=0.0471]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:17<00:21,  1.24it/s, batch_loss=0.0261, epoch_loss=0.0338, task=0, task_score=0.0505]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:17<00:21,  1.22it/s, batch_loss=0.0261, epoch_loss=0.0338, task=0, task_score=0.0505]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:24<00:21,  1.22it/s, batch_loss=0.0332, epoch_loss=0.0338, task=0, task_score=0.0389]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:24<01:04,  2.60s/it, batch_loss=0.0332, epoch_loss=0.0338, task=0, task_score=0.0389]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:24<01:04,  2.60s/it, batch_loss=0.0344, epoch_loss=0.0338, task=1, task_score=0.1486]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:24<00:46,  1.93s/it, batch_loss=0.0344, epoch_loss=0.0338, task=1, task_score=0.1486]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:25<00:46,  1.93s/it, batch_loss=0.0342, epoch_loss=0.0338, task=0, task_score=0.0571]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:25<00:35,  1.56s/it, batch_loss=0.0342, epoch_loss=0.0338, task=0, task_score=0.0571]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:25<00:35,  1.56s/it, batch_loss=0.0135, epoch_loss=0.0331, task=1, task_score=0.0696]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:25<00:26,  1.20s/it, batch_loss=0.0135, epoch_loss=0.0331, task=1, task_score=0.0696]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:26<00:26,  1.20s/it, batch_loss=0.0176, epoch_loss=0.0325, task=1, task_score=0.0642]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:26<00:20,  1.04it/s, batch_loss=0.0176, epoch_loss=0.0325, task=1, task_score=0.0642]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:26<00:20,  1.04it/s, batch_loss=0.0143, epoch_loss=0.0319, task=1, task_score=0.0498]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:26<00:15,  1.30it/s, batch_loss=0.0143, epoch_loss=0.0319, task=1, task_score=0.0498]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:27<00:15,  1.30it/s, batch_loss=0.0330, epoch_loss=0.0319, task=0, task_score=0.0293]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:27<00:13,  1.36it/s, batch_loss=0.0330, epoch_loss=0.0319, task=0, task_score=0.0293]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:27<00:13,  1.36it/s, batch_loss=0.0349, epoch_loss=0.0320, task=0, task_score=0.0376]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:27<00:12,  1.42it/s, batch_loss=0.0349, epoch_loss=0.0320, task=0, task_score=0.0376]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:28<00:12,  1.42it/s, batch_loss=0.0354, epoch_loss=0.0321, task=0, task_score=0.0314]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  66%|██████▌   | 33/50 [00:28<00:11,  1.51it/s, batch_loss=0.0354, epoch_loss=0.0321, task=0, task_score=0.0314]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:28<00:11,  1.51it/s, batch_loss=0.0151, epoch_loss=0.0316, task=1, task_score=0.0403]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:28<00:09,  1.77it/s, batch_loss=0.0151, epoch_loss=0.0316, task=1, task_score=0.0403]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:29<00:09,  1.77it/s, batch_loss=0.0130, epoch_loss=0.0311, task=1, task_score=0.0487]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:29<00:07,  2.07it/s, batch_loss=0.0130, epoch_loss=0.0311, task=1, task_score=0.0487]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:29<00:07,  2.07it/s, batch_loss=0.0286, epoch_loss=0.0310, task=0, task_score=0.0463]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:29<00:08,  1.68it/s, batch_loss=0.0286, epoch_loss=0.0310, task=0, task_score=0.0463]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:30<00:08,  1.68it/s, batch_loss=0.0127, epoch_loss=0.0305, task=1, task_score=0.0572]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:30<00:06,  1.95it/s, batch_loss=0.0127, epoch_loss=0.0305, task=1, task_score=0.0572]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:30<00:06,  1.95it/s, batch_loss=0.0348, epoch_loss=0.0306, task=0, task_score=0.0287]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:30<00:06,  1.72it/s, batch_loss=0.0348, epoch_loss=0.0306, task=0, task_score=0.0287]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:31<00:06,  1.72it/s, batch_loss=0.0282, epoch_loss=0.0306, task=0, task_score=0.0426]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:31<00:07,  1.41it/s, batch_loss=0.0282, epoch_loss=0.0306, task=0, task_score=0.0426]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:32<00:07,  1.41it/s, batch_loss=0.0296, epoch_loss=0.0305, task=0, task_score=0.0305]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:32<00:06,  1.45it/s, batch_loss=0.0296, epoch_loss=0.0305, task=0, task_score=0.0305]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:34<00:06,  1.45it/s, batch_loss=0.0312, epoch_loss=0.0305, task=0, task_score=0.0312]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:34<00:08,  1.04it/s, batch_loss=0.0312, epoch_loss=0.0305, task=0, task_score=0.0312]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:34<00:08,  1.04it/s, batch_loss=0.0148, epoch_loss=0.0302, task=1, task_score=0.0374]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:34<00:06,  1.25it/s, batch_loss=0.0148, epoch_loss=0.0302, task=1, task_score=0.0374]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:35<00:06,  1.25it/s, batch_loss=0.0277, epoch_loss=0.0301, task=0, task_score=0.0383]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:35<00:06,  1.13it/s, batch_loss=0.0277, epoch_loss=0.0301, task=0, task_score=0.0383]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:36<00:06,  1.13it/s, batch_loss=0.0127, epoch_loss=0.0297, task=1, task_score=0.0584]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:36<00:04,  1.31it/s, batch_loss=0.0127, epoch_loss=0.0297, task=1, task_score=0.0584]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:36<00:04,  1.31it/s, batch_loss=0.0294, epoch_loss=0.0297, task=1, task_score=0.1333]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:36<00:03,  1.64it/s, batch_loss=0.0294, epoch_loss=0.0297, task=1, task_score=0.1333]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:37<00:03,  1.64it/s, batch_loss=0.0303, epoch_loss=0.0297, task=0, task_score=0.0531]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:37<00:02,  1.55it/s, batch_loss=0.0303, epoch_loss=0.0297, task=0, task_score=0.0531]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:37<00:02,  1.55it/s, batch_loss=0.0136, epoch_loss=0.0294, task=1, task_score=0.0498]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:37<00:01,  1.51it/s, batch_loss=0.0136, epoch_loss=0.0294, task=1, task_score=0.0498]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:38<00:01,  1.51it/s, batch_loss=0.0343, epoch_loss=0.0295, task=0, task_score=0.0364]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:38<00:01,  1.43it/s, batch_loss=0.0343, epoch_loss=0.0295, task=0, task_score=0.0364]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:39<00:01,  1.43it/s, batch_loss=0.0133, epoch_loss=0.0291, task=1, task_score=0.0520]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:39<00:00,  1.66it/s, batch_loss=0.0133, epoch_loss=0.0291, task=1, task_score=0.0520]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:39<00:00,  1.66it/s, batch_loss=0.0144, epoch_loss=0.0288, task=1, task_score=0.0561]\u001b[A\n",
      "Batch: 100%|██████████| 50/50 [00:39<00:00,  1.86it/s, batch_loss=0.0144, epoch_loss=0.0288, task=1, task_score=0.0561]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Evaluating model:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating model:   3%|▎         | 1/39 [00:00<00:25,  1.51it/s]\u001b[A\n",
      "Evaluating model:   5%|▌         | 2/39 [00:01<00:27,  1.36it/s]\u001b[A\n",
      "Evaluating model:   8%|▊         | 3/39 [00:02<00:26,  1.36it/s]\u001b[A\n",
      "Evaluating model:  10%|█         | 4/39 [00:03<00:25,  1.39it/s]\u001b[A\n",
      "Evaluating model:  13%|█▎        | 5/39 [00:04<00:29,  1.16it/s]\u001b[A\n",
      "Evaluating model:  15%|█▌        | 6/39 [00:04<00:26,  1.24it/s]\u001b[A\n",
      "Evaluating model:  18%|█▊        | 7/39 [00:05<00:23,  1.34it/s]\u001b[A\n",
      "Evaluating model:  21%|██        | 8/39 [00:05<00:19,  1.58it/s]\u001b[A\n",
      "Evaluating model:  23%|██▎       | 9/39 [00:06<00:17,  1.76it/s]\u001b[A\n",
      "Evaluating model:  26%|██▌       | 10/39 [00:06<00:15,  1.84it/s]\u001b[A\n",
      "Evaluating model:  28%|██▊       | 11/39 [00:07<00:16,  1.66it/s]\u001b[A\n",
      "Evaluating model:  31%|███       | 12/39 [00:07<00:15,  1.74it/s]\u001b[A\n",
      "Evaluating model:  33%|███▎      | 13/39 [00:08<00:14,  1.82it/s]\u001b[A\n",
      "Evaluating model:  36%|███▌      | 14/39 [00:08<00:12,  2.04it/s]\u001b[A\n",
      "Evaluating model:  38%|███▊      | 15/39 [00:09<00:11,  2.00it/s]\u001b[A\n",
      "Evaluating model:  41%|████      | 16/39 [00:09<00:10,  2.13it/s]\u001b[A\n",
      "Evaluating model:  44%|████▎     | 17/39 [00:10<00:09,  2.23it/s]\u001b[A\n",
      "Evaluating model:  46%|████▌     | 18/39 [00:10<00:10,  2.03it/s]\u001b[A\n",
      "Evaluating model:  49%|████▊     | 19/39 [00:11<00:09,  2.03it/s]\u001b[A\n",
      "Evaluating model:  51%|█████▏    | 20/39 [00:11<00:08,  2.11it/s]\u001b[A\n",
      "Evaluating model:  54%|█████▍    | 21/39 [00:12<00:08,  2.24it/s]\u001b[A\n",
      "Evaluating model:  56%|█████▋    | 22/39 [00:12<00:08,  1.90it/s]\u001b[A\n",
      "Evaluating model:  59%|█████▉    | 23/39 [00:13<00:07,  2.01it/s]\u001b[A\n",
      "Evaluating model:  62%|██████▏   | 24/39 [00:13<00:06,  2.18it/s]\u001b[A\n",
      "Evaluating model:  64%|██████▍   | 25/39 [00:14<00:06,  2.18it/s]\u001b[A\n",
      "Evaluating model:  67%|██████▋   | 26/39 [00:14<00:05,  2.22it/s]\u001b[A\n",
      "Evaluating model:  69%|██████▉   | 27/39 [00:14<00:05,  2.35it/s]\u001b[A\n",
      "Evaluating model:  72%|███████▏  | 28/39 [00:15<00:04,  2.37it/s]\u001b[A\n",
      "Evaluating model:  74%|███████▍  | 29/39 [00:15<00:05,  1.97it/s]\u001b[A\n",
      "Evaluating model:  77%|███████▋  | 30/39 [00:16<00:04,  1.91it/s]\u001b[A\n",
      "Evaluating model:  79%|███████▉  | 31/39 [00:16<00:03,  2.25it/s]\u001b[A\n",
      "Evaluating model:  82%|████████▏ | 32/39 [00:17<00:03,  1.91it/s]\u001b[A\n",
      "Evaluating model:  85%|████████▍ | 33/39 [00:18<00:03,  1.78it/s]\u001b[A\n",
      "Evaluating model:  87%|████████▋ | 34/39 [00:18<00:02,  1.96it/s]\u001b[A\n",
      "Evaluating model:  90%|████████▉ | 35/39 [00:19<00:02,  1.80it/s]\u001b[A\n",
      "Evaluating model:  92%|█████████▏| 36/39 [00:19<00:01,  1.76it/s]\u001b[A\n",
      "Evaluating model:  95%|█████████▍| 37/39 [00:21<00:01,  1.03it/s]\u001b[A\n",
      "Evaluating model:  97%|█████████▋| 38/39 [00:22<00:00,  1.12it/s]\u001b[A\n",
      "Evaluating model: 100%|██████████| 39/39 [00:22<00:00,  1.35it/s]\u001b[A\n",
      "Training model:  10%|█         | 1/10 [01:02<09:20, 62.30s/it, dev_loss=0.0294, dev_score=0.0197, loss=0.0144]\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s, batch_loss=0.0126, epoch_loss=0.0126, task=1, task_score=0.0396]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:15,  3.24it/s, batch_loss=0.0126, epoch_loss=0.0126, task=1, task_score=0.0396]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:01<00:15,  3.24it/s, batch_loss=0.0341, epoch_loss=0.0234, task=0, task_score=0.0393]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:01<00:24,  1.97it/s, batch_loss=0.0341, epoch_loss=0.0234, task=0, task_score=0.0393]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:01<00:24,  1.97it/s, batch_loss=0.0274, epoch_loss=0.0247, task=0, task_score=0.0426]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:01<00:24,  1.92it/s, batch_loss=0.0274, epoch_loss=0.0247, task=0, task_score=0.0426]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:02<00:24,  1.92it/s, batch_loss=0.0297, epoch_loss=0.0260, task=0, task_score=0.0417]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:   8%|▊         | 4/50 [00:02<00:28,  1.64it/s, batch_loss=0.0297, epoch_loss=0.0260, task=0, task_score=0.0417]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:03<00:28,  1.64it/s, batch_loss=0.0259, epoch_loss=0.0259, task=0, task_score=0.0392]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:03<00:27,  1.64it/s, batch_loss=0.0259, epoch_loss=0.0259, task=0, task_score=0.0392]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:03<00:27,  1.64it/s, batch_loss=0.0132, epoch_loss=0.0238, task=1, task_score=0.0546]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:03<00:23,  1.89it/s, batch_loss=0.0132, epoch_loss=0.0238, task=1, task_score=0.0546]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:03<00:23,  1.89it/s, batch_loss=0.0145, epoch_loss=0.0225, task=1, task_score=0.0525]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:03<00:20,  2.09it/s, batch_loss=0.0145, epoch_loss=0.0225, task=1, task_score=0.0525]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:04<00:20,  2.09it/s, batch_loss=0.0159, epoch_loss=0.0217, task=1, task_score=0.0378]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:04<00:18,  2.23it/s, batch_loss=0.0159, epoch_loss=0.0217, task=1, task_score=0.0378]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:04<00:18,  2.23it/s, batch_loss=0.0137, epoch_loss=0.0208, task=1, task_score=0.0647]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:04<00:16,  2.48it/s, batch_loss=0.0137, epoch_loss=0.0208, task=1, task_score=0.0647]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:05<00:16,  2.48it/s, batch_loss=0.0318, epoch_loss=0.0219, task=0, task_score=0.0612]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:05<00:18,  2.21it/s, batch_loss=0.0318, epoch_loss=0.0219, task=0, task_score=0.0612]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:05<00:18,  2.21it/s, batch_loss=0.0360, epoch_loss=0.0232, task=0, task_score=0.0396]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:05<00:20,  1.92it/s, batch_loss=0.0360, epoch_loss=0.0232, task=0, task_score=0.0396]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:06<00:20,  1.92it/s, batch_loss=0.0132, epoch_loss=0.0223, task=1, task_score=0.0749]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:06<00:17,  2.15it/s, batch_loss=0.0132, epoch_loss=0.0223, task=1, task_score=0.0749]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:07<00:17,  2.15it/s, batch_loss=0.0277, epoch_loss=0.0227, task=0, task_score=0.0370]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:07<00:21,  1.68it/s, batch_loss=0.0277, epoch_loss=0.0227, task=0, task_score=0.0370]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:07<00:21,  1.68it/s, batch_loss=0.0160, epoch_loss=0.0223, task=1, task_score=0.0378]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:07<00:18,  1.90it/s, batch_loss=0.0160, epoch_loss=0.0223, task=1, task_score=0.0378]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:08<00:18,  1.90it/s, batch_loss=0.0295, epoch_loss=0.0228, task=0, task_score=0.0361]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:08<00:20,  1.68it/s, batch_loss=0.0295, epoch_loss=0.0228, task=0, task_score=0.0361]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:08<00:20,  1.68it/s, batch_loss=0.0308, epoch_loss=0.0233, task=0, task_score=0.0412]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:09<00:21,  1.55it/s, batch_loss=0.0308, epoch_loss=0.0233, task=0, task_score=0.0412]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:09<00:21,  1.55it/s, batch_loss=0.0146, epoch_loss=0.0227, task=1, task_score=0.0467]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:09<00:18,  1.80it/s, batch_loss=0.0146, epoch_loss=0.0227, task=1, task_score=0.0467]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:10<00:18,  1.80it/s, batch_loss=0.0301, epoch_loss=0.0232, task=0, task_score=0.0283]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:10<00:19,  1.61it/s, batch_loss=0.0301, epoch_loss=0.0232, task=0, task_score=0.0283]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:11<00:19,  1.61it/s, batch_loss=0.0355, epoch_loss=0.0238, task=0, task_score=0.0364]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:11<00:22,  1.39it/s, batch_loss=0.0355, epoch_loss=0.0238, task=0, task_score=0.0364]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:12<00:22,  1.39it/s, batch_loss=0.0270, epoch_loss=0.0240, task=0, task_score=0.0541]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:12<00:25,  1.19it/s, batch_loss=0.0270, epoch_loss=0.0240, task=0, task_score=0.0541]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:12<00:25,  1.19it/s, batch_loss=0.0180, epoch_loss=0.0237, task=0, task_score=0.0774]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:12<00:22,  1.30it/s, batch_loss=0.0180, epoch_loss=0.0237, task=0, task_score=0.0774]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:13<00:22,  1.30it/s, batch_loss=0.0149, epoch_loss=0.0233, task=1, task_score=0.0385]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:13<00:18,  1.53it/s, batch_loss=0.0149, epoch_loss=0.0233, task=1, task_score=0.0385]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:13<00:18,  1.53it/s, batch_loss=0.0133, epoch_loss=0.0228, task=1, task_score=0.0494]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:13<00:15,  1.74it/s, batch_loss=0.0133, epoch_loss=0.0228, task=1, task_score=0.0494]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:13<00:15,  1.74it/s, batch_loss=0.0138, epoch_loss=0.0225, task=1, task_score=0.0623]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:13<00:12,  2.02it/s, batch_loss=0.0138, epoch_loss=0.0225, task=1, task_score=0.0623]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:14<00:12,  2.02it/s, batch_loss=0.0133, epoch_loss=0.0221, task=1, task_score=0.0417]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:14<00:10,  2.32it/s, batch_loss=0.0133, epoch_loss=0.0221, task=1, task_score=0.0417]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:14<00:10,  2.32it/s, batch_loss=0.0149, epoch_loss=0.0218, task=1, task_score=0.0457]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:14<00:09,  2.56it/s, batch_loss=0.0149, epoch_loss=0.0218, task=1, task_score=0.0457]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:15<00:09,  2.56it/s, batch_loss=0.0259, epoch_loss=0.0220, task=0, task_score=0.0582]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:15<00:11,  1.93it/s, batch_loss=0.0259, epoch_loss=0.0220, task=0, task_score=0.0582]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:15<00:11,  1.93it/s, batch_loss=0.0153, epoch_loss=0.0217, task=1, task_score=0.0739]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:15<00:10,  2.08it/s, batch_loss=0.0153, epoch_loss=0.0217, task=1, task_score=0.0739]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:16<00:10,  2.08it/s, batch_loss=0.0291, epoch_loss=0.0220, task=0, task_score=0.0391]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:16<00:12,  1.74it/s, batch_loss=0.0291, epoch_loss=0.0220, task=0, task_score=0.0391]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:16<00:12,  1.74it/s, batch_loss=0.0155, epoch_loss=0.0218, task=1, task_score=0.0301]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:16<00:10,  1.88it/s, batch_loss=0.0155, epoch_loss=0.0218, task=1, task_score=0.0301]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:17<00:10,  1.88it/s, batch_loss=0.0304, epoch_loss=0.0221, task=0, task_score=0.0324]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:17<00:11,  1.71it/s, batch_loss=0.0304, epoch_loss=0.0221, task=0, task_score=0.0324]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:17<00:11,  1.71it/s, batch_loss=0.0150, epoch_loss=0.0218, task=1, task_score=0.0397]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:17<00:09,  1.93it/s, batch_loss=0.0150, epoch_loss=0.0218, task=1, task_score=0.0397]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:18<00:09,  1.93it/s, batch_loss=0.0254, epoch_loss=0.0219, task=0, task_score=0.0352]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:18<00:09,  1.75it/s, batch_loss=0.0254, epoch_loss=0.0219, task=0, task_score=0.0352]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:19<00:09,  1.75it/s, batch_loss=0.0134, epoch_loss=0.0217, task=1, task_score=0.0403]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:19<00:08,  1.92it/s, batch_loss=0.0134, epoch_loss=0.0217, task=1, task_score=0.0403]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:19<00:08,  1.92it/s, batch_loss=0.0106, epoch_loss=0.0214, task=1, task_score=0.0408]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:19<00:06,  2.24it/s, batch_loss=0.0106, epoch_loss=0.0214, task=1, task_score=0.0408]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:19<00:06,  2.24it/s, batch_loss=0.0116, epoch_loss=0.0211, task=1, task_score=0.0340]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:19<00:05,  2.54it/s, batch_loss=0.0116, epoch_loss=0.0211, task=1, task_score=0.0340]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:19<00:05,  2.54it/s, batch_loss=0.0159, epoch_loss=0.0210, task=1, task_score=0.0313]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  74%|███████▍  | 37/50 [00:19<00:04,  2.75it/s, batch_loss=0.0159, epoch_loss=0.0210, task=1, task_score=0.0313]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:20<00:04,  2.75it/s, batch_loss=0.0315, epoch_loss=0.0212, task=0, task_score=0.0327]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:20<00:04,  2.41it/s, batch_loss=0.0315, epoch_loss=0.0212, task=0, task_score=0.0327]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:20<00:04,  2.41it/s, batch_loss=0.0118, epoch_loss=0.0210, task=1, task_score=0.0665]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:20<00:04,  2.65it/s, batch_loss=0.0118, epoch_loss=0.0210, task=1, task_score=0.0665]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:21<00:04,  2.65it/s, batch_loss=0.0332, epoch_loss=0.0213, task=0, task_score=0.0338]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:21<00:04,  2.09it/s, batch_loss=0.0332, epoch_loss=0.0213, task=0, task_score=0.0338]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:22<00:04,  2.09it/s, batch_loss=0.0318, epoch_loss=0.0216, task=0, task_score=0.0471]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:22<00:04,  1.80it/s, batch_loss=0.0318, epoch_loss=0.0216, task=0, task_score=0.0471]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:22<00:04,  1.80it/s, batch_loss=0.0320, epoch_loss=0.0218, task=0, task_score=0.0348]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:22<00:04,  1.76it/s, batch_loss=0.0320, epoch_loss=0.0218, task=0, task_score=0.0348]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:23<00:04,  1.76it/s, batch_loss=0.0122, epoch_loss=0.0216, task=1, task_score=0.0601]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:23<00:03,  1.99it/s, batch_loss=0.0122, epoch_loss=0.0216, task=1, task_score=0.0601]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:23<00:03,  1.99it/s, batch_loss=0.0128, epoch_loss=0.0214, task=1, task_score=0.0492]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:23<00:02,  2.20it/s, batch_loss=0.0128, epoch_loss=0.0214, task=1, task_score=0.0492]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:24<00:02,  2.20it/s, batch_loss=0.0332, epoch_loss=0.0216, task=0, task_score=0.0450]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:24<00:03,  1.62it/s, batch_loss=0.0332, epoch_loss=0.0216, task=0, task_score=0.0450]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:24<00:03,  1.62it/s, batch_loss=0.0133, epoch_loss=0.0215, task=1, task_score=0.0693]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:24<00:02,  1.85it/s, batch_loss=0.0133, epoch_loss=0.0215, task=1, task_score=0.0693]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:25<00:02,  1.85it/s, batch_loss=0.0140, epoch_loss=0.0213, task=1, task_score=0.0504]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:25<00:01,  2.14it/s, batch_loss=0.0140, epoch_loss=0.0213, task=1, task_score=0.0504]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:25<00:01,  2.14it/s, batch_loss=0.0121, epoch_loss=0.0211, task=1, task_score=0.0813]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:25<00:00,  2.36it/s, batch_loss=0.0121, epoch_loss=0.0211, task=1, task_score=0.0813]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:26<00:00,  2.36it/s, batch_loss=0.0369, epoch_loss=0.0214, task=0, task_score=0.0379]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:26<00:00,  1.84it/s, batch_loss=0.0369, epoch_loss=0.0214, task=0, task_score=0.0379]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:27<00:00,  1.84it/s, batch_loss=0.0243, epoch_loss=0.0215, task=0, task_score=0.0404]\u001b[A\n",
      "Batch: 100%|██████████| 50/50 [00:27<00:00,  1.57it/s, batch_loss=0.0243, epoch_loss=0.0215, task=0, task_score=0.0404]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Evaluating model:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating model:   3%|▎         | 1/39 [00:00<00:11,  3.31it/s]\u001b[A\n",
      "Evaluating model:   5%|▌         | 2/39 [00:00<00:12,  2.99it/s]\u001b[A\n",
      "Evaluating model:   8%|▊         | 3/39 [00:01<00:14,  2.53it/s]\u001b[A\n",
      "Evaluating model:  10%|█         | 4/39 [00:01<00:17,  2.05it/s]\u001b[A\n",
      "Evaluating model:  13%|█▎        | 5/39 [00:02<00:15,  2.15it/s]\u001b[A\n",
      "Evaluating model:  15%|█▌        | 6/39 [00:02<00:15,  2.07it/s]\u001b[A\n",
      "Evaluating model:  18%|█▊        | 7/39 [00:03<00:18,  1.71it/s]\u001b[A\n",
      "Evaluating model:  21%|██        | 8/39 [00:04<00:17,  1.82it/s]\u001b[A\n",
      "Evaluating model:  23%|██▎       | 9/39 [00:04<00:15,  1.95it/s]\u001b[A\n",
      "Evaluating model:  26%|██▌       | 10/39 [00:06<00:28,  1.02it/s]\u001b[A\n",
      "Evaluating model:  28%|██▊       | 11/39 [00:07<00:24,  1.14it/s]\u001b[A\n",
      "Evaluating model:  31%|███       | 12/39 [00:07<00:20,  1.32it/s]\u001b[A\n",
      "Evaluating model:  33%|███▎      | 13/39 [00:08<00:18,  1.44it/s]\u001b[A\n",
      "Evaluating model:  36%|███▌      | 14/39 [00:09<00:17,  1.46it/s]\u001b[A\n",
      "Evaluating model:  38%|███▊      | 15/39 [00:09<00:14,  1.64it/s]\u001b[A\n",
      "Evaluating model:  41%|████      | 16/39 [00:10<00:15,  1.46it/s]\u001b[A\n",
      "Evaluating model:  44%|████▎     | 17/39 [00:10<00:14,  1.50it/s]\u001b[A\n",
      "Evaluating model:  46%|████▌     | 18/39 [00:11<00:12,  1.66it/s]\u001b[A\n",
      "Evaluating model:  49%|████▊     | 19/39 [00:12<00:12,  1.55it/s]\u001b[A\n",
      "Evaluating model:  51%|█████▏    | 20/39 [00:12<00:12,  1.50it/s]\u001b[A\n",
      "Evaluating model:  54%|█████▍    | 21/39 [00:13<00:13,  1.30it/s]\u001b[A\n",
      "Evaluating model:  56%|█████▋    | 22/39 [00:15<00:15,  1.10it/s]\u001b[A\n",
      "Evaluating model:  59%|█████▉    | 23/39 [00:15<00:14,  1.14it/s]\u001b[A\n",
      "Evaluating model:  62%|██████▏   | 24/39 [00:16<00:11,  1.34it/s]\u001b[A\n",
      "Evaluating model:  64%|██████▍   | 25/39 [00:16<00:09,  1.50it/s]\u001b[A\n",
      "Evaluating model:  67%|██████▋   | 26/39 [00:17<00:08,  1.60it/s]\u001b[A\n",
      "Evaluating model:  69%|██████▉   | 27/39 [00:17<00:06,  1.76it/s]\u001b[A\n",
      "Evaluating model:  72%|███████▏  | 28/39 [00:18<00:06,  1.57it/s]\u001b[A\n",
      "Evaluating model:  74%|███████▍  | 29/39 [00:19<00:06,  1.61it/s]\u001b[A\n",
      "Evaluating model:  77%|███████▋  | 30/39 [00:19<00:05,  1.67it/s]\u001b[A\n",
      "Evaluating model:  79%|███████▉  | 31/39 [00:20<00:04,  1.77it/s]\u001b[A\n",
      "Evaluating model:  82%|████████▏ | 32/39 [00:20<00:04,  1.63it/s]\u001b[A\n",
      "Evaluating model:  85%|████████▍ | 33/39 [00:21<00:04,  1.50it/s]\u001b[A\n",
      "Evaluating model:  87%|████████▋ | 34/39 [00:22<00:03,  1.47it/s]\u001b[A\n",
      "Evaluating model:  90%|████████▉ | 35/39 [00:22<00:02,  1.65it/s]\u001b[A\n",
      "Evaluating model:  92%|█████████▏| 36/39 [00:23<00:01,  1.56it/s]\u001b[A\n",
      "Evaluating model:  95%|█████████▍| 37/39 [00:24<00:01,  1.31it/s]\u001b[A\n",
      "Evaluating model:  97%|█████████▋| 38/39 [00:25<00:00,  1.37it/s]\u001b[A\n",
      "Evaluating model: 100%|██████████| 39/39 [00:25<00:00,  1.54it/s]\u001b[A\n",
      "Training model:  20%|██        | 2/10 [01:55<07:55, 59.50s/it, dev_loss=0.0284, dev_score=0.0205, loss=0.0243]\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Batch:   0%|          | 0/50 [00:01<?, ?it/s, batch_loss=0.0268, epoch_loss=0.0268, task=0, task_score=0.0347]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:01<00:52,  1.07s/it, batch_loss=0.0268, epoch_loss=0.0268, task=0, task_score=0.0347]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:01<00:52,  1.07s/it, batch_loss=0.0264, epoch_loss=0.0266, task=0, task_score=0.0543]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:01<00:48,  1.00s/it, batch_loss=0.0264, epoch_loss=0.0266, task=0, task_score=0.0543]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:02<00:48,  1.00s/it, batch_loss=0.0258, epoch_loss=0.0263, task=0, task_score=0.0546]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:02<00:42,  1.12it/s, batch_loss=0.0258, epoch_loss=0.0263, task=0, task_score=0.0546]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:02<00:42,  1.12it/s, batch_loss=0.0489, epoch_loss=0.0287, task=1, task_score=0.1217]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:02<00:31,  1.46it/s, batch_loss=0.0489, epoch_loss=0.0287, task=1, task_score=0.1217]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:03<00:31,  1.46it/s, batch_loss=0.0116, epoch_loss=0.0247, task=1, task_score=0.0911]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:03<00:26,  1.71it/s, batch_loss=0.0116, epoch_loss=0.0247, task=1, task_score=0.0911]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:03<00:26,  1.71it/s, batch_loss=0.0089, epoch_loss=0.0218, task=1, task_score=0.0471]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:03<00:23,  1.89it/s, batch_loss=0.0089, epoch_loss=0.0218, task=1, task_score=0.0471]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:05<00:23,  1.89it/s, batch_loss=0.0281, epoch_loss=0.0228, task=0, task_score=0.0434]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:05<00:35,  1.21it/s, batch_loss=0.0281, epoch_loss=0.0228, task=0, task_score=0.0434]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:05<00:35,  1.21it/s, batch_loss=0.0333, epoch_loss=0.0242, task=0, task_score=0.0319]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  16%|█▌        | 8/50 [00:05<00:34,  1.22it/s, batch_loss=0.0333, epoch_loss=0.0242, task=0, task_score=0.0319]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:06<00:34,  1.22it/s, batch_loss=0.0287, epoch_loss=0.0247, task=0, task_score=0.0392]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:06<00:32,  1.27it/s, batch_loss=0.0287, epoch_loss=0.0247, task=0, task_score=0.0392]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:07<00:32,  1.27it/s, batch_loss=0.0222, epoch_loss=0.0245, task=0, task_score=0.0568]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:07<00:28,  1.39it/s, batch_loss=0.0222, epoch_loss=0.0245, task=0, task_score=0.0568]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:07<00:28,  1.39it/s, batch_loss=0.0202, epoch_loss=0.0241, task=1, task_score=0.0964]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:07<00:24,  1.62it/s, batch_loss=0.0202, epoch_loss=0.0241, task=1, task_score=0.0964]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:07<00:24,  1.62it/s, batch_loss=0.0200, epoch_loss=0.0237, task=1, task_score=0.0562]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:07<00:20,  1.89it/s, batch_loss=0.0200, epoch_loss=0.0237, task=1, task_score=0.0562]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:08<00:20,  1.89it/s, batch_loss=0.0167, epoch_loss=0.0231, task=1, task_score=0.0522]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:08<00:16,  2.18it/s, batch_loss=0.0167, epoch_loss=0.0231, task=1, task_score=0.0522]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:08<00:16,  2.18it/s, batch_loss=0.0144, epoch_loss=0.0225, task=1, task_score=0.0549]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:08<00:14,  2.41it/s, batch_loss=0.0144, epoch_loss=0.0225, task=1, task_score=0.0549]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:08<00:14,  2.41it/s, batch_loss=0.0135, epoch_loss=0.0218, task=1, task_score=0.0547]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:08<00:13,  2.60it/s, batch_loss=0.0135, epoch_loss=0.0218, task=1, task_score=0.0547]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:10<00:13,  2.60it/s, batch_loss=0.0303, epoch_loss=0.0224, task=0, task_score=0.0600]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:10<00:24,  1.40it/s, batch_loss=0.0303, epoch_loss=0.0224, task=0, task_score=0.0600]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:10<00:24,  1.40it/s, batch_loss=0.0138, epoch_loss=0.0219, task=1, task_score=0.0739]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:10<00:19,  1.66it/s, batch_loss=0.0138, epoch_loss=0.0219, task=1, task_score=0.0739]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:11<00:19,  1.66it/s, batch_loss=0.0291, epoch_loss=0.0223, task=0, task_score=0.0374]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:11<00:20,  1.58it/s, batch_loss=0.0291, epoch_loss=0.0223, task=0, task_score=0.0374]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:11<00:20,  1.58it/s, batch_loss=0.0123, epoch_loss=0.0217, task=1, task_score=0.0555]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:11<00:16,  1.83it/s, batch_loss=0.0123, epoch_loss=0.0217, task=1, task_score=0.0555]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:11<00:16,  1.83it/s, batch_loss=0.0147, epoch_loss=0.0214, task=1, task_score=0.0578]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:11<00:14,  2.05it/s, batch_loss=0.0147, epoch_loss=0.0214, task=1, task_score=0.0578]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:12<00:14,  2.05it/s, batch_loss=0.0163, epoch_loss=0.0211, task=1, task_score=0.0459]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:12<00:12,  2.28it/s, batch_loss=0.0163, epoch_loss=0.0211, task=1, task_score=0.0459]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:12<00:12,  2.28it/s, batch_loss=0.0251, epoch_loss=0.0213, task=0, task_score=0.0523]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:12<00:14,  1.96it/s, batch_loss=0.0251, epoch_loss=0.0213, task=0, task_score=0.0523]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:13<00:14,  1.96it/s, batch_loss=0.0145, epoch_loss=0.0210, task=1, task_score=0.0434]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:13<00:12,  2.17it/s, batch_loss=0.0145, epoch_loss=0.0210, task=1, task_score=0.0434]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:14<00:12,  2.17it/s, batch_loss=0.0260, epoch_loss=0.0212, task=0, task_score=0.0542]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:14<00:14,  1.80it/s, batch_loss=0.0260, epoch_loss=0.0212, task=0, task_score=0.0542]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:14<00:14,  1.80it/s, batch_loss=0.0285, epoch_loss=0.0215, task=0, task_score=0.0357]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:14<00:14,  1.76it/s, batch_loss=0.0285, epoch_loss=0.0215, task=0, task_score=0.0357]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:15<00:14,  1.76it/s, batch_loss=0.0254, epoch_loss=0.0217, task=0, task_score=0.0415]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:15<00:14,  1.62it/s, batch_loss=0.0254, epoch_loss=0.0217, task=0, task_score=0.0415]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:15<00:14,  1.62it/s, batch_loss=0.0139, epoch_loss=0.0214, task=1, task_score=0.0580]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:15<00:12,  1.89it/s, batch_loss=0.0139, epoch_loss=0.0214, task=1, task_score=0.0580]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:16<00:12,  1.89it/s, batch_loss=0.0136, epoch_loss=0.0211, task=1, task_score=0.0432]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:16<00:10,  2.12it/s, batch_loss=0.0136, epoch_loss=0.0211, task=1, task_score=0.0432]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:16<00:10,  2.12it/s, batch_loss=0.0105, epoch_loss=0.0207, task=1, task_score=0.0717]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:16<00:08,  2.37it/s, batch_loss=0.0105, epoch_loss=0.0207, task=1, task_score=0.0717]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:16<00:08,  2.37it/s, batch_loss=0.0191, epoch_loss=0.0207, task=0, task_score=0.0534]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:17<00:09,  2.08it/s, batch_loss=0.0191, epoch_loss=0.0207, task=0, task_score=0.0534]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:17<00:09,  2.08it/s, batch_loss=0.0155, epoch_loss=0.0205, task=1, task_score=0.0794]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:17<00:08,  2.36it/s, batch_loss=0.0155, epoch_loss=0.0205, task=1, task_score=0.0794]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:17<00:08,  2.36it/s, batch_loss=0.0117, epoch_loss=0.0202, task=1, task_score=0.0692]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:17<00:06,  2.60it/s, batch_loss=0.0117, epoch_loss=0.0202, task=1, task_score=0.0692]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:18<00:06,  2.60it/s, batch_loss=0.0268, epoch_loss=0.0204, task=0, task_score=0.0609]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:18<00:07,  2.33it/s, batch_loss=0.0268, epoch_loss=0.0204, task=0, task_score=0.0609]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:18<00:07,  2.33it/s, batch_loss=0.0301, epoch_loss=0.0207, task=0, task_score=0.0426]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:18<00:08,  1.88it/s, batch_loss=0.0301, epoch_loss=0.0207, task=0, task_score=0.0426]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:19<00:08,  1.88it/s, batch_loss=0.0135, epoch_loss=0.0205, task=1, task_score=0.0432]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:19<00:07,  2.10it/s, batch_loss=0.0135, epoch_loss=0.0205, task=1, task_score=0.0432]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:20<00:07,  2.10it/s, batch_loss=0.0239, epoch_loss=0.0206, task=0, task_score=0.0573]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:20<00:11,  1.22it/s, batch_loss=0.0239, epoch_loss=0.0206, task=0, task_score=0.0573]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:21<00:11,  1.22it/s, batch_loss=0.0127, epoch_loss=0.0204, task=1, task_score=0.0441]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:21<00:08,  1.45it/s, batch_loss=0.0127, epoch_loss=0.0204, task=1, task_score=0.0441]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:21<00:08,  1.45it/s, batch_loss=0.0118, epoch_loss=0.0201, task=1, task_score=0.0519]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:21<00:06,  1.75it/s, batch_loss=0.0118, epoch_loss=0.0201, task=1, task_score=0.0519]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:22<00:06,  1.75it/s, batch_loss=0.0262, epoch_loss=0.0203, task=0, task_score=0.0407]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:22<00:06,  1.65it/s, batch_loss=0.0262, epoch_loss=0.0203, task=0, task_score=0.0407]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:22<00:06,  1.65it/s, batch_loss=0.0207, epoch_loss=0.0203, task=0, task_score=0.0563]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:22<00:05,  1.70it/s, batch_loss=0.0207, epoch_loss=0.0203, task=0, task_score=0.0563]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:23<00:05,  1.70it/s, batch_loss=0.0163, epoch_loss=0.0202, task=1, task_score=0.0528]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  82%|████████▏ | 41/50 [00:23<00:04,  1.95it/s, batch_loss=0.0163, epoch_loss=0.0202, task=1, task_score=0.0528]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:23<00:04,  1.95it/s, batch_loss=0.0126, epoch_loss=0.0200, task=1, task_score=0.0598]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:23<00:03,  2.19it/s, batch_loss=0.0126, epoch_loss=0.0200, task=1, task_score=0.0598]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:24<00:03,  2.19it/s, batch_loss=0.0286, epoch_loss=0.0202, task=0, task_score=0.0431]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:24<00:04,  1.46it/s, batch_loss=0.0286, epoch_loss=0.0202, task=0, task_score=0.0431]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:24<00:04,  1.46it/s, batch_loss=0.0124, epoch_loss=0.0200, task=1, task_score=0.0700]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:24<00:03,  1.74it/s, batch_loss=0.0124, epoch_loss=0.0200, task=1, task_score=0.0700]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:25<00:03,  1.74it/s, batch_loss=0.0124, epoch_loss=0.0199, task=1, task_score=0.0514]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:25<00:02,  1.99it/s, batch_loss=0.0124, epoch_loss=0.0199, task=1, task_score=0.0514]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:26<00:02,  1.99it/s, batch_loss=0.0302, epoch_loss=0.0201, task=0, task_score=0.0473]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:26<00:02,  1.56it/s, batch_loss=0.0302, epoch_loss=0.0201, task=0, task_score=0.0473]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:26<00:02,  1.56it/s, batch_loss=0.0127, epoch_loss=0.0199, task=1, task_score=0.0694]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:26<00:01,  1.85it/s, batch_loss=0.0127, epoch_loss=0.0199, task=1, task_score=0.0694]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:26<00:01,  1.85it/s, batch_loss=0.0135, epoch_loss=0.0198, task=1, task_score=0.0743]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:26<00:00,  2.16it/s, batch_loss=0.0135, epoch_loss=0.0198, task=1, task_score=0.0743]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:27<00:00,  2.16it/s, batch_loss=0.0101, epoch_loss=0.0196, task=1, task_score=0.0378]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:27<00:00,  2.44it/s, batch_loss=0.0101, epoch_loss=0.0196, task=1, task_score=0.0378]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:27<00:00,  2.44it/s, batch_loss=0.0109, epoch_loss=0.0194, task=1, task_score=0.0668]\u001b[A\n",
      "Batch: 100%|██████████| 50/50 [00:27<00:00,  2.57it/s, batch_loss=0.0109, epoch_loss=0.0194, task=1, task_score=0.0668]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Evaluating model:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating model:   3%|▎         | 1/39 [00:00<00:30,  1.24it/s]\u001b[A\n",
      "Evaluating model:   5%|▌         | 2/39 [00:01<00:28,  1.32it/s]\u001b[A\n",
      "Evaluating model:   8%|▊         | 3/39 [00:02<00:26,  1.34it/s]\u001b[A\n",
      "Evaluating model:  10%|█         | 4/39 [00:02<00:24,  1.45it/s]\u001b[A\n",
      "Evaluating model:  13%|█▎        | 5/39 [00:03<00:20,  1.64it/s]\u001b[A\n",
      "Evaluating model:  15%|█▌        | 6/39 [00:04<00:31,  1.05it/s]\u001b[A\n",
      "Evaluating model:  18%|█▊        | 7/39 [00:05<00:29,  1.09it/s]\u001b[A\n",
      "Evaluating model:  21%|██        | 8/39 [00:06<00:29,  1.05it/s]\u001b[A\n",
      "Evaluating model:  23%|██▎       | 9/39 [00:07<00:23,  1.28it/s]\u001b[A\n",
      "Evaluating model:  26%|██▌       | 10/39 [00:07<00:21,  1.38it/s]\u001b[A\n",
      "Evaluating model:  28%|██▊       | 11/39 [00:08<00:20,  1.36it/s]\u001b[A\n",
      "Evaluating model:  31%|███       | 12/39 [00:09<00:18,  1.46it/s]\u001b[A\n",
      "Evaluating model:  33%|███▎      | 13/39 [00:09<00:16,  1.60it/s]\u001b[A\n",
      "Evaluating model:  36%|███▌      | 14/39 [00:10<00:14,  1.69it/s]\u001b[A\n",
      "Evaluating model:  38%|███▊      | 15/39 [00:10<00:13,  1.78it/s]\u001b[A\n",
      "Evaluating model:  41%|████      | 16/39 [00:10<00:11,  1.94it/s]\u001b[A\n",
      "Evaluating model:  44%|████▎     | 17/39 [00:11<00:10,  2.02it/s]\u001b[A\n",
      "Evaluating model:  46%|████▌     | 18/39 [00:11<00:10,  2.06it/s]\u001b[A\n",
      "Evaluating model:  49%|████▊     | 19/39 [00:12<00:09,  2.01it/s]\u001b[A\n",
      "Evaluating model:  51%|█████▏    | 20/39 [00:12<00:09,  2.02it/s]\u001b[A\n",
      "Evaluating model:  54%|█████▍    | 21/39 [00:13<00:10,  1.77it/s]\u001b[A\n",
      "Evaluating model:  56%|█████▋    | 22/39 [00:14<00:08,  1.93it/s]\u001b[A\n",
      "Evaluating model:  59%|█████▉    | 23/39 [00:14<00:07,  2.07it/s]\u001b[A\n",
      "Evaluating model:  62%|██████▏   | 24/39 [00:15<00:08,  1.85it/s]\u001b[A\n",
      "Evaluating model:  64%|██████▍   | 25/39 [00:15<00:07,  1.96it/s]\u001b[A\n",
      "Evaluating model:  67%|██████▋   | 26/39 [00:16<00:06,  1.88it/s]\u001b[A\n",
      "Evaluating model:  69%|██████▉   | 27/39 [00:16<00:06,  1.96it/s]\u001b[A\n",
      "Evaluating model:  72%|███████▏  | 28/39 [00:16<00:05,  2.11it/s]\u001b[A\n",
      "Evaluating model:  74%|███████▍  | 29/39 [00:17<00:05,  1.91it/s]\u001b[A\n",
      "Evaluating model:  77%|███████▋  | 30/39 [00:18<00:05,  1.68it/s]\u001b[A\n",
      "Evaluating model:  79%|███████▉  | 31/39 [00:19<00:05,  1.51it/s]\u001b[A\n",
      "Evaluating model:  82%|████████▏ | 32/39 [00:19<00:04,  1.65it/s]\u001b[A\n",
      "Evaluating model:  85%|████████▍ | 33/39 [00:20<00:03,  1.79it/s]\u001b[A\n",
      "Evaluating model:  87%|████████▋ | 34/39 [00:20<00:02,  1.91it/s]\u001b[A\n",
      "Evaluating model:  90%|████████▉ | 35/39 [00:21<00:02,  1.97it/s]\u001b[A\n",
      "Evaluating model:  92%|█████████▏| 36/39 [00:21<00:01,  2.03it/s]\u001b[A\n",
      "Evaluating model:  95%|█████████▍| 37/39 [00:21<00:00,  2.05it/s]\u001b[A\n",
      "Evaluating model:  97%|█████████▋| 38/39 [00:22<00:00,  2.01it/s]\u001b[A\n",
      "Evaluating model: 100%|██████████| 39/39 [00:23<00:00,  1.84it/s]\u001b[A\n",
      "Training model:  30%|███       | 3/10 [02:46<06:38, 56.87s/it, dev_loss=0.0310, dev_score=0.0205, loss=0.0109]\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\n",
      "Batch:   0%|          | 0/50 [00:00<?, ?it/s, batch_loss=0.0306, epoch_loss=0.0306, task=0, task_score=0.0370]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:26,  1.86it/s, batch_loss=0.0306, epoch_loss=0.0306, task=0, task_score=0.0370]\u001b[A\n",
      "Batch:   2%|▏         | 1/50 [00:00<00:26,  1.86it/s, batch_loss=0.0134, epoch_loss=0.0220, task=1, task_score=0.0535]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:00<00:23,  2.02it/s, batch_loss=0.0134, epoch_loss=0.0220, task=1, task_score=0.0535]\u001b[A\n",
      "Batch:   4%|▍         | 2/50 [00:01<00:23,  2.02it/s, batch_loss=0.0259, epoch_loss=0.0233, task=0, task_score=0.0466]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:01<00:27,  1.72it/s, batch_loss=0.0259, epoch_loss=0.0233, task=0, task_score=0.0466]\u001b[A\n",
      "Batch:   6%|▌         | 3/50 [00:02<00:27,  1.72it/s, batch_loss=0.0089, epoch_loss=0.0197, task=1, task_score=0.0839]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:02<00:22,  2.02it/s, batch_loss=0.0089, epoch_loss=0.0197, task=1, task_score=0.0839]\u001b[A\n",
      "Batch:   8%|▊         | 4/50 [00:02<00:22,  2.02it/s, batch_loss=0.0235, epoch_loss=0.0205, task=0, task_score=0.0417]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:02<00:23,  1.88it/s, batch_loss=0.0235, epoch_loss=0.0205, task=0, task_score=0.0417]\u001b[A\n",
      "Batch:  10%|█         | 5/50 [00:03<00:23,  1.88it/s, batch_loss=0.0229, epoch_loss=0.0209, task=0, task_score=0.0528]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:03<00:24,  1.80it/s, batch_loss=0.0229, epoch_loss=0.0209, task=0, task_score=0.0528]\u001b[A\n",
      "Batch:  12%|█▏        | 6/50 [00:03<00:24,  1.80it/s, batch_loss=0.0113, epoch_loss=0.0195, task=1, task_score=0.0584]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:03<00:20,  2.06it/s, batch_loss=0.0113, epoch_loss=0.0195, task=1, task_score=0.0584]\u001b[A\n",
      "Batch:  14%|█▍        | 7/50 [00:04<00:20,  2.06it/s, batch_loss=0.0291, epoch_loss=0.0207, task=0, task_score=0.0489]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:04<00:24,  1.69it/s, batch_loss=0.0291, epoch_loss=0.0207, task=0, task_score=0.0489]\u001b[A\n",
      "Batch:  16%|█▌        | 8/50 [00:04<00:24,  1.69it/s, batch_loss=0.0111, epoch_loss=0.0196, task=1, task_score=0.0545]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:04<00:20,  2.00it/s, batch_loss=0.0111, epoch_loss=0.0196, task=1, task_score=0.0545]\u001b[A\n",
      "Batch:  18%|█▊        | 9/50 [00:05<00:20,  2.00it/s, batch_loss=0.0337, epoch_loss=0.0210, task=0, task_score=0.0355]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:05<00:25,  1.56it/s, batch_loss=0.0337, epoch_loss=0.0210, task=0, task_score=0.0355]\u001b[A\n",
      "Batch:  20%|██        | 10/50 [00:06<00:25,  1.56it/s, batch_loss=0.0293, epoch_loss=0.0218, task=0, task_score=0.0333]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:06<00:25,  1.55it/s, batch_loss=0.0293, epoch_loss=0.0218, task=0, task_score=0.0333]\u001b[A\n",
      "Batch:  22%|██▏       | 11/50 [00:06<00:25,  1.55it/s, batch_loss=0.0113, epoch_loss=0.0209, task=1, task_score=0.0403]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  24%|██▍       | 12/50 [00:06<00:20,  1.84it/s, batch_loss=0.0113, epoch_loss=0.0209, task=1, task_score=0.0403]\u001b[A\n",
      "Batch:  24%|██▍       | 12/50 [00:07<00:20,  1.84it/s, batch_loss=0.0268, epoch_loss=0.0214, task=0, task_score=0.0426]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:07<00:20,  1.80it/s, batch_loss=0.0268, epoch_loss=0.0214, task=0, task_score=0.0426]\u001b[A\n",
      "Batch:  26%|██▌       | 13/50 [00:07<00:20,  1.80it/s, batch_loss=0.0268, epoch_loss=0.0218, task=0, task_score=0.0434]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:07<00:22,  1.64it/s, batch_loss=0.0268, epoch_loss=0.0218, task=0, task_score=0.0434]\u001b[A\n",
      "Batch:  28%|██▊       | 14/50 [00:08<00:22,  1.64it/s, batch_loss=0.0113, epoch_loss=0.0211, task=1, task_score=0.0614]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:08<00:18,  1.91it/s, batch_loss=0.0113, epoch_loss=0.0211, task=1, task_score=0.0614]\u001b[A\n",
      "Batch:  30%|███       | 15/50 [00:08<00:18,  1.91it/s, batch_loss=0.0118, epoch_loss=0.0205, task=1, task_score=0.0742]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:08<00:15,  2.20it/s, batch_loss=0.0118, epoch_loss=0.0205, task=1, task_score=0.0742]\u001b[A\n",
      "Batch:  32%|███▏      | 16/50 [00:09<00:15,  2.20it/s, batch_loss=0.0241, epoch_loss=0.0207, task=0, task_score=0.0508]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:09<00:18,  1.78it/s, batch_loss=0.0241, epoch_loss=0.0207, task=0, task_score=0.0508]\u001b[A\n",
      "Batch:  34%|███▍      | 17/50 [00:09<00:18,  1.78it/s, batch_loss=0.0284, epoch_loss=0.0211, task=0, task_score=0.0368]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:09<00:18,  1.77it/s, batch_loss=0.0284, epoch_loss=0.0211, task=0, task_score=0.0368]\u001b[A\n",
      "Batch:  36%|███▌      | 18/50 [00:10<00:18,  1.77it/s, batch_loss=0.0121, epoch_loss=0.0206, task=1, task_score=0.0828]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:10<00:14,  2.07it/s, batch_loss=0.0121, epoch_loss=0.0206, task=1, task_score=0.0828]\u001b[A\n",
      "Batch:  38%|███▊      | 19/50 [00:10<00:14,  2.07it/s, batch_loss=0.0095, epoch_loss=0.0201, task=1, task_score=0.0992]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:10<00:12,  2.35it/s, batch_loss=0.0095, epoch_loss=0.0201, task=1, task_score=0.0992]\u001b[A\n",
      "Batch:  40%|████      | 20/50 [00:10<00:12,  2.35it/s, batch_loss=0.0106, epoch_loss=0.0196, task=1, task_score=0.0772]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:10<00:11,  2.55it/s, batch_loss=0.0106, epoch_loss=0.0196, task=1, task_score=0.0772]\u001b[A\n",
      "Batch:  42%|████▏     | 21/50 [00:11<00:11,  2.55it/s, batch_loss=0.0103, epoch_loss=0.0192, task=1, task_score=0.0837]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:11<00:10,  2.64it/s, batch_loss=0.0103, epoch_loss=0.0192, task=1, task_score=0.0837]\u001b[A\n",
      "Batch:  44%|████▍     | 22/50 [00:11<00:10,  2.64it/s, batch_loss=0.0115, epoch_loss=0.0189, task=1, task_score=0.0543]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:11<00:09,  2.80it/s, batch_loss=0.0115, epoch_loss=0.0189, task=1, task_score=0.0543]\u001b[A\n",
      "Batch:  46%|████▌     | 23/50 [00:11<00:09,  2.80it/s, batch_loss=0.0103, epoch_loss=0.0185, task=1, task_score=0.0849]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:11<00:09,  2.88it/s, batch_loss=0.0103, epoch_loss=0.0185, task=1, task_score=0.0849]\u001b[A\n",
      "Batch:  48%|████▊     | 24/50 [00:12<00:09,  2.88it/s, batch_loss=0.0303, epoch_loss=0.0190, task=0, task_score=0.0317]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:12<00:11,  2.16it/s, batch_loss=0.0303, epoch_loss=0.0190, task=0, task_score=0.0317]\u001b[A\n",
      "Batch:  50%|█████     | 25/50 [00:13<00:11,  2.16it/s, batch_loss=0.0267, epoch_loss=0.0193, task=0, task_score=0.0330]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:13<00:11,  2.05it/s, batch_loss=0.0267, epoch_loss=0.0193, task=0, task_score=0.0330]\u001b[A\n",
      "Batch:  52%|█████▏    | 26/50 [00:13<00:11,  2.05it/s, batch_loss=0.0136, epoch_loss=0.0191, task=1, task_score=0.0354]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:13<00:10,  2.26it/s, batch_loss=0.0136, epoch_loss=0.0191, task=1, task_score=0.0354]\u001b[A\n",
      "Batch:  54%|█████▍    | 27/50 [00:14<00:10,  2.26it/s, batch_loss=0.0311, epoch_loss=0.0195, task=0, task_score=0.0581]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:14<00:11,  1.95it/s, batch_loss=0.0311, epoch_loss=0.0195, task=0, task_score=0.0581]\u001b[A\n",
      "Batch:  56%|█████▌    | 28/50 [00:14<00:11,  1.95it/s, batch_loss=0.0254, epoch_loss=0.0197, task=0, task_score=0.0536]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:14<00:11,  1.89it/s, batch_loss=0.0254, epoch_loss=0.0197, task=0, task_score=0.0536]\u001b[A\n",
      "Batch:  58%|█████▊    | 29/50 [00:15<00:11,  1.89it/s, batch_loss=0.0100, epoch_loss=0.0194, task=1, task_score=0.0789]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:15<00:09,  2.10it/s, batch_loss=0.0100, epoch_loss=0.0194, task=1, task_score=0.0789]\u001b[A\n",
      "Batch:  60%|██████    | 30/50 [00:15<00:09,  2.10it/s, batch_loss=0.0112, epoch_loss=0.0191, task=1, task_score=0.0649]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:15<00:07,  2.38it/s, batch_loss=0.0112, epoch_loss=0.0191, task=1, task_score=0.0649]\u001b[A\n",
      "Batch:  62%|██████▏   | 31/50 [00:16<00:07,  2.38it/s, batch_loss=0.0309, epoch_loss=0.0195, task=0, task_score=0.0291]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:16<00:09,  2.00it/s, batch_loss=0.0309, epoch_loss=0.0195, task=0, task_score=0.0291]\u001b[A\n",
      "Batch:  64%|██████▍   | 32/50 [00:16<00:09,  2.00it/s, batch_loss=0.0099, epoch_loss=0.0192, task=1, task_score=0.0562]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:16<00:07,  2.30it/s, batch_loss=0.0099, epoch_loss=0.0192, task=1, task_score=0.0562]\u001b[A\n",
      "Batch:  66%|██████▌   | 33/50 [00:16<00:07,  2.30it/s, batch_loss=0.0108, epoch_loss=0.0190, task=1, task_score=0.0581]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:16<00:06,  2.53it/s, batch_loss=0.0108, epoch_loss=0.0190, task=1, task_score=0.0581]\u001b[A\n",
      "Batch:  68%|██████▊   | 34/50 [00:17<00:06,  2.53it/s, batch_loss=0.0293, epoch_loss=0.0193, task=0, task_score=0.0468]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:17<00:07,  2.07it/s, batch_loss=0.0293, epoch_loss=0.0193, task=0, task_score=0.0468]\u001b[A\n",
      "Batch:  70%|███████   | 35/50 [00:17<00:07,  2.07it/s, batch_loss=0.0135, epoch_loss=0.0191, task=1, task_score=0.0487]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:17<00:06,  2.32it/s, batch_loss=0.0135, epoch_loss=0.0191, task=1, task_score=0.0487]\u001b[A\n",
      "Batch:  72%|███████▏  | 36/50 [00:18<00:06,  2.32it/s, batch_loss=0.0283, epoch_loss=0.0193, task=0, task_score=0.0380]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:18<00:07,  1.77it/s, batch_loss=0.0283, epoch_loss=0.0193, task=0, task_score=0.0380]\u001b[A\n",
      "Batch:  74%|███████▍  | 37/50 [00:19<00:07,  1.77it/s, batch_loss=0.0284, epoch_loss=0.0196, task=0, task_score=0.0393]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:19<00:07,  1.61it/s, batch_loss=0.0284, epoch_loss=0.0196, task=0, task_score=0.0393]\u001b[A\n",
      "Batch:  76%|███████▌  | 38/50 [00:19<00:07,  1.61it/s, batch_loss=0.0293, epoch_loss=0.0198, task=0, task_score=0.0259]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:19<00:07,  1.54it/s, batch_loss=0.0293, epoch_loss=0.0198, task=0, task_score=0.0259]\u001b[A\n",
      "Batch:  78%|███████▊  | 39/50 [00:20<00:07,  1.54it/s, batch_loss=0.0301, epoch_loss=0.0201, task=0, task_score=0.0446]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:20<00:06,  1.57it/s, batch_loss=0.0301, epoch_loss=0.0201, task=0, task_score=0.0446]\u001b[A\n",
      "Batch:  80%|████████  | 40/50 [00:20<00:06,  1.57it/s, batch_loss=0.0117, epoch_loss=0.0199, task=1, task_score=0.0766]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:20<00:05,  1.79it/s, batch_loss=0.0117, epoch_loss=0.0199, task=1, task_score=0.0766]\u001b[A\n",
      "Batch:  82%|████████▏ | 41/50 [00:21<00:05,  1.79it/s, batch_loss=0.0110, epoch_loss=0.0197, task=1, task_score=0.0497]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:21<00:03,  2.08it/s, batch_loss=0.0110, epoch_loss=0.0197, task=1, task_score=0.0497]\u001b[A\n",
      "Batch:  84%|████████▍ | 42/50 [00:22<00:03,  2.08it/s, batch_loss=0.0298, epoch_loss=0.0199, task=0, task_score=0.0389]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:22<00:04,  1.73it/s, batch_loss=0.0298, epoch_loss=0.0199, task=0, task_score=0.0389]\u001b[A\n",
      "Batch:  86%|████████▌ | 43/50 [00:25<00:04,  1.73it/s, batch_loss=0.0304, epoch_loss=0.0201, task=0, task_score=0.0340]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:25<00:09,  1.55s/it, batch_loss=0.0304, epoch_loss=0.0201, task=0, task_score=0.0340]\u001b[A\n",
      "Batch:  88%|████████▊ | 44/50 [00:26<00:09,  1.55s/it, batch_loss=0.0091, epoch_loss=0.0199, task=1, task_score=0.1204]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch:  90%|█████████ | 45/50 [00:26<00:06,  1.23s/it, batch_loss=0.0091, epoch_loss=0.0199, task=1, task_score=0.1204]\u001b[A\n",
      "Batch:  90%|█████████ | 45/50 [00:26<00:06,  1.23s/it, batch_loss=0.0285, epoch_loss=0.0201, task=0, task_score=0.0430]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:26<00:04,  1.03s/it, batch_loss=0.0285, epoch_loss=0.0201, task=0, task_score=0.0430]\u001b[A\n",
      "Batch:  92%|█████████▏| 46/50 [00:27<00:04,  1.03s/it, batch_loss=0.0088, epoch_loss=0.0198, task=1, task_score=0.0643]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:27<00:02,  1.22it/s, batch_loss=0.0088, epoch_loss=0.0198, task=1, task_score=0.0643]\u001b[A\n",
      "Batch:  94%|█████████▍| 47/50 [00:27<00:02,  1.22it/s, batch_loss=0.0249, epoch_loss=0.0199, task=0, task_score=0.0448]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:27<00:01,  1.37it/s, batch_loss=0.0249, epoch_loss=0.0199, task=0, task_score=0.0448]\u001b[A\n",
      "Batch:  96%|█████████▌| 48/50 [00:28<00:01,  1.37it/s, batch_loss=0.0257, epoch_loss=0.0201, task=0, task_score=0.0446]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:28<00:00,  1.33it/s, batch_loss=0.0257, epoch_loss=0.0201, task=0, task_score=0.0446]\u001b[A\n",
      "Batch:  98%|█████████▊| 49/50 [00:29<00:00,  1.33it/s, batch_loss=0.0270, epoch_loss=0.0202, task=0, task_score=0.0492]\u001b[A\n",
      "Batch: 100%|██████████| 50/50 [00:29<00:00,  1.04it/s, batch_loss=0.0270, epoch_loss=0.0202, task=0, task_score=0.0492]\u001b[A\n",
      "                                                                                                                       \u001b[A\n",
      "Evaluating model:   0%|          | 0/39 [00:00<?, ?it/s]\u001b[A\n",
      "Evaluating model:   3%|▎         | 1/39 [00:00<00:29,  1.27it/s]\u001b[A\n",
      "Evaluating model:   5%|▌         | 2/39 [00:01<00:29,  1.26it/s]\u001b[A\n",
      "Evaluating model:   8%|▊         | 3/39 [00:02<00:24,  1.48it/s]\u001b[A\n",
      "Evaluating model:  10%|█         | 4/39 [00:02<00:21,  1.64it/s]\u001b[A\n",
      "Evaluating model:  13%|█▎        | 5/39 [00:02<00:18,  1.84it/s]\u001b[A\n",
      "Evaluating model:  15%|█▌        | 6/39 [00:03<00:17,  1.94it/s]\u001b[A\n",
      "Evaluating model:  18%|█▊        | 7/39 [00:03<00:15,  2.12it/s]\u001b[A\n",
      "Evaluating model:  21%|██        | 8/39 [00:04<00:14,  2.09it/s]\u001b[A\n",
      "Evaluating model:  23%|██▎       | 9/39 [00:04<00:16,  1.82it/s]\u001b[A\n",
      "Evaluating model:  26%|██▌       | 10/39 [00:05<00:16,  1.78it/s]\u001b[A\n",
      "Evaluating model:  28%|██▊       | 11/39 [00:05<00:14,  1.87it/s]\u001b[A\n",
      "Evaluating model:  31%|███       | 12/39 [00:06<00:15,  1.77it/s]\u001b[A\n",
      "Evaluating model:  33%|███▎      | 13/39 [00:06<00:13,  1.94it/s]\u001b[A\n",
      "Evaluating model:  36%|███▌      | 14/39 [00:07<00:13,  1.80it/s]\u001b[A\n",
      "Evaluating model:  38%|███▊      | 15/39 [00:08<00:12,  1.87it/s]\u001b[A\n",
      "Evaluating model:  41%|████      | 16/39 [00:08<00:14,  1.62it/s]\u001b[A\n",
      "Evaluating model:  44%|████▎     | 17/39 [00:09<00:14,  1.48it/s]\u001b[A\n",
      "Evaluating model:  46%|████▌     | 18/39 [00:10<00:12,  1.71it/s]\u001b[A\n",
      "Evaluating model:  49%|████▊     | 19/39 [00:10<00:10,  1.87it/s]\u001b[A\n",
      "Evaluating model:  51%|█████▏    | 20/39 [00:10<00:09,  2.02it/s]\u001b[A\n",
      "Evaluating model:  54%|█████▍    | 21/39 [00:11<00:08,  2.12it/s]\u001b[A\n",
      "Evaluating model:  56%|█████▋    | 22/39 [00:11<00:07,  2.24it/s]\u001b[A\n",
      "Evaluating model:  59%|█████▉    | 23/39 [00:12<00:06,  2.35it/s]\u001b[A\n",
      "Evaluating model:  62%|██████▏   | 24/39 [00:12<00:07,  1.94it/s]\u001b[A\n",
      "Evaluating model:  64%|██████▍   | 25/39 [00:13<00:07,  1.95it/s]\u001b[A\n",
      "Evaluating model:  67%|██████▋   | 26/39 [00:13<00:06,  2.04it/s]\u001b[A\n",
      "Evaluating model:  69%|██████▉   | 27/39 [00:14<00:05,  2.08it/s]\u001b[A\n",
      "Evaluating model:  72%|███████▏  | 28/39 [00:14<00:05,  2.17it/s]\u001b[A\n",
      "Evaluating model:  74%|███████▍  | 29/39 [00:15<00:04,  2.21it/s]\u001b[A\n",
      "Evaluating model:  77%|███████▋  | 30/39 [00:16<00:07,  1.15it/s]\u001b[A\n",
      "Evaluating model:  79%|███████▉  | 31/39 [00:17<00:06,  1.21it/s]\u001b[A\n",
      "Evaluating model:  82%|████████▏ | 32/39 [00:18<00:05,  1.26it/s]\u001b[A\n",
      "Evaluating model:  85%|████████▍ | 33/39 [00:18<00:04,  1.37it/s]\u001b[A\n",
      "Evaluating model:  87%|████████▋ | 34/39 [00:19<00:03,  1.54it/s]\u001b[A\n",
      "Evaluating model:  90%|████████▉ | 35/39 [00:19<00:02,  1.78it/s]\u001b[A\n",
      "Evaluating model:  92%|█████████▏| 36/39 [00:20<00:01,  1.77it/s]\u001b[A\n",
      "Evaluating model:  95%|█████████▍| 37/39 [00:20<00:01,  1.85it/s]\u001b[A\n",
      "Evaluating model:  97%|█████████▋| 38/39 [00:21<00:00,  2.17it/s]\u001b[A\n",
      "Evaluating model: 100%|██████████| 39/39 [00:22<00:00,  1.56it/s]\u001b[A\n",
      "                                                                                                              "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping: Terminate\n",
      "Loading weights from epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "run_mtl_model(train = True, **modelling_vars, **batch_writing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'f1-score': [0.019746062875596253, 0.020510140338038184, 0.020493812060904146, 0.019956901033051994], 'precision': [0.015730650075595327, 0.016424099417566985, 0.016517081511881273, 0.01612070826570358], 'recall': [0.026915195684188285, 0.027974030623037244, 0.027859387924381994, 0.026960222760604544], 'accuracy': [0.4412595882115462, 0.4578118691966088, 0.465482438433589, 0.46669358094469116], 'loss': [0.02935877652913272, 0.02839940134247898, 0.030988091945070677, 0.0261436183461269]}\n"
     ]
    }
   ],
   "source": [
    "print(dev_metrics.scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    }
   ],
   "source": [
    "# Do tests\n",
    "main_task_eval = dict(model = model,\n",
    "                      batchers = main_test,\n",
    "                      loss = loss,\n",
    "                      metrics = Metrics(metrics, display, stop_metric),\n",
    "                      gpu = gpu,\n",
    "                      mtl = 0,\n",
    "                      store = False,\n",
    "                      data = None,\n",
    "                      writer = csv.writer(open('test3', 'w')),\n",
    "                      hyper_info = [embedding],\n",
    "                      model_hdr = ['name'],\n",
    "                      metric_hdr = ['f1-score'],\n",
    "                      main_name = 'davidson',\n",
    "                      data_name = 'davidson'\n",
    "                      )\n",
    "\n",
    "run_mtl_model(train = False, **main_task_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Evaluating model:   0%|          | 0/11 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    }
   ],
   "source": [
    "for i, aux in enumerate(test_batchers):\n",
    "    print(i)\n",
    "    print(auxillary[i]['task_id'])\n",
    "    aux_metrics = Metrics(metrics, display, stop_metric)\n",
    "    aux_dict = dict(model = model,\n",
    "                    batchers = aux,\n",
    "                    metrics = aux_metrics,\n",
    "                    gpu = gpu,\n",
    "                    mtl = auxillary[i]['task_id'],\n",
    "                    store = False,\n",
    "                    data = None,\n",
    "                    data_name = auxillary[i]['name'],\n",
    "                    main_name = 'davidson',\n",
    "                    writer = csv.writer(open('test4', 'w')),\n",
    "                    loss = loss,\n",
    "                    hyper_info = [embedding],\n",
    "                    model_hdr = ['name'],\n",
    "                    metric_hdr = ['f1-score'],\n",
    "                    )\n",
    "    run_mtl_model(train = False, **aux_dict)\n",
    "    aux_metrics = {f\"{auxillary[i]['name']}_{m}\": key for m, key in aux_metrics.scores.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auxillary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batchers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
